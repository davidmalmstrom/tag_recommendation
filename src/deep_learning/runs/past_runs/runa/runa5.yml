--nn_model: MLP
--is_tag: "1"
--eval_recall: "1"
--topk: "3"
#--dataset: "ml-1m"
--big_tag: "0"
--epochs: "20"
--layers: "[32,24,18,12]"
#--mf_pretrain: "Pretrain/ml-1m_GMF_8_1501651698.h5"
#--mlp_pretrain: "Pretrain/ml-1m_MLP_[64,32,16,8]_1501652038.h5"


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', epochs=20, eval_recall=1, is_tag=1, layers='[32,24,18,12]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_neg=4, out=1, path='Data/', reg_layers='[0,0,0,0]', reg_mf=0, topk=3, verbose=1) 
# Load data done [2.6 s]. #user=17422, #item=986, #train=133102, #test=17422
# Init: Recall = 0.0021, Jaccard score = 0.0011
# Iteration 0 fit: [6.4 s]: Recall = 0.0279, Jaccard score = 0.0153, loss = 0.4753, val_loss = 0.0000, eval: [8.1 s]
# Iteration 1 fit: [5.8 s]: Recall = 0.0277, Jaccard score = 0.0152, loss = 0.4416, val_loss = 0.0000, eval: [7.8 s]
# Iteration 2 fit: [5.8 s]: Recall = 0.0294, Jaccard score = 0.0161, loss = 0.4396, val_loss = 0.0000, eval: [7.8 s]
# Iteration 3 fit: [5.8 s]: Recall = 0.0291, Jaccard score = 0.0159, loss = 0.4383, val_loss = 0.0000, eval: [8.0 s]
# Iteration 4 fit: [5.8 s]: Recall = 0.0302, Jaccard score = 0.0166, loss = 0.4370, val_loss = 0.0000, eval: [8.0 s]
# Iteration 5 fit: [5.8 s]: Recall = 0.0289, Jaccard score = 0.0158, loss = 0.4357, val_loss = 0.0000, eval: [8.1 s]
# Iteration 6 fit: [5.8 s]: Recall = 0.0264, Jaccard score = 0.0144, loss = 0.4327, val_loss = 0.0000, eval: [8.0 s]
# Iteration 7 fit: [5.8 s]: Recall = 0.0268, Jaccard score = 0.0147, loss = 0.4296, val_loss = 0.0000, eval: [8.4 s]
# Iteration 8 fit: [5.8 s]: Recall = 0.0243, Jaccard score = 0.0133, loss = 0.4261, val_loss = 0.0000, eval: [8.1 s]
# Iteration 9 fit: [5.8 s]: Recall = 0.0245, Jaccard score = 0.0134, loss = 0.4223, val_loss = 0.0000, eval: [8.4 s]
# Iteration 10 fit: [5.8 s]: Recall = 0.0234, Jaccard score = 0.0128, loss = 0.4185, val_loss = 0.0000, eval: [7.8 s]
# Iteration 11 fit: [5.8 s]: Recall = 0.0226, Jaccard score = 0.0123, loss = 0.4141, val_loss = 0.0000, eval: [8.0 s]
# Iteration 12 fit: [5.8 s]: Recall = 0.0230, Jaccard score = 0.0125, loss = 0.4095, val_loss = 0.0000, eval: [7.7 s]
# Iteration 13 fit: [5.8 s]: Recall = 0.0215, Jaccard score = 0.0117, loss = 0.4052, val_loss = 0.0000, eval: [7.7 s]
# Iteration 14 fit: [5.8 s]: Recall = 0.0234, Jaccard score = 0.0128, loss = 0.4007, val_loss = 0.0000, eval: [8.4 s]
# Iteration 15 fit: [5.8 s]: Recall = 0.0215, Jaccard score = 0.0117, loss = 0.3963, val_loss = 0.0000, eval: [8.0 s]
# Iteration 16 fit: [5.8 s]: Recall = 0.0211, Jaccard score = 0.0115, loss = 0.3922, val_loss = 0.0000, eval: [8.2 s]
# Iteration 17 fit: [5.8 s]: Recall = 0.0207, Jaccard score = 0.0113, loss = 0.3874, val_loss = 0.0000, eval: [8.3 s]
# Iteration 18 fit: [5.8 s]: Recall = 0.0215, Jaccard score = 0.0117, loss = 0.3834, val_loss = 0.0000, eval: [8.1 s]
# Iteration 19 fit: [5.8 s]: Recall = 0.0186, Jaccard score = 0.0101, loss = 0.3796, val_loss = 0.0000, eval: [7.8 s]
# End. Best Iteration 4:  Recall = 0.0302, Jaccard score = 0.0166. 
# The best NeuMF model is saved to Pretrain/_MLP_8_[32,24,18,12]_1559911444.h5