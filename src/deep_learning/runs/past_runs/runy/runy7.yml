--nn_model: NeuMF
--is_tag: "1"
--eval_recall: "1"
--topk: "3"
--big_tag: "0"
--epochs: "300"
--num_factors: "94"
--early_stopping: "45"
--layers: "[512,96]"
--reg_layers: "[0,0]"
--test_dataset: "1"
--mf_pretrain: "Pretrain/_GMF_94_[64,32,16,8]_1568411865.h5"
--mlp_pretrain: "Pretrain/_MLP_8_[512,96]_1568498541.h5"

# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=45, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1568411865.h5', mlp_pretrain='Pretrain/_MLP_8_[512,96]_1568498541.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,96]_1568618678.h5
--weights_path: Pretrain/_NeuMF_94_[512,96]_1568618678.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1568411865.h5) and MLP (Pretrain/_MLP_8_[512,96]_1568498541.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 96)           145248      concatenate_2[0][0]              
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 7,845,439
# Trainable params: 7,845,439
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.1908, Jaccard score = 0.1276
# Model test performed 
# Recall score: 0.18444543628654317     Jaccard score: 0.12420166804418063

# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=45, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1568411865.h5', mlp_pretrain='Pretrain/_MLP_8_[512,96]_1568498541.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,96]_1568620137.h5
--weights_path: Pretrain/_NeuMF_94_[512,96]_1568620137.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1568411865.h5) and MLP (Pretrain/_MLP_8_[512,96]_1568498541.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 96)           145248      concatenate_2[0][0]              
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 7,845,439
# Trainable params: 7,845,439
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.1908, Jaccard score = 0.1276
# Iteration 0 fit: [31.6 s]: Recall = 0.1789, Jaccard score = 0.1187, loss = 0.0049, gradient norm = 1.0000, eval: [36.7 s]
# Iteration 1 fit: [31.0 s]: Recall = 0.1749, Jaccard score = 0.1158, loss = 0.0054, gradient norm = 1.0000, eval: [36.6 s]
# Iteration 2 fit: [30.9 s]: Recall = 0.1783, Jaccard score = 0.1183, loss = 0.0058, gradient norm = 1.0000, eval: [36.7 s]
# Iteration 3 fit: [31.0 s]: Recall = 0.1776, Jaccard score = 0.1178, loss = 0.0066, gradient norm = 1.0000, eval: [36.7 s]


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=45, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.0001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1568411865.h5', mlp_pretrain='Pretrain/_MLP_8_[512,96]_1568498541.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,96]_1568620631.h5
--weights_path: Pretrain/_NeuMF_94_[512,96]_1568620631.h5
# Load data done [1.8 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1568411865.h5) and MLP (Pretrain/_MLP_8_[512,96]_1568498541.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 96)           145248      concatenate_2[0][0]              
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 7,845,439
# Trainable params: 7,845,439
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.3966, Jaccard score = 0.3077
# Iteration 0 fit: [31.4 s]: Recall = 0.3912, Jaccard score = 0.3023, loss = 0.0006, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 1 fit: [30.9 s]: Recall = 0.3920, Jaccard score = 0.3031, loss = 0.0006, gradient norm = 1.0000, eval: [7.6 s]
# Iteration 2 fit: [31.0 s]: Recall = 0.3964, Jaccard score = 0.3075, loss = 0.0005, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 3 fit: [30.9 s]: Recall = 0.3924, Jaccard score = 0.3035, loss = 0.0005, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 4 fit: [30.8 s]: Recall = 0.3941, Jaccard score = 0.3052, loss = 0.0005, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 5 fit: [30.9 s]: Recall = 0.3922, Jaccard score = 0.3032, loss = 0.0004, gradient norm = 1.0000, eval: [7.6 s]
# Iteration 6 fit: [30.9 s]: Recall = 0.3936, Jaccard score = 0.3047, loss = 0.0004, gradient norm = 1.0000, eval: [7.8 s]
# Iteration 7 fit: [32.0 s]: Recall = 0.3919, Jaccard score = 0.3030, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 8 fit: [30.9 s]: Recall = 0.3925, Jaccard score = 0.3036, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 9 fit: [31.1 s]: Recall = 0.3943, Jaccard score = 0.3054, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 10 fit: [31.0 s]: Recall = 0.3919, Jaccard score = 0.3030, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 11 fit: [30.9 s]: Recall = 0.3956, Jaccard score = 0.3067, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 12 fit: [31.0 s]: Recall = 0.3900, Jaccard score = 0.3011, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 13 fit: [30.9 s]: Recall = 0.3886, Jaccard score = 0.2997, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 14 fit: [31.0 s]: Recall = 0.3903, Jaccard score = 0.3014, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 15 fit: [31.0 s]: Recall = 0.3898, Jaccard score = 0.3008, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 16 fit: [31.0 s]: Recall = 0.3903, Jaccard score = 0.3014, loss = 0.0003, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 17 fit: [31.0 s]: Recall = 0.3910, Jaccard score = 0.3021, loss = 0.0003, gradient norm = 1.0000, eval: [7.6 s]
# Iteration 18 fit: [31.0 s]: Recall = 0.3902, Jaccard score = 0.3013, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 19 fit: [30.9 s]: Recall = 0.3918, Jaccard score = 0.3029, loss = 0.0003, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 20 fit: [30.9 s]: Recall = 0.3924, Jaccard score = 0.3035, loss = 0.0003, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 21 fit: [30.9 s]: Recall = 0.3855, Jaccard score = 0.2966, loss = 0.0004, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 22 fit: [31.0 s]: Recall = 0.3925, Jaccard score = 0.3036, loss = 0.0002, gradient norm = 1.0000, eval: [7.6 s]
# Iteration 23 fit: [31.1 s]: Recall = 0.3860, Jaccard score = 0.2971, loss = 0.0003, gradient norm = 1.0000, eval: [7.7 s]
# Iteration 24 fit: [30.9 s]: Recall = 0.3897, Jaccard score = 0.3007, loss = 0.0003, gradient norm = 1.0000, eval: [7.6 s]
