--nn_model: GMF
--is_tag: "1"
--eval_recall: "1"
--topk: "3"
--big_tag: "0"
--epochs: "300"
--num_factors: "94"
--early_stopping: "145"
--test_dataset: "1"
--percentage: "0.1"
--dataset_name_prepend: "cold_0.1_"

# Launched by terminal.
# GMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.1_', early_stopping=145, epochs=300, eval_recall=1, is_tag=1, layers='[64,32,16,8]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='GMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.1, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_GMF_94_[64,32,16,8]_1566560517.h5
--weights_path: Pretrain/_GMF_94_[64,32,16,8]_1566560517.h5
# Load data done [1.8 s]. #user=20000, #item=2000, #train=147903, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1094)         0           flatten_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# user_feature_item_latent1 (Dens (None, 94)           102930      concatenate_1[0][0]              
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_feature_item_latent_bn1 (B (None, 94)           376         user_feature_item_latent1[0][0]  
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# leaky_re_lu_1 (LeakyReLU)       (None, 94)           0           user_feature_item_latent_bn1[0][0
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           leaky_re_lu_1[0][0]              
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            95          multiply_1[0][0]                 
# ==================================================================================================
# Total params: 2,171,401
# Trainable params: 2,171,213
# Non-trainable params: 188
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0280, Jaccard score = 0.0206
# Iteration 0 fit: [20.8 s]: Recall = 0.1773, Jaccard score = 0.1468, loss = 0.4908, gradient norm = 0.2966, eval: [10.5 s]
# Iteration 1 fit: [17.0 s]: Recall = 0.1933, Jaccard score = 0.1623, loss = 0.3857, gradient norm = 0.2533, eval: [8.5 s]
# Iteration 2 fit: [17.0 s]: Recall = 0.2029, Jaccard score = 0.1718, loss = 0.3581, gradient norm = 0.2568, eval: [8.6 s]
# Iteration 3 fit: [17.7 s]: Recall = 0.1997, Jaccard score = 0.1686, loss = 0.3344, gradient norm = 0.2679, eval: [8.7 s]
# Iteration 4 fit: [17.2 s]: Recall = 0.1970, Jaccard score = 0.1659, loss = 0.3122, gradient norm = 0.2797, eval: [10.6 s]
# Iteration 5 fit: [18.3 s]: Recall = 0.1935, Jaccard score = 0.1625, loss = 0.2899, gradient norm = 0.2893, eval: [8.5 s]
# Iteration 6 fit: [17.2 s]: Recall = 0.1874, Jaccard score = 0.1565, loss = 0.2683, gradient norm = 0.2965, eval: [8.5 s]
# Iteration 7 fit: [17.8 s]: Recall = 0.1870, Jaccard score = 0.1562, loss = 0.2474, gradient norm = 0.2995, eval: [8.5 s]
# Iteration 8 fit: [17.3 s]: Recall = 0.1833, Jaccard score = 0.1526, loss = 0.2277, gradient norm = 0.3006, eval: [8.5 s]
# Iteration 9 fit: [17.4 s]: Recall = 0.1800, Jaccard score = 0.1495, loss = 0.2089, gradient norm = 0.2995, eval: [8.4 s]
# Iteration 10 fit: [16.9 s]: Recall = 0.1771, Jaccard score = 0.1467, loss = 0.1921, gradient norm = 0.2967, eval: [8.5 s]
# Iteration 11 fit: [17.1 s]: Recall = 0.1725, Jaccard score = 0.1424, loss = 0.1760, gradient norm = 0.2939, eval: [8.7 s]
# Iteration 12 fit: [17.7 s]: Recall = 0.1732, Jaccard score = 0.1430, loss = 0.1618, gradient norm = 0.2889, eval: [8.5 s]
# Iteration 13 fit: [18.7 s]: Recall = 0.1726, Jaccard score = 0.1425, loss = 0.1481, gradient norm = 0.2832, eval: [9.9 s]
# Iteration 14 fit: [16.9 s]: Recall = 0.1671, Jaccard score = 0.1372, loss = 0.1368, gradient norm = 0.2780, eval: [8.5 s]
# Iteration 15 fit: [17.4 s]: Recall = 0.1690, Jaccard score = 0.1390, loss = 0.1261, gradient norm = 0.2712, eval: [10.6 s]
# Iteration 16 fit: [19.1 s]: Recall = 0.1650, Jaccard score = 0.1353, loss = 0.1163, gradient norm = 0.2657, eval: [8.6 s]
# Iteration 17 fit: [17.3 s]: Recall = 0.1657, Jaccard score = 0.1359, loss = 0.1086, gradient norm = 0.2602, eval: [8.6 s]
# Iteration 18 fit: [17.4 s]: Recall = 0.1702, Jaccard score = 0.1402, loss = 0.1002, gradient norm = 0.2520, eval: [8.5 s]
# Iteration 19 fit: [17.0 s]: Recall = 0.1677, Jaccard score = 0.1378, loss = 0.0926, gradient norm = 0.2452, eval: [9.3 s]
# Iteration 20 fit: [18.9 s]: Recall = 0.1694, Jaccard score = 0.1395, loss = 0.0872, gradient norm = 0.2400, eval: [8.5 s]
# Iteration 21 fit: [17.3 s]: Recall = 0.1675, Jaccard score = 0.1376, loss = 0.0820, gradient norm = 0.2332, eval: [8.5 s]
# Iteration 22 fit: [20.1 s]: Recall = 0.1661, Jaccard score = 0.1364, loss = 0.0765, gradient norm = 0.2270, eval: [10.5 s]
# Iteration 23 fit: [17.6 s]: Recall = 0.1657, Jaccard score = 0.1360, loss = 0.0721, gradient norm = 0.2220, eval: [8.8 s]
# Iteration 24 fit: [18.1 s]: Recall = 0.1684, Jaccard score = 0.1384, loss = 0.0684, gradient norm = 0.2163, eval: [8.5 s]
# Iteration 25 fit: [17.0 s]: Recall = 0.1635, Jaccard score = 0.1340, loss = 0.0646, gradient norm = 0.2097, eval: [8.6 s]
# Iteration 26 fit: [17.1 s]: Recall = 0.1659, Jaccard score = 0.1361, loss = 0.0613, gradient norm = 0.2044, eval: [8.5 s]
# Iteration 27 fit: [17.6 s]: Recall = 0.1678, Jaccard score = 0.1380, loss = 0.0585, gradient norm = 0.1996, eval: [8.5 s]
# Iteration 28 fit: [17.5 s]: Recall = 0.1656, Jaccard score = 0.1359, loss = 0.0560, gradient norm = 0.1956, eval: [8.5 s]
# Iteration 29 fit: [17.0 s]: Recall = 0.1671, Jaccard score = 0.1372, loss = 0.0523, gradient norm = 0.1883, eval: [8.7 s]
# Iteration 30 fit: [17.4 s]: Recall = 0.1653, Jaccard score = 0.1356, loss = 0.0498, gradient norm = 0.1842, eval: [8.6 s]
# Iteration 31 fit: [17.5 s]: Recall = 0.1684, Jaccard score = 0.1385, loss = 0.0478, gradient norm = 0.1795, eval: [8.6 s]
# Iteration 32 fit: [17.3 s]: Recall = 0.1649, Jaccard score = 0.1352, loss = 0.0463, gradient norm = 0.1752, eval: [8.5 s]
# Iteration 33 fit: [17.1 s]: Recall = 0.1665, Jaccard score = 0.1367, loss = 0.0435, gradient norm = 0.1693, eval: [8.6 s]
# Iteration 34 fit: [17.4 s]: Recall = 0.1680, Jaccard score = 0.1381, loss = 0.0421, gradient norm = 0.1657, eval: [8.5 s]
# Iteration 35 fit: [17.2 s]: Recall = 0.1696, Jaccard score = 0.1396, loss = 0.0409, gradient norm = 0.1626, eval: [8.6 s]
# Iteration 36 fit: [17.6 s]: Recall = 0.1685, Jaccard score = 0.1386, loss = 0.0392, gradient norm = 0.1587, eval: [8.6 s]
# Iteration 37 fit: [17.4 s]: Recall = 0.1723, Jaccard score = 0.1422, loss = 0.0373, gradient norm = 0.1541, eval: [8.6 s]
# Iteration 38 fit: [17.5 s]: Recall = 0.1678, Jaccard score = 0.1380, loss = 0.0364, gradient norm = 0.1517, eval: [8.5 s]
# Iteration 39 fit: [17.1 s]: Recall = 0.1673, Jaccard score = 0.1375, loss = 0.0353, gradient norm = 0.1483, eval: [8.5 s]
# Iteration 40 fit: [17.1 s]: Recall = 0.1685, Jaccard score = 0.1386, loss = 0.0339, gradient norm = 0.1438, eval: [8.6 s]
# Iteration 41 fit: [17.7 s]: Recall = 0.1676, Jaccard score = 0.1377, loss = 0.0323, gradient norm = 0.1398, eval: [8.6 s]
# Iteration 42 fit: [18.6 s]: Recall = 0.1661, Jaccard score = 0.1364, loss = 0.0311, gradient norm = 0.1370, eval: [10.5 s]
# Iteration 43 fit: [19.8 s]: Recall = 0.1689, Jaccard score = 0.1389, loss = 0.0306, gradient norm = 0.1345, eval: [9.3 s]
# Iteration 44 fit: [17.6 s]: Recall = 0.1698, Jaccard score = 0.1398, loss = 0.0297, gradient norm = 0.1315, eval: [8.6 s]
# Iteration 45 fit: [18.7 s]: Recall = 0.1680, Jaccard score = 0.1381, loss = 0.0282, gradient norm = 0.1274, eval: [10.6 s]
# Iteration 46 fit: [18.9 s]: Recall = 0.1671, Jaccard score = 0.1372, loss = 0.0274, gradient norm = 0.1254, eval: [10.8 s]
# Iteration 47 fit: [18.7 s]: Recall = 0.1671, Jaccard score = 0.1372, loss = 0.0266, gradient norm = 0.1226, eval: [8.9 s]
# Iteration 48 fit: [17.9 s]: Recall = 0.1677, Jaccard score = 0.1378, loss = 0.0255, gradient norm = 0.1192, eval: [9.5 s]
# Iteration 49 fit: [19.3 s]: Recall = 0.1679, Jaccard score = 0.1380, loss = 0.0251, gradient norm = 0.1157, eval: [8.6 s]
# Iteration 50 fit: [18.2 s]: Recall = 0.1691, Jaccard score = 0.1391, loss = 0.0249, gradient norm = 0.1155, eval: [8.8 s]
# Iteration 51 fit: [17.8 s]: Recall = 0.1673, Jaccard score = 0.1374, loss = 0.0240, gradient norm = 0.1130, eval: [8.7 s]
# Iteration 52 fit: [20.3 s]: Recall = 0.1671, Jaccard score = 0.1372, loss = 0.0230, gradient norm = 0.1097, eval: [8.9 s]
# Iteration 53 fit: [20.3 s]: Recall = 0.1710, Jaccard score = 0.1409, loss = 0.0225, gradient norm = 0.1072, eval: [11.7 s]
# Iteration 54 fit: [19.7 s]: Recall = 0.1696, Jaccard score = 0.1396, loss = 0.0219, gradient norm = 0.1053, eval: [8.6 s]
# Iteration 55 fit: [17.6 s]: Recall = 0.1684, Jaccard score = 0.1384, loss = 0.0213, gradient norm = 0.1030, eval: [10.5 s]
# Iteration 56 fit: [20.1 s]: Recall = 0.1727, Jaccard score = 0.1425, loss = 0.0209, gradient norm = 0.1011, eval: [9.9 s]
# Iteration 57 fit: [19.5 s]: Recall = 0.1664, Jaccard score = 0.1366, loss = 0.0201, gradient norm = 0.0984, eval: [10.8 s]
# Iteration 58 fit: [20.7 s]: Recall = 0.1682, Jaccard score = 0.1383, loss = 0.0202, gradient norm = 0.0981, eval: [10.8 s]
# Iteration 59 fit: [20.2 s]: Recall = 0.1689, Jaccard score = 0.1389, loss = 0.0193, gradient norm = 0.0948, eval: [8.9 s]
# Iteration 60 fit: [20.3 s]: Recall = 0.1700, Jaccard score = 0.1399, loss = 0.0198, gradient norm = 0.0956, eval: [9.4 s]
# Iteration 61 fit: [17.1 s]: Recall = 0.1680, Jaccard score = 0.1381, loss = 0.0188, gradient norm = 0.0922, eval: [8.6 s]
# Iteration 62 fit: [17.9 s]: Recall = 0.1689, Jaccard score = 0.1390, loss = 0.0180, gradient norm = 0.0896, eval: [8.5 s]
# Iteration 63 fit: [17.7 s]: Recall = 0.1696, Jaccard score = 0.1396, loss = 0.0181, gradient norm = 0.0892, eval: [10.2 s]
# Iteration 64 fit: [18.4 s]: Recall = 0.1730, Jaccard score = 0.1428, loss = 0.0176, gradient norm = 0.0876, eval: [8.7 s]
# Iteration 65 fit: [17.6 s]: Recall = 0.1725, Jaccard score = 0.1424, loss = 0.0171, gradient norm = 0.0859, eval: [8.6 s]
# Iteration 66 fit: [17.5 s]: Recall = 0.1731, Jaccard score = 0.1429, loss = 0.0162, gradient norm = 0.0824, eval: [8.5 s]
# Iteration 67 fit: [17.2 s]: Recall = 0.1728, Jaccard score = 0.1426, loss = 0.0165, gradient norm = 0.0832, eval: [8.7 s]
# Iteration 68 fit: [17.2 s]: Recall = 0.1757, Jaccard score = 0.1453, loss = 0.0164, gradient norm = 0.0829, eval: [8.7 s]
# Iteration 69 fit: [17.5 s]: Recall = 0.1742, Jaccard score = 0.1439, loss = 0.0159, gradient norm = 0.0814, eval: [8.6 s]
# Iteration 70 fit: [17.5 s]: Recall = 0.1703, Jaccard score = 0.1402, loss = 0.0154, gradient norm = 0.0793, eval: [8.5 s]
# Iteration 71 fit: [17.3 s]: Recall = 0.1721, Jaccard score = 0.1419, loss = 0.0153, gradient norm = 0.0792, eval: [8.5 s]
# Iteration 72 fit: [17.8 s]: Recall = 0.1725, Jaccard score = 0.1424, loss = 0.0151, gradient norm = 0.0780, eval: [8.6 s]
# Iteration 73 fit: [17.8 s]: Recall = 0.1733, Jaccard score = 0.1431, loss = 0.0147, gradient norm = 0.0771, eval: [8.5 s]
# Iteration 74 fit: [17.5 s]: Recall = 0.1716, Jaccard score = 0.1415, loss = 0.0149, gradient norm = 0.0776, eval: [8.5 s]
# Iteration 75 fit: [17.5 s]: Recall = 0.1719, Jaccard score = 0.1418, loss = 0.0142, gradient norm = 0.0758, eval: [8.6 s]
# Iteration 76 fit: [17.5 s]: Recall = 0.1737, Jaccard score = 0.1434, loss = 0.0141, gradient norm = 0.0746, eval: [8.5 s]
# Iteration 77 fit: [17.5 s]: Recall = 0.1735, Jaccard score = 0.1433, loss = 0.0140, gradient norm = 0.0745, eval: [8.5 s]
# Iteration 78 fit: [17.2 s]: Recall = 0.1744, Jaccard score = 0.1442, loss = 0.0140, gradient norm = 0.0744, eval: [8.5 s]
# Iteration 79 fit: [17.2 s]: Recall = 0.1764, Jaccard score = 0.1461, loss = 0.0137, gradient norm = 0.0731, eval: [8.5 s]
# Iteration 80 fit: [17.6 s]: Recall = 0.1753, Jaccard score = 0.1450, loss = 0.0140, gradient norm = 0.0746, eval: [8.5 s]
# Iteration 81 fit: [17.6 s]: Recall = 0.1734, Jaccard score = 0.1431, loss = 0.0135, gradient norm = 0.0722, eval: [8.6 s]
# Iteration 82 fit: [17.6 s]: Recall = 0.1761, Jaccard score = 0.1458, loss = 0.0134, gradient norm = 0.0721, eval: [8.5 s]
# Iteration 83 fit: [17.6 s]: Recall = 0.1751, Jaccard score = 0.1448, loss = 0.0131, gradient norm = 0.0712, eval: [8.5 s]
# Iteration 84 fit: [17.6 s]: Recall = 0.1762, Jaccard score = 0.1458, loss = 0.0125, gradient norm = 0.0700, eval: [8.5 s]
# Iteration 85 fit: [17.7 s]: Recall = 0.1743, Jaccard score = 0.1441, loss = 0.0129, gradient norm = 0.0706, eval: [8.5 s]
# Iteration 86 fit: [17.6 s]: Recall = 0.1759, Jaccard score = 0.1456, loss = 0.0127, gradient norm = 0.0698, eval: [8.5 s]
# Iteration 87 fit: [17.5 s]: Recall = 0.1756, Jaccard score = 0.1453, loss = 0.0128, gradient norm = 0.0708, eval: [8.6 s]
# Iteration 88 fit: [17.5 s]: Recall = 0.1751, Jaccard score = 0.1448, loss = 0.0121, gradient norm = 0.0688, eval: [8.6 s]
# Iteration 89 fit: [17.2 s]: Recall = 0.1764, Jaccard score = 0.1460, loss = 0.0123, gradient norm = 0.0691, eval: [8.6 s]
# Iteration 90 fit: [17.5 s]: Recall = 0.1753, Jaccard score = 0.1450, loss = 0.0119, gradient norm = 0.0681, eval: [8.5 s]
# Iteration 91 fit: [17.6 s]: Recall = 0.1722, Jaccard score = 0.1421, loss = 0.0120, gradient norm = 0.0684, eval: [8.6 s]
# Iteration 92 fit: [17.5 s]: Recall = 0.1781, Jaccard score = 0.1476, loss = 0.0120, gradient norm = 0.0688, eval: [8.5 s]
# Iteration 93 fit: [17.6 s]: Recall = 0.1742, Jaccard score = 0.1440, loss = 0.0115, gradient norm = 0.0671, eval: [8.5 s]
# Iteration 94 fit: [17.6 s]: Recall = 0.1767, Jaccard score = 0.1463, loss = 0.0116, gradient norm = 0.0680, eval: [8.5 s]
# Iteration 95 fit: [17.6 s]: Recall = 0.1751, Jaccard score = 0.1448, loss = 0.0115, gradient norm = 0.0674, eval: [8.5 s]
# Model test performed 
# Recall score: 0.05711775043936731     Jaccard score: 0.043287984016744364