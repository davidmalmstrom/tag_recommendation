--nn_model: GMF
--is_tag: "1"
--eval_recall: "1"
--topk: "10"
--big_tag: "0"
--epochs: "600"
--lr: "0.01"
--num_factors: "94"
--reg_mf: "0"
--early_stopping: "600"
--test_dataset: "1"

# Comment: med dropout
# Launched by terminal.
# GMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[64,32,16,8]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='GMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0.0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_GMF_94_[64,32,16,8]_1569327651.h5
--weights_path: Pretrain/_GMF_94_[64,32,16,8]_1569327651.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 94)           0           flatten_1[0][0]                  
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 94)           0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            95          multiply_1[0][0]                 
# ==================================================================================================
# Total params: 2,068,095
# Trainable params: 2,068,095
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0043, Jaccard score = 0.0013
# Iteration 0 fit: [11.3 s]: Recall = 0.00434, Jaccard score = 0.0013, loss = 0.545180, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 1 fit: [10.8 s]: Recall = 0.00388, Jaccard score = 0.0012, loss = 0.501557, gradient norm = 1.0000, eval: [19.2 s]
# Iteration 2 fit: [10.8 s]: Recall = 0.00514, Jaccard score = 0.0016, loss = 0.501593, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 3 fit: [10.8 s]: Recall = 0.00571, Jaccard score = 0.0017, loss = 0.501509, gradient norm = 1.0000, eval: [19.2 s]
# Iteration 4 fit: [10.8 s]: Recall = 0.00400, Jaccard score = 0.0012, loss = 0.501536, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 5 fit: [10.8 s]: Recall = 0.00640, Jaccard score = 0.0020, loss = 0.501440, gradient norm = 1.0000, eval: [19.2 s]


# Launched by terminal.
# GMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[64,32,16,8]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='GMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0.0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_GMF_94_[64,32,16,8]_1569327866.h5
--weights_path: Pretrain/_GMF_94_[64,32,16,8]_1569327866.h5
# Load data done [1.8 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 94)           0           flatten_1[0][0]                  
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 94)           0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            95          multiply_1[0][0]                 
# ==================================================================================================
# Total params: 2,068,095
# Trainable params: 2,068,095
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0057, Jaccard score = 0.0017
# Iteration 0 fit: [11.2 s]: Recall = 0.00537, Jaccard score = 0.0016, loss = 0.539683, gradient norm = 1.0000, eval: [18.8 s]
# Iteration 1 fit: [10.7 s]: Recall = 0.00708, Jaccard score = 0.0022, loss = 0.501105, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 2 fit: [10.7 s]: Recall = 0.00537, Jaccard score = 0.0016, loss = 0.500887, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 3 fit: [10.7 s]: Recall = 0.00605, Jaccard score = 0.0018, loss = 0.500192, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 4 fit: [10.7 s]: Recall = 0.00617, Jaccard score = 0.0019, loss = 0.498722, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 5 fit: [10.7 s]: Recall = 0.00708, Jaccard score = 0.0022, loss = 0.495768, gradient norm = 1.0000, eval: [19.2 s]


# Launched by terminal.
# GMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[64,32,16,8]', learner='adam', lr=0.01, mf_pretrain='', mlp_pretrain='', nn_model='GMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0.0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_GMF_94_[64,32,16,8]_1569328104.h5
--weights_path: Pretrain/_GMF_94_[64,32,16,8]_1569328104.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 94)           0           flatten_1[0][0]                  
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 94)           0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            95          multiply_1[0][0]                 
# ==================================================================================================
# Total params: 2,068,095
# Trainable params: 2,068,095
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0064, Jaccard score = 0.0020
# Iteration 0 fit: [11.3 s]: Recall = 0.00651, Jaccard score = 0.0020, loss = 0.511609, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 1 fit: [10.8 s]: Recall = 0.00754, Jaccard score = 0.0023, loss = 0.508444, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 2 fit: [10.7 s]: Recall = 0.03496, Jaccard score = 0.0108, loss = 0.495298, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 3 fit: [10.8 s]: Recall = 0.07288, Jaccard score = 0.0227, loss = 0.424967, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 4 fit: [10.8 s]: Recall = 0.10669, Jaccard score = 0.0336, loss = 0.341736, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 5 fit: [10.8 s]: Recall = 0.13777, Jaccard score = 0.0438, loss = 0.272979, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 6 fit: [10.7 s]: Recall = 0.16107, Jaccard score = 0.0516, loss = 0.222358, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 7 fit: [10.8 s]: Recall = 0.17432, Jaccard score = 0.0560, loss = 0.187765, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 8 fit: [10.7 s]: Recall = 0.19328, Jaccard score = 0.0625, loss = 0.162436, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 9 fit: [10.8 s]: Recall = 0.21305, Jaccard score = 0.0694, loss = 0.145796, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 10 fit: [10.8 s]: Recall = 0.22058, Jaccard score = 0.0720, loss = 0.133376, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 11 fit: [10.7 s]: Recall = 0.22904, Jaccard score = 0.0750, loss = 0.123657, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 12 fit: [10.8 s]: Recall = 0.24012, Jaccard score = 0.0789, loss = 0.118079, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 13 fit: [10.8 s]: Recall = 0.24857, Jaccard score = 0.0819, loss = 0.111310, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 14 fit: [10.8 s]: Recall = 0.25314, Jaccard score = 0.0835, loss = 0.105644, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 15 fit: [10.8 s]: Recall = 0.24674, Jaccard score = 0.0812, loss = 0.103095, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 16 fit: [10.7 s]: Recall = 0.25782, Jaccard score = 0.0852, loss = 0.101115, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 17 fit: [10.8 s]: Recall = 0.26559, Jaccard score = 0.0880, loss = 0.097202, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 18 fit: [10.8 s]: Recall = 0.27199, Jaccard score = 0.0903, loss = 0.094862, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 19 fit: [10.9 s]: Recall = 0.27542, Jaccard score = 0.0915, loss = 0.092354, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 20 fit: [10.8 s]: Recall = 0.27827, Jaccard score = 0.0926, loss = 0.092233, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 21 fit: [10.7 s]: Recall = 0.27302, Jaccard score = 0.0907, loss = 0.090521, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 22 fit: [10.8 s]: Recall = 0.28170, Jaccard score = 0.0938, loss = 0.088454, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 23 fit: [10.8 s]: Recall = 0.27919, Jaccard score = 0.0929, loss = 0.087685, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 24 fit: [10.7 s]: Recall = 0.27519, Jaccard score = 0.0914, loss = 0.087292, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 25 fit: [10.8 s]: Recall = 0.28775, Jaccard score = 0.0960, loss = 0.086659, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 26 fit: [10.8 s]: Recall = 0.27804, Jaccard score = 0.0925, loss = 0.084791, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 27 fit: [10.8 s]: Recall = 0.28398, Jaccard score = 0.0946, loss = 0.085875, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 28 fit: [10.8 s]: Recall = 0.29175, Jaccard score = 0.0975, loss = 0.084486, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 29 fit: [10.8 s]: Recall = 0.29826, Jaccard score = 0.0999, loss = 0.083703, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 30 fit: [10.8 s]: Recall = 0.29255, Jaccard score = 0.0978, loss = 0.083506, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 31 fit: [10.7 s]: Recall = 0.29712, Jaccard score = 0.0995, loss = 0.083065, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 32 fit: [10.8 s]: Recall = 0.29484, Jaccard score = 0.0986, loss = 0.084004, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 33 fit: [10.8 s]: Recall = 0.29484, Jaccard score = 0.0986, loss = 0.083724, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 34 fit: [10.7 s]: Recall = 0.29609, Jaccard score = 0.0991, loss = 0.083212, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 35 fit: [10.7 s]: Recall = 0.28684, Jaccard score = 0.0957, loss = 0.082268, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 36 fit: [10.7 s]: Recall = 0.29221, Jaccard score = 0.0976, loss = 0.082513, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 37 fit: [10.7 s]: Recall = 0.28558, Jaccard score = 0.0952, loss = 0.083381, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 38 fit: [10.7 s]: Recall = 0.29758, Jaccard score = 0.0996, loss = 0.083116, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 39 fit: [10.8 s]: Recall = 0.29461, Jaccard score = 0.0985, loss = 0.084069, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 40 fit: [10.8 s]: Recall = 0.29507, Jaccard score = 0.0987, loss = 0.081774, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 41 fit: [10.8 s]: Recall = 0.29701, Jaccard score = 0.0994, loss = 0.082973, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 42 fit: [10.8 s]: Recall = 0.29849, Jaccard score = 0.1000, loss = 0.082769, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 43 fit: [10.7 s]: Recall = 0.30443, Jaccard score = 0.1022, loss = 0.083058, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 44 fit: [10.8 s]: Recall = 0.29621, Jaccard score = 0.0991, loss = 0.083952, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 45 fit: [10.8 s]: Recall = 0.30672, Jaccard score = 0.1030, loss = 0.083761, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 46 fit: [10.8 s]: Recall = 0.30386, Jaccard score = 0.1019, loss = 0.084296, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 47 fit: [10.8 s]: Recall = 0.30957, Jaccard score = 0.1041, loss = 0.083654, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 48 fit: [10.7 s]: Recall = 0.30683, Jaccard score = 0.1030, loss = 0.083728, gradient norm = 1.0000, eval: [19.1 s]
# Iteration 49 fit: [10.8 s]: Recall = 0.30112, Jaccard score = 0.1009, loss = 0.083202, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 50 fit: [10.8 s]: Recall = 0.30009, Jaccard score = 0.1005, loss = 0.084734, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 51 fit: [10.7 s]: Recall = 0.30957, Jaccard score = 0.1041, loss = 0.084799, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 52 fit: [10.7 s]: Recall = 0.30969, Jaccard score = 0.1041, loss = 0.083825, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 53 fit: [10.8 s]: Recall = 0.31300, Jaccard score = 0.1053, loss = 0.085743, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 54 fit: [10.7 s]: Recall = 0.29689, Jaccard score = 0.0994, loss = 0.084933, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 55 fit: [10.7 s]: Recall = 0.30089, Jaccard score = 0.1008, loss = 0.083899, gradient norm = 1.0000, eval: [18.9 s]
# Iteration 56 fit: [10.7 s]: Recall = 0.30352, Jaccard score = 0.1018, loss = 0.084500, gradient norm = 1.0000, eval: [19.0 s]
# Iteration 57 fit: [10.8 s]: Recall = 0.30226, Jaccard score = 0.1013, loss = 0.085079, gradient norm = 1.0000, eval: [19.0 s]
