--nn_model: MLP
--is_tag: "1"
--eval_recall: "1"
--topk: "10"
--big_tag: "0"
--epochs: "600"
--early_stopping: "150"
--lr: "0.002"
--layers: "[512,750,350,96]"
--reg_layers: "[0,0,0,0]"
--test_dataset: "1"


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569393806.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569393806.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# batch_normalization_1 (BatchNor (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           batch_normalization_1[0][0]      
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# batch_normalization_2 (BatchNor (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  batch_normalization_2[0][0]      
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# batch_normalization_3 (BatchNor (None, 750)          3000        layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      batch_normalization_3[0][0]      
# __________________________________________________________________________________________________
# batch_normalization_4 (BatchNor (None, 350)          1400        layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       batch_normalization_4[0][0]      
# __________________________________________________________________________________________________
# batch_normalization_5 (BatchNor (None, 96)           384         layer3[0][0]                     
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 96)           0           batch_normalization_5[0][0]      
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_1[0][0]                  
# ==================================================================================================
# Total params: 7,070,225
# Trainable params: 7,066,809
# Non-trainable params: 3,416
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0051, Jaccard score = 0.0016
# Iteration 0 fit: [39.8 s]: Recall = 0.11138, Jaccard score = 0.0351, loss = 0.432401, gradient norm = 1.0000, eval: [57.5 s]
# Iteration 1 fit: [38.7 s]: Recall = 0.13891, Jaccard score = 0.0442, loss = 0.379856, gradient norm = 1.0000, eval: [57.4 s]
# Iteration 2 fit: [38.6 s]: Recall = 0.16130, Jaccard score = 0.0516, loss = 0.347796, gradient norm = 1.0000, eval: [57.7 s]
# Iteration 3 fit: [38.6 s]: Recall = 0.17009, Jaccard score = 0.0546, loss = 0.313010, gradient norm = 1.0000, eval: [57.3 s]
# Iteration 4 fit: [38.7 s]: Recall = 0.17501, Jaccard score = 0.0563, loss = 0.274473, gradient norm = 1.0000, eval: [57.7 s]
# Iteration 5 fit: [38.6 s]: Recall = 0.17752, Jaccard score = 0.0571, loss = 0.238305, gradient norm = 1.0000, eval: [57.3 s]
# Iteration 6 fit: [38.5 s]: Recall = 0.18209, Jaccard score = 0.0587, loss = 0.205860, gradient norm = 1.0000, eval: [56.2 s]
# Iteration 7 fit: [38.6 s]: Recall = 0.17775, Jaccard score = 0.0572, loss = 0.180521, gradient norm = 1.0000, eval: [57.6 s]
# Iteration 8 fit: [38.6 s]: Recall = 0.17683, Jaccard score = 0.0569, loss = 0.160468, gradient norm = 1.0000, eval: [56.2 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569394805.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569394805.h5
# Load data done [1.8 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# batch_normalization_1 (BatchNor (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# batch_normalization_2 (BatchNor (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           dropout_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           batch_normalization_2[0][0]      
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# dropout_3 (Dropout)             (None, 750)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      dropout_3[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 350)          0           layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       dropout_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_5 (Dropout)             (None, 96)           0           layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_5[0][0]                  
# ==================================================================================================
# Total params: 7,065,441
# Trainable params: 7,064,417
# Non-trainable params: 1,024
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0055, Jaccard score = 0.0017
# Iteration 0 fit: [35.2 s]: Recall = 0.10235, Jaccard score = 0.0322, loss = 0.438467, gradient norm = 1.0000, eval: [48.5 s]
# Iteration 1 fit: [34.0 s]: Recall = 0.13834, Jaccard score = 0.0440, loss = 0.399260, gradient norm = 1.0000, eval: [49.8 s]
# Iteration 2 fit: [34.0 s]: Recall = 0.16004, Jaccard score = 0.0512, loss = 0.374957, gradient norm = 1.0000, eval: [49.9 s]
# Iteration 3 fit: [34.0 s]: Recall = 0.16690, Jaccard score = 0.0535, loss = 0.356493, gradient norm = 1.0000, eval: [48.3 s]
# Iteration 4 fit: [34.0 s]: Recall = 0.17980, Jaccard score = 0.0579, loss = 0.339343, gradient norm = 1.0000, eval: [49.9 s]
# Iteration 5 fit: [34.0 s]: Recall = 0.18472, Jaccard score = 0.0596, loss = 0.325019, gradient norm = 1.0000, eval: [50.0 s]
# Iteration 6 fit: [34.0 s]: Recall = 0.19168, Jaccard score = 0.0620, loss = 0.310475, gradient norm = 1.0000, eval: [49.9 s]
# Iteration 7 fit: [34.0 s]: Recall = 0.19397, Jaccard score = 0.0628, loss = 0.298675, gradient norm = 1.0000, eval: [49.8 s]
# Iteration 8 fit: [34.0 s]: Recall = 0.20356, Jaccard score = 0.0661, loss = 0.287115, gradient norm = 1.0000, eval: [49.9 s]
# Iteration 9 fit: [34.0 s]: Recall = 0.20516, Jaccard score = 0.0666, loss = 0.275860, gradient norm = 1.0000, eval: [50.0 s]
# Iteration 10 fit: [34.0 s]: Recall = 0.20813, Jaccard score = 0.0677, loss = 0.265024, gradient norm = 1.0000, eval: [50.0 s]
# Iteration 11 fit: [34.0 s]: Recall = 0.21236, Jaccard score = 0.0691, loss = 0.255424, gradient norm = 1.0000, eval: [49.2 s]
# Iteration 12 fit: [34.0 s]: Recall = 0.21636, Jaccard score = 0.0705, loss = 0.246575, gradient norm = 1.0000, eval: [50.0 s]
# Iteration 13 fit: [34.0 s]: Recall = 0.22081, Jaccard score = 0.0721, loss = 0.238330, gradient norm = 1.0000, eval: [49.9 s]
# Iteration 14 fit: [34.0 s]: Recall = 0.22218, Jaccard score = 0.0726, loss = 0.228842, gradient norm = 1.0000, eval: [50.1 s]
# Iteration 15 fit: [34.0 s]: Recall = 0.22584, Jaccard score = 0.0738, loss = 0.222661, gradient norm = 1.0000, eval: [49.8 s]
# Iteration 16 fit: [34.0 s]: Recall = 0.22595, Jaccard score = 0.0739, loss = 0.213506, gradient norm = 1.0000, eval: [49.8 s]
# Iteration 17 fit: [34.0 s]: Recall = 0.23281, Jaccard score = 0.0763, loss = 0.207413, gradient norm = 1.0000, eval: [49.9 s]
# Iteration 18 fit: [34.0 s]: Recall = 0.23326, Jaccard score = 0.0764, loss = 0.200922, gradient norm = 1.0000, eval: [50.1 s]
# Iteration 19 fit: [34.0 s]: Recall = 0.23075, Jaccard score = 0.0756, loss = 0.194698, gradient norm = 1.0000, eval: [50.1 s]
# Iteration 20 fit: [33.9 s]: Recall = 0.23052, Jaccard score = 0.0755, loss = 0.188839, gradient norm = 1.0000, eval: [50.2 s]
# Iteration 21 fit: [34.0 s]: Recall = 0.23795, Jaccard score = 0.0781, loss = 0.183306, gradient norm = 1.0000, eval: [50.2 s]
# Iteration 22 fit: [34.1 s]: Recall = 0.23852, Jaccard score = 0.0783, loss = 0.178036, gradient norm = 1.0000, eval: [48.4 s]
# Iteration 23 fit: [34.1 s]: Recall = 0.23247, Jaccard score = 0.0762, loss = 0.173394, gradient norm = 1.0000, eval: [50.1 s]
# Iteration 24 fit: [34.0 s]: Recall = 0.23978, Jaccard score = 0.0787, loss = 0.168323, gradient norm = 1.0000, eval: [49.8 s]
# Iteration 25 fit: [34.0 s]: Recall = 0.23429, Jaccard score = 0.0768, loss = 0.163224, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 26 fit: [34.0 s]: Recall = 0.23692, Jaccard score = 0.0777, loss = 0.159190, gradient norm = 1.0000, eval: [49.9 s]

# Ã„ndrar lr

# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.01, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569397193.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569397193.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# batch_normalization_1 (BatchNor (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# batch_normalization_2 (BatchNor (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           dropout_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           batch_normalization_2[0][0]      
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# dropout_3 (Dropout)             (None, 750)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      dropout_3[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 350)          0           layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       dropout_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_5 (Dropout)             (None, 96)           0           layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_5[0][0]                  
# ==================================================================================================
# Total params: 7,065,441
# Trainable params: 7,064,417
# Non-trainable params: 1,024
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0057, Jaccard score = 0.0017
# Iteration 0 fit: [36.2 s]: Recall = 0.11024, Jaccard score = 0.0347, loss = 0.439672, gradient norm = 1.0000, eval: [48.9 s]
# Iteration 1 fit: [33.7 s]: Recall = 0.13731, Jaccard score = 0.0436, loss = 0.407782, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 2 fit: [33.7 s]: Recall = 0.14154, Jaccard score = 0.0450, loss = 0.389619, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 3 fit: [34.2 s]: Recall = 0.14793, Jaccard score = 0.0472, loss = 0.376929, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 4 fit: [33.7 s]: Recall = 0.16335, Jaccard score = 0.0523, loss = 0.365204, gradient norm = 1.0000, eval: [50.4 s]
# Iteration 5 fit: [34.1 s]: Recall = 0.16735, Jaccard score = 0.0537, loss = 0.359240, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 6 fit: [33.9 s]: Recall = 0.16461, Jaccard score = 0.0528, loss = 0.353347, gradient norm = 1.0000, eval: [50.4 s]
# Iteration 7 fit: [34.2 s]: Recall = 0.17181, Jaccard score = 0.0552, loss = 0.339251, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 8 fit: [33.7 s]: Recall = 0.16827, Jaccard score = 0.0540, loss = 0.338648, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 9 fit: [34.1 s]: Recall = 0.17409, Jaccard score = 0.0560, loss = 0.338447, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 10 fit: [33.9 s]: Recall = 0.17066, Jaccard score = 0.0548, loss = 0.342171, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 11 fit: [34.1 s]: Recall = 0.15753, Jaccard score = 0.0504, loss = 0.360501, gradient norm = 1.0000, eval: [50.5 s]
# Iteration 12 fit: [34.0 s]: Recall = 0.02159, Jaccard score = 0.0066, loss = 0.361948, gradient norm = 1.0000, eval: [50.4 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.004, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569398671.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569398671.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# bn_user (BatchNormalization)    (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           bn_user[0][0]                    
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# bn_item (BatchNormalization)    (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           dropout_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           bn_item[0][0]                    
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# dropout_3 (Dropout)             (None, 750)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      dropout_3[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 350)          0           layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       dropout_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_5 (Dropout)             (None, 96)           0           layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_5[0][0]                  
# ==================================================================================================
# Total params: 7,065,441
# Trainable params: 7,064,417
# Non-trainable params: 1,024
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0040, Jaccard score = 0.0012
# Iteration 0 fit: [34.8 s]: Recall = 0.10795, Jaccard score = 0.0340, loss = 0.430913, gradient norm = 1.0000, eval: [48.9 s]
# Iteration 1 fit: [33.6 s]: Recall = 0.15684, Jaccard score = 0.0501, loss = 0.387112, gradient norm = 1.0000, eval: [48.8 s]
# Iteration 2 fit: [33.7 s]: Recall = 0.17386, Jaccard score = 0.0559, loss = 0.359493, gradient norm = 1.0000, eval: [49.0 s]
# Iteration 3 fit: [33.7 s]: Recall = 0.18060, Jaccard score = 0.0582, loss = 0.336310, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 4 fit: [33.8 s]: Recall = 0.19408, Jaccard score = 0.0628, loss = 0.317142, gradient norm = 1.0000, eval: [49.0 s]
# Iteration 5 fit: [33.7 s]: Recall = 0.19979, Jaccard score = 0.0648, loss = 0.299700, gradient norm = 1.0000, eval: [48.9 s]
# Iteration 6 fit: [33.7 s]: Recall = 0.20493, Jaccard score = 0.0665, loss = 0.284969, gradient norm = 1.0000, eval: [49.0 s]
# Iteration 7 fit: [33.7 s]: Recall = 0.21293, Jaccard score = 0.0693, loss = 0.269627, gradient norm = 1.0000, eval: [49.0 s]
# Iteration 8 fit: [33.6 s]: Recall = 0.22058, Jaccard score = 0.0720, loss = 0.255481, gradient norm = 1.0000, eval: [48.9 s]
# Iteration 9 fit: [33.7 s]: Recall = 0.22595, Jaccard score = 0.0739, loss = 0.241528, gradient norm = 1.0000, eval: [49.3 s]
# Iteration 10 fit: [35.5 s]: Recall = 0.23384, Jaccard score = 0.0766, loss = 0.229501, gradient norm = 1.0000, eval: [49.3 s]
# Iteration 11 fit: [33.7 s]: Recall = 0.23920, Jaccard score = 0.0785, loss = 0.218616, gradient norm = 1.0000, eval: [49.5 s]
# Iteration 12 fit: [33.7 s]: Recall = 0.23772, Jaccard score = 0.0780, loss = 0.207730, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 13 fit: [33.7 s]: Recall = 0.24263, Jaccard score = 0.0798, loss = 0.198984, gradient norm = 1.0000, eval: [49.3 s]
# Iteration 14 fit: [33.7 s]: Recall = 0.24720, Jaccard score = 0.0814, loss = 0.190515, gradient norm = 1.0000, eval: [48.8 s]
# Iteration 15 fit: [33.7 s]: Recall = 0.24880, Jaccard score = 0.0820, loss = 0.183399, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 16 fit: [33.7 s]: Recall = 0.25451, Jaccard score = 0.0840, loss = 0.176631, gradient norm = 1.0000, eval: [48.9 s]
# Iteration 17 fit: [33.7 s]: Recall = 0.25725, Jaccard score = 0.0850, loss = 0.169590, gradient norm = 1.0000, eval: [49.0 s]
# Iteration 18 fit: [33.7 s]: Recall = 0.25246, Jaccard score = 0.0833, loss = 0.163824, gradient norm = 1.0000, eval: [49.0 s]
# Iteration 19 fit: [33.7 s]: Recall = 0.25851, Jaccard score = 0.0854, loss = 0.158728, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 20 fit: [33.7 s]: Recall = 0.26159, Jaccard score = 0.0865, loss = 0.153030, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 21 fit: [33.7 s]: Recall = 0.26559, Jaccard score = 0.0880, loss = 0.148534, gradient norm = 1.0000, eval: [49.5 s]
# Iteration 22 fit: [33.7 s]: Recall = 0.26594, Jaccard score = 0.0881, loss = 0.144332, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 23 fit: [33.7 s]: Recall = 0.26959, Jaccard score = 0.0894, loss = 0.141528, gradient norm = 1.0000, eval: [49.2 s]
# Iteration 24 fit: [33.6 s]: Recall = 0.26959, Jaccard score = 0.0894, loss = 0.136808, gradient norm = 1.0000, eval: [48.8 s]
# Iteration 25 fit: [34.2 s]: Recall = 0.27370, Jaccard score = 0.0909, loss = 0.131422, gradient norm = 1.0000, eval: [49.4 s]
# Iteration 26 fit: [33.7 s]: Recall = 0.27530, Jaccard score = 0.0915, loss = 0.129694, gradient norm = 1.0000, eval: [48.9 s]
# Iteration 27 fit: [33.7 s]: Recall = 0.28250, Jaccard score = 0.0941, loss = 0.125132, gradient norm = 1.0000, eval: [49.7 s]
# Iteration 28 fit: [33.7 s]: Recall = 0.27907, Jaccard score = 0.0929, loss = 0.123716, gradient norm = 1.0000, eval: [49.2 s]
# Iteration 29 fit: [34.1 s]: Recall = 0.27724, Jaccard score = 0.0922, loss = 0.122533, gradient norm = 1.0000, eval: [49.2 s]
# Iteration 30 fit: [33.7 s]: Recall = 0.27839, Jaccard score = 0.0926, loss = 0.119280, gradient norm = 1.0000, eval: [49.1 s]
# Iteration 31 fit: [33.7 s]: Recall = 0.27907, Jaccard score = 0.0929, loss = 0.115802, gradient norm = 1.0000, eval: [49.2 s]
# Iteration 32 fit: [33.7 s]: Recall = 0.28227, Jaccard score = 0.0940, loss = 0.117721, gradient norm = 1.0000, eval: [49.0 s]
# Iteration 33 fit: [33.7 s]: Recall = 0.28273, Jaccard score = 0.0942, loss = 0.112034, gradient norm = 1.0000, eval: [49.7 s]
# Iteration 34 fit: [33.7 s]: Recall = 0.28638, Jaccard score = 0.0955, loss = 0.111266, gradient norm = 1.0000, eval: [48.9 s]
# Iteration 35 fit: [33.7 s]: Recall = 0.28673, Jaccard score = 0.0956, loss = 0.111141, gradient norm = 1.0000, eval: [49.2 s]
# Iteration 36 fit: [33.7 s]: Recall = 0.28741, Jaccard score = 0.0959, loss = 0.106490, gradient norm = 1.0000, eval: [48.9 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569401886.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569401886.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# bn_user (BatchNormalization)    (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           bn_user[0][0]                    
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# bn_item (BatchNormalization)    (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           dropout_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           bn_item[0][0]                    
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# dropout_3 (Dropout)             (None, 750)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      dropout_3[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 350)          0           layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       dropout_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_5 (Dropout)             (None, 96)           0           layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_5[0][0]                  
# ==================================================================================================
# Total params: 7,065,441
# Trainable params: 7,064,417
# Non-trainable params: 1,024
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0955, Jaccard score = 0.0299
# Iteration 0 fit: [35.0 s]: Recall = 0.42918, Jaccard score = 0.1503, loss = 0.440012, gradient norm = 1.0000, eval: [8.6 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.003, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569401981.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569401981.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# bn_user (BatchNormalization)    (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           bn_user[0][0]                    
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# bn_item (BatchNormalization)    (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           dropout_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           bn_item[0][0]                    
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# dropout_3 (Dropout)             (None, 750)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      dropout_3[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 350)          0           layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       dropout_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_5 (Dropout)             (None, 96)           0           layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_5[0][0]                  
# ==================================================================================================
# Total params: 7,065,441
# Trainable params: 7,064,417
# Non-trainable params: 1,024
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.1009, Jaccard score = 0.0317
# Iteration 0 fit: [35.2 s]: Recall = 0.45910, Jaccard score = 0.1625, loss = 0.430675, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 1 fit: [34.0 s]: Recall = 0.50491, Jaccard score = 0.1816, loss = 0.386618, gradient norm = 1.0000, eval: [8.8 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.003, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569439394.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569439394.h5
# Load data done [1.9 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# bn_user (BatchNormalization)    (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           bn_user[0][0]                    
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# bn_item (BatchNormalization)    (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           dropout_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           bn_item[0][0]                    
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# dropout_3 (Dropout)             (None, 750)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      dropout_3[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 350)          0           layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       dropout_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_5 (Dropout)             (None, 96)           0           layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_5[0][0]                  
# ==================================================================================================
# Total params: 7,065,441
# Trainable params: 7,064,417
# Non-trainable params: 1,024
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0977, Jaccard score = 0.0306
# Iteration 0 fit: [35.3 s]: Recall = 0.46173, Jaccard score = 0.1636, loss = 0.431083, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 1 fit: [34.1 s]: Recall = 0.51337, Jaccard score = 0.1852, loss = 0.388270, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 2 fit: [34.2 s]: Recall = 0.52490, Jaccard score = 0.1902, loss = 0.359611, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 3 fit: [34.1 s]: Recall = 0.54706, Jaccard score = 0.1998, loss = 0.337016, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 4 fit: [34.1 s]: Recall = 0.55940, Jaccard score = 0.2053, loss = 0.317699, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 5 fit: [34.2 s]: Recall = 0.56831, Jaccard score = 0.2092, loss = 0.299850, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 6 fit: [34.1 s]: Recall = 0.57574, Jaccard score = 0.2125, loss = 0.283319, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 7 fit: [34.1 s]: Recall = 0.58659, Jaccard score = 0.2174, loss = 0.268123, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 8 fit: [34.1 s]: Recall = 0.58647, Jaccard score = 0.2174, loss = 0.254707, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 9 fit: [34.1 s]: Recall = 0.59024, Jaccard score = 0.2191, loss = 0.240680, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 10 fit: [34.2 s]: Recall = 0.59824, Jaccard score = 0.2227, loss = 0.227727, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 11 fit: [34.1 s]: Recall = 0.60201, Jaccard score = 0.2244, loss = 0.216426, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 12 fit: [34.2 s]: Recall = 0.60224, Jaccard score = 0.2245, loss = 0.206176, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 13 fit: [34.2 s]: Recall = 0.60909, Jaccard score = 0.2276, loss = 0.195696, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 14 fit: [34.2 s]: Recall = 0.61401, Jaccard score = 0.2299, loss = 0.186095, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 15 fit: [34.1 s]: Recall = 0.61960, Jaccard score = 0.2325, loss = 0.177378, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 16 fit: [34.2 s]: Recall = 0.62074, Jaccard score = 0.2330, loss = 0.169953, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 17 fit: [34.1 s]: Recall = 0.61458, Jaccard score = 0.2302, loss = 0.162936, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 18 fit: [34.1 s]: Recall = 0.62474, Jaccard score = 0.2349, loss = 0.156944, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 19 fit: [34.1 s]: Recall = 0.62040, Jaccard score = 0.2329, loss = 0.150899, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 20 fit: [34.1 s]: Recall = 0.62406, Jaccard score = 0.2346, loss = 0.145724, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 21 fit: [34.1 s]: Recall = 0.62886, Jaccard score = 0.2368, loss = 0.139834, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 22 fit: [34.2 s]: Recall = 0.62828, Jaccard score = 0.2365, loss = 0.134987, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 23 fit: [34.1 s]: Recall = 0.63080, Jaccard score = 0.2377, loss = 0.130284, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 24 fit: [34.2 s]: Recall = 0.63263, Jaccard score = 0.2385, loss = 0.126070, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 25 fit: [34.2 s]: Recall = 0.63194, Jaccard score = 0.2382, loss = 0.122715, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 26 fit: [34.2 s]: Recall = 0.62966, Jaccard score = 0.2372, loss = 0.118708, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 27 fit: [34.1 s]: Recall = 0.63582, Jaccard score = 0.2400, loss = 0.115778, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 28 fit: [34.2 s]: Recall = 0.63480, Jaccard score = 0.2396, loss = 0.112311, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 29 fit: [34.1 s]: Recall = 0.63525, Jaccard score = 0.2398, loss = 0.108987, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 30 fit: [34.1 s]: Recall = 0.64096, Jaccard score = 0.2424, loss = 0.107996, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 31 fit: [34.2 s]: Recall = 0.63914, Jaccard score = 0.2416, loss = 0.103642, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 32 fit: [34.1 s]: Recall = 0.64165, Jaccard score = 0.2428, loss = 0.102379, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 33 fit: [34.2 s]: Recall = 0.64565, Jaccard score = 0.2447, loss = 0.098845, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 34 fit: [34.2 s]: Recall = 0.64256, Jaccard score = 0.2432, loss = 0.097965, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 35 fit: [34.1 s]: Recall = 0.64211, Jaccard score = 0.2430, loss = 0.095680, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 36 fit: [34.1 s]: Recall = 0.64485, Jaccard score = 0.2443, loss = 0.093937, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 37 fit: [34.1 s]: Recall = 0.64508, Jaccard score = 0.2444, loss = 0.092056, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 38 fit: [34.1 s]: Recall = 0.64588, Jaccard score = 0.2448, loss = 0.089809, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 39 fit: [34.2 s]: Recall = 0.64690, Jaccard score = 0.2452, loss = 0.088305, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 40 fit: [34.2 s]: Recall = 0.64759, Jaccard score = 0.2456, loss = 0.086696, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 41 fit: [34.2 s]: Recall = 0.64930, Jaccard score = 0.2464, loss = 0.084713, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 42 fit: [34.2 s]: Recall = 0.64405, Jaccard score = 0.2439, loss = 0.083575, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 43 fit: [34.1 s]: Recall = 0.64907, Jaccard score = 0.2463, loss = 0.082843, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 44 fit: [34.1 s]: Recall = 0.65673, Jaccard score = 0.2499, loss = 0.081313, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 45 fit: [34.2 s]: Recall = 0.64291, Jaccard score = 0.2434, loss = 0.080203, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 46 fit: [34.1 s]: Recall = 0.64656, Jaccard score = 0.2451, loss = 0.079000, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 47 fit: [34.1 s]: Recall = 0.65490, Jaccard score = 0.2490, loss = 0.077534, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 48 fit: [34.1 s]: Recall = 0.64428, Jaccard score = 0.2440, loss = 0.076144, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 49 fit: [34.1 s]: Recall = 0.64839, Jaccard score = 0.2459, loss = 0.075777, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 50 fit: [34.1 s]: Recall = 0.64999, Jaccard score = 0.2467, loss = 0.075058, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 51 fit: [34.1 s]: Recall = 0.64839, Jaccard score = 0.2459, loss = 0.072978, gradient norm = 1.0000, eval: [8.8 s]
# Iteration 52 fit: [34.2 s]: Recall = 0.65113, Jaccard score = 0.2472, loss = 0.072134, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 53 fit: [34.1 s]: Recall = 0.65159, Jaccard score = 0.2475, loss = 0.072210, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 54 fit: [34.2 s]: Recall = 0.65182, Jaccard score = 0.2476, loss = 0.070917, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 55 fit: [34.1 s]: Recall = 0.64873, Jaccard score = 0.2461, loss = 0.071742, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 56 fit: [34.1 s]: Recall = 0.65376, Jaccard score = 0.2485, loss = 0.069299, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 57 fit: [34.1 s]: Recall = 0.65170, Jaccard score = 0.2475, loss = 0.068017, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 58 fit: [34.2 s]: Recall = 0.64942, Jaccard score = 0.2464, loss = 0.066933, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 59 fit: [34.1 s]: Recall = 0.64279, Jaccard score = 0.2433, loss = 0.066729, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 60 fit: [34.2 s]: Recall = 0.64976, Jaccard score = 0.2466, loss = 0.067601, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 61 fit: [34.1 s]: Recall = 0.64816, Jaccard score = 0.2458, loss = 0.065911, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 62 fit: [34.2 s]: Recall = 0.64816, Jaccard score = 0.2458, loss = 0.065831, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 63 fit: [34.1 s]: Recall = 0.64142, Jaccard score = 0.2427, loss = 0.065311, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 64 fit: [34.1 s]: Recall = 0.65056, Jaccard score = 0.2470, loss = 0.063632, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 65 fit: [34.2 s]: Recall = 0.64690, Jaccard score = 0.2452, loss = 0.063562, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 66 fit: [34.1 s]: Recall = 0.64428, Jaccard score = 0.2440, loss = 0.061936, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 67 fit: [34.1 s]: Recall = 0.64999, Jaccard score = 0.2467, loss = 0.061859, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 68 fit: [34.1 s]: Recall = 0.64828, Jaccard score = 0.2459, loss = 0.061163, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 69 fit: [34.1 s]: Recall = 0.64588, Jaccard score = 0.2448, loss = 0.061308, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 70 fit: [34.1 s]: Recall = 0.64770, Jaccard score = 0.2456, loss = 0.060981, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 71 fit: [34.1 s]: Recall = 0.64839, Jaccard score = 0.2459, loss = 0.060942, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 72 fit: [34.2 s]: Recall = 0.64793, Jaccard score = 0.2457, loss = 0.061119, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 73 fit: [34.1 s]: Recall = 0.64416, Jaccard score = 0.2440, loss = 0.060079, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 74 fit: [34.1 s]: Recall = 0.65444, Jaccard score = 0.2488, loss = 0.059391, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 75 fit: [34.1 s]: Recall = 0.64976, Jaccard score = 0.2466, loss = 0.059958, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 76 fit: [34.1 s]: Recall = 0.64028, Jaccard score = 0.2421, loss = 0.058592, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 77 fit: [34.2 s]: Recall = 0.64485, Jaccard score = 0.2443, loss = 0.057915, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 78 fit: [34.1 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.057576, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 79 fit: [34.1 s]: Recall = 0.64770, Jaccard score = 0.2456, loss = 0.058379, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 80 fit: [34.1 s]: Recall = 0.64245, Jaccard score = 0.2431, loss = 0.058523, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 81 fit: [34.2 s]: Recall = 0.64713, Jaccard score = 0.2454, loss = 0.057732, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 82 fit: [34.1 s]: Recall = 0.64633, Jaccard score = 0.2450, loss = 0.055468, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 83 fit: [34.1 s]: Recall = 0.64828, Jaccard score = 0.2459, loss = 0.056823, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 84 fit: [34.1 s]: Recall = 0.64645, Jaccard score = 0.2450, loss = 0.056016, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 85 fit: [34.1 s]: Recall = 0.64987, Jaccard score = 0.2467, loss = 0.056494, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 86 fit: [34.2 s]: Recall = 0.64473, Jaccard score = 0.2442, loss = 0.055144, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 87 fit: [34.1 s]: Recall = 0.64188, Jaccard score = 0.2429, loss = 0.055828, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 88 fit: [34.2 s]: Recall = 0.65136, Jaccard score = 0.2474, loss = 0.054727, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 89 fit: [34.1 s]: Recall = 0.65045, Jaccard score = 0.2469, loss = 0.055154, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 90 fit: [34.2 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.055235, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 91 fit: [34.2 s]: Recall = 0.64839, Jaccard score = 0.2459, loss = 0.054288, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 92 fit: [34.1 s]: Recall = 0.63982, Jaccard score = 0.2419, loss = 0.053788, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 93 fit: [34.2 s]: Recall = 0.64610, Jaccard score = 0.2449, loss = 0.053986, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 94 fit: [34.2 s]: Recall = 0.64656, Jaccard score = 0.2451, loss = 0.052933, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 95 fit: [34.1 s]: Recall = 0.64531, Jaccard score = 0.2445, loss = 0.051990, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 96 fit: [34.2 s]: Recall = 0.64588, Jaccard score = 0.2448, loss = 0.054465, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 97 fit: [34.1 s]: Recall = 0.64725, Jaccard score = 0.2454, loss = 0.052547, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 98 fit: [34.1 s]: Recall = 0.65204, Jaccard score = 0.2477, loss = 0.051905, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 99 fit: [34.2 s]: Recall = 0.64451, Jaccard score = 0.2441, loss = 0.051732, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 100 fit: [34.2 s]: Recall = 0.64485, Jaccard score = 0.2443, loss = 0.052206, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 101 fit: [34.1 s]: Recall = 0.65513, Jaccard score = 0.2491, loss = 0.052660, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 102 fit: [34.2 s]: Recall = 0.64428, Jaccard score = 0.2440, loss = 0.052891, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 103 fit: [34.1 s]: Recall = 0.64885, Jaccard score = 0.2462, loss = 0.051677, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 104 fit: [34.2 s]: Recall = 0.64839, Jaccard score = 0.2459, loss = 0.050744, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 105 fit: [34.1 s]: Recall = 0.64896, Jaccard score = 0.2462, loss = 0.051974, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 106 fit: [34.2 s]: Recall = 0.64451, Jaccard score = 0.2441, loss = 0.052675, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 107 fit: [34.1 s]: Recall = 0.64725, Jaccard score = 0.2454, loss = 0.050781, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 108 fit: [34.1 s]: Recall = 0.64519, Jaccard score = 0.2444, loss = 0.051735, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 109 fit: [34.1 s]: Recall = 0.64405, Jaccard score = 0.2439, loss = 0.052904, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 110 fit: [34.1 s]: Recall = 0.64565, Jaccard score = 0.2447, loss = 0.051406, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 111 fit: [34.1 s]: Recall = 0.63834, Jaccard score = 0.2412, loss = 0.050990, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 112 fit: [34.1 s]: Recall = 0.64085, Jaccard score = 0.2424, loss = 0.051120, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 113 fit: [34.2 s]: Recall = 0.64553, Jaccard score = 0.2446, loss = 0.050166, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 114 fit: [34.1 s]: Recall = 0.63685, Jaccard score = 0.2405, loss = 0.050784, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 115 fit: [34.2 s]: Recall = 0.64599, Jaccard score = 0.2448, loss = 0.050998, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 116 fit: [34.2 s]: Recall = 0.63982, Jaccard score = 0.2419, loss = 0.050798, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 117 fit: [34.1 s]: Recall = 0.64679, Jaccard score = 0.2452, loss = 0.051010, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 118 fit: [34.2 s]: Recall = 0.64565, Jaccard score = 0.2447, loss = 0.050397, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 119 fit: [34.1 s]: Recall = 0.64828, Jaccard score = 0.2459, loss = 0.050611, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 120 fit: [34.1 s]: Recall = 0.63982, Jaccard score = 0.2419, loss = 0.051341, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 121 fit: [34.1 s]: Recall = 0.64371, Jaccard score = 0.2437, loss = 0.050195, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 122 fit: [34.1 s]: Recall = 0.64108, Jaccard score = 0.2425, loss = 0.049802, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 123 fit: [34.1 s]: Recall = 0.64131, Jaccard score = 0.2426, loss = 0.049892, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 124 fit: [34.1 s]: Recall = 0.64245, Jaccard score = 0.2431, loss = 0.050485, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 125 fit: [34.1 s]: Recall = 0.64416, Jaccard score = 0.2440, loss = 0.050228, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 126 fit: [34.1 s]: Recall = 0.63994, Jaccard score = 0.2420, loss = 0.049486, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 127 fit: [34.1 s]: Recall = 0.64416, Jaccard score = 0.2440, loss = 0.048466, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 128 fit: [34.1 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.049816, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 129 fit: [34.1 s]: Recall = 0.64222, Jaccard score = 0.2430, loss = 0.051235, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 130 fit: [34.1 s]: Recall = 0.63217, Jaccard score = 0.2383, loss = 0.051443, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 131 fit: [34.1 s]: Recall = 0.64291, Jaccard score = 0.2434, loss = 0.049585, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 132 fit: [34.2 s]: Recall = 0.63617, Jaccard score = 0.2402, loss = 0.052022, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 133 fit: [34.1 s]: Recall = 0.64119, Jaccard score = 0.2426, loss = 0.050056, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 134 fit: [34.1 s]: Recall = 0.63994, Jaccard score = 0.2420, loss = 0.049645, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 135 fit: [34.1 s]: Recall = 0.64005, Jaccard score = 0.2420, loss = 0.051870, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 136 fit: [34.2 s]: Recall = 0.63251, Jaccard score = 0.2385, loss = 0.048713, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 137 fit: [34.1 s]: Recall = 0.63194, Jaccard score = 0.2382, loss = 0.048517, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 138 fit: [34.2 s]: Recall = 0.63891, Jaccard score = 0.2415, loss = 0.048745, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 139 fit: [34.1 s]: Recall = 0.63605, Jaccard score = 0.2401, loss = 0.049436, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 140 fit: [34.2 s]: Recall = 0.64382, Jaccard score = 0.2438, loss = 0.051114, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 141 fit: [34.1 s]: Recall = 0.64108, Jaccard score = 0.2425, loss = 0.049913, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 142 fit: [34.2 s]: Recall = 0.63708, Jaccard score = 0.2406, loss = 0.049904, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 143 fit: [34.1 s]: Recall = 0.62886, Jaccard score = 0.2368, loss = 0.048909, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 144 fit: [34.1 s]: Recall = 0.63971, Jaccard score = 0.2419, loss = 0.049836, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 145 fit: [34.1 s]: Recall = 0.63445, Jaccard score = 0.2394, loss = 0.049579, gradient norm = 1.0000, eval: [8.8 s]
# Iteration 146 fit: [34.1 s]: Recall = 0.63628, Jaccard score = 0.2403, loss = 0.049055, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 147 fit: [34.1 s]: Recall = 0.63365, Jaccard score = 0.2390, loss = 0.049813, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 148 fit: [34.2 s]: Recall = 0.63994, Jaccard score = 0.2420, loss = 0.048296, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 149 fit: [34.1 s]: Recall = 0.64428, Jaccard score = 0.2440, loss = 0.047433, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 150 fit: [34.2 s]: Recall = 0.63639, Jaccard score = 0.2403, loss = 0.053310, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 151 fit: [34.1 s]: Recall = 0.63662, Jaccard score = 0.2404, loss = 0.050908, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 152 fit: [34.2 s]: Recall = 0.63502, Jaccard score = 0.2397, loss = 0.051831, gradient norm = 1.0000, eval: [8.5 s]
# Iteration 153 fit: [34.1 s]: Recall = 0.63822, Jaccard score = 0.2412, loss = 0.049868, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 154 fit: [34.1 s]: Recall = 0.63822, Jaccard score = 0.2412, loss = 0.049887, gradient norm = 1.0000, eval: [8.6 s]
# Recall score: 0.30127203749163134     Jaccard score: 0.10281014393420151

# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=150, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.002, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,750,350,96]_1569446277.h5
--weights_path: Pretrain/_MLP_8_[512,750,350,96]_1569446277.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 256)          0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# bn_user (BatchNormalization)    (None, 256)          1024        flatten_1[0][0]                  
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           bn_user[0][0]                    
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# bn_item (BatchNormalization)    (None, 256)          1024        flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           dropout_1[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           bn_item[0][0]                    
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# dropout_3 (Dropout)             (None, 750)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      dropout_3[0][0]                  
# __________________________________________________________________________________________________
# dropout_4 (Dropout)             (None, 350)          0           layer2[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       dropout_4[0][0]                  
# __________________________________________________________________________________________________
# dropout_5 (Dropout)             (None, 96)           0           layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          dropout_5[0][0]                  
# ==================================================================================================
# Total params: 7,065,441
# Trainable params: 7,064,417
# Non-trainable params: 1,024
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.1020, Jaccard score = 0.0321
# Iteration 0 fit: [35.4 s]: Recall = 0.44848, Jaccard score = 0.1581, loss = 0.433294, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 1 fit: [34.2 s]: Recall = 0.49966, Jaccard score = 0.1794, loss = 0.391524, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 2 fit: [34.2 s]: Recall = 0.53061, Jaccard score = 0.1927, loss = 0.364640, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 3 fit: [34.2 s]: Recall = 0.54204, Jaccard score = 0.1976, loss = 0.342171, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 4 fit: [34.2 s]: Recall = 0.54958, Jaccard score = 0.2009, loss = 0.323374, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 5 fit: [34.2 s]: Recall = 0.56020, Jaccard score = 0.2056, loss = 0.306947, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 6 fit: [34.2 s]: Recall = 0.56831, Jaccard score = 0.2092, loss = 0.290463, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 7 fit: [34.2 s]: Recall = 0.58145, Jaccard score = 0.2151, loss = 0.276336, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 8 fit: [34.2 s]: Recall = 0.58293, Jaccard score = 0.2158, loss = 0.262859, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 9 fit: [34.2 s]: Recall = 0.58088, Jaccard score = 0.2148, loss = 0.249769, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 10 fit: [34.2 s]: Recall = 0.59241, Jaccard score = 0.2200, loss = 0.238089, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 11 fit: [34.2 s]: Recall = 0.59093, Jaccard score = 0.2194, loss = 0.226764, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 12 fit: [34.2 s]: Recall = 0.59904, Jaccard score = 0.2231, loss = 0.216554, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 13 fit: [34.2 s]: Recall = 0.60247, Jaccard score = 0.2246, loss = 0.206312, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 14 fit: [34.1 s]: Recall = 0.60612, Jaccard score = 0.2263, loss = 0.196939, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 15 fit: [34.1 s]: Recall = 0.60886, Jaccard score = 0.2275, loss = 0.188464, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 16 fit: [34.2 s]: Recall = 0.60681, Jaccard score = 0.2266, loss = 0.180239, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 17 fit: [34.1 s]: Recall = 0.61069, Jaccard score = 0.2284, loss = 0.173928, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 18 fit: [34.1 s]: Recall = 0.61092, Jaccard score = 0.2285, loss = 0.167225, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 19 fit: [34.2 s]: Recall = 0.61766, Jaccard score = 0.2316, loss = 0.160668, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 20 fit: [34.2 s]: Recall = 0.61423, Jaccard score = 0.2300, loss = 0.154916, gradient norm = 1.0000, eval: [8.8 s]
# Iteration 21 fit: [34.2 s]: Recall = 0.61903, Jaccard score = 0.2322, loss = 0.148791, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 22 fit: [34.2 s]: Recall = 0.62177, Jaccard score = 0.2335, loss = 0.143694, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 23 fit: [34.2 s]: Recall = 0.62234, Jaccard score = 0.2338, loss = 0.138784, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 24 fit: [34.1 s]: Recall = 0.62783, Jaccard score = 0.2363, loss = 0.134861, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 25 fit: [34.2 s]: Recall = 0.62634, Jaccard score = 0.2356, loss = 0.131580, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 26 fit: [34.1 s]: Recall = 0.62771, Jaccard score = 0.2363, loss = 0.126414, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 27 fit: [34.1 s]: Recall = 0.63000, Jaccard score = 0.2373, loss = 0.123103, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 28 fit: [34.2 s]: Recall = 0.62988, Jaccard score = 0.2373, loss = 0.118983, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 29 fit: [34.1 s]: Recall = 0.63331, Jaccard score = 0.2389, loss = 0.115941, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 30 fit: [34.2 s]: Recall = 0.64176, Jaccard score = 0.2428, loss = 0.112610, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 31 fit: [34.2 s]: Recall = 0.63251, Jaccard score = 0.2385, loss = 0.109780, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 32 fit: [34.1 s]: Recall = 0.63605, Jaccard score = 0.2401, loss = 0.106280, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 33 fit: [34.1 s]: Recall = 0.63514, Jaccard score = 0.2397, loss = 0.104523, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 34 fit: [34.2 s]: Recall = 0.64074, Jaccard score = 0.2423, loss = 0.101722, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 35 fit: [34.1 s]: Recall = 0.63731, Jaccard score = 0.2407, loss = 0.099031, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 36 fit: [34.1 s]: Recall = 0.63697, Jaccard score = 0.2406, loss = 0.097787, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 37 fit: [34.2 s]: Recall = 0.63925, Jaccard score = 0.2416, loss = 0.094691, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 38 fit: [34.1 s]: Recall = 0.64393, Jaccard score = 0.2438, loss = 0.092924, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 39 fit: [34.2 s]: Recall = 0.64233, Jaccard score = 0.2431, loss = 0.090056, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 40 fit: [34.1 s]: Recall = 0.64336, Jaccard score = 0.2436, loss = 0.089263, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 41 fit: [34.2 s]: Recall = 0.64588, Jaccard score = 0.2448, loss = 0.087322, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 42 fit: [34.1 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.085652, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 43 fit: [34.2 s]: Recall = 0.64633, Jaccard score = 0.2450, loss = 0.083187, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 44 fit: [34.2 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.082195, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 45 fit: [34.2 s]: Recall = 0.64588, Jaccard score = 0.2448, loss = 0.081552, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 46 fit: [34.1 s]: Recall = 0.65136, Jaccard score = 0.2474, loss = 0.078580, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 47 fit: [34.2 s]: Recall = 0.64805, Jaccard score = 0.2458, loss = 0.077854, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 48 fit: [34.1 s]: Recall = 0.64816, Jaccard score = 0.2458, loss = 0.076548, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 49 fit: [34.1 s]: Recall = 0.64919, Jaccard score = 0.2463, loss = 0.074693, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 50 fit: [34.1 s]: Recall = 0.65216, Jaccard score = 0.2477, loss = 0.073842, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 51 fit: [34.2 s]: Recall = 0.64999, Jaccard score = 0.2467, loss = 0.072771, gradient norm = 1.0000, eval: [8.8 s]
# Iteration 52 fit: [34.2 s]: Recall = 0.64679, Jaccard score = 0.2452, loss = 0.071489, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 53 fit: [34.1 s]: Recall = 0.65079, Jaccard score = 0.2471, loss = 0.070778, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 54 fit: [34.1 s]: Recall = 0.64987, Jaccard score = 0.2467, loss = 0.068989, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 55 fit: [34.1 s]: Recall = 0.64885, Jaccard score = 0.2462, loss = 0.068089, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 56 fit: [34.2 s]: Recall = 0.65216, Jaccard score = 0.2477, loss = 0.068159, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 57 fit: [34.2 s]: Recall = 0.65056, Jaccard score = 0.2470, loss = 0.067115, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 58 fit: [34.2 s]: Recall = 0.65547, Jaccard score = 0.2493, loss = 0.065495, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 59 fit: [34.2 s]: Recall = 0.64770, Jaccard score = 0.2456, loss = 0.064620, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 60 fit: [34.1 s]: Recall = 0.64930, Jaccard score = 0.2464, loss = 0.063617, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 61 fit: [34.2 s]: Recall = 0.65273, Jaccard score = 0.2480, loss = 0.062954, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 62 fit: [34.1 s]: Recall = 0.65113, Jaccard score = 0.2472, loss = 0.062409, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 63 fit: [34.2 s]: Recall = 0.65387, Jaccard score = 0.2485, loss = 0.061377, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 64 fit: [34.1 s]: Recall = 0.65090, Jaccard score = 0.2471, loss = 0.061253, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 65 fit: [34.1 s]: Recall = 0.65090, Jaccard score = 0.2471, loss = 0.060365, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 66 fit: [34.1 s]: Recall = 0.65193, Jaccard score = 0.2476, loss = 0.059561, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 67 fit: [34.3 s]: Recall = 0.64565, Jaccard score = 0.2447, loss = 0.058997, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 68 fit: [34.2 s]: Recall = 0.65410, Jaccard score = 0.2487, loss = 0.057524, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 69 fit: [34.1 s]: Recall = 0.64736, Jaccard score = 0.2455, loss = 0.057348, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 70 fit: [34.1 s]: Recall = 0.65204, Jaccard score = 0.2477, loss = 0.056525, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 71 fit: [34.1 s]: Recall = 0.65204, Jaccard score = 0.2477, loss = 0.056629, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 72 fit: [34.2 s]: Recall = 0.64896, Jaccard score = 0.2462, loss = 0.055278, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 73 fit: [34.1 s]: Recall = 0.65170, Jaccard score = 0.2475, loss = 0.055594, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 74 fit: [34.1 s]: Recall = 0.65501, Jaccard score = 0.2491, loss = 0.055399, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 75 fit: [34.1 s]: Recall = 0.65079, Jaccard score = 0.2471, loss = 0.053202, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 76 fit: [34.1 s]: Recall = 0.65125, Jaccard score = 0.2473, loss = 0.053715, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 77 fit: [34.1 s]: Recall = 0.64987, Jaccard score = 0.2467, loss = 0.052437, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 78 fit: [34.1 s]: Recall = 0.65627, Jaccard score = 0.2497, loss = 0.052065, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 79 fit: [34.2 s]: Recall = 0.65901, Jaccard score = 0.2510, loss = 0.051849, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 80 fit: [34.2 s]: Recall = 0.65467, Jaccard score = 0.2489, loss = 0.051236, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 81 fit: [34.1 s]: Recall = 0.65159, Jaccard score = 0.2475, loss = 0.050678, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 82 fit: [34.2 s]: Recall = 0.65467, Jaccard score = 0.2489, loss = 0.051204, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 83 fit: [34.1 s]: Recall = 0.65125, Jaccard score = 0.2473, loss = 0.049497, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 84 fit: [34.1 s]: Recall = 0.65296, Jaccard score = 0.2481, loss = 0.049251, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 85 fit: [34.1 s]: Recall = 0.65147, Jaccard score = 0.2474, loss = 0.048915, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 86 fit: [34.1 s]: Recall = 0.65444, Jaccard score = 0.2488, loss = 0.048450, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 87 fit: [34.1 s]: Recall = 0.65593, Jaccard score = 0.2495, loss = 0.047958, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 88 fit: [34.1 s]: Recall = 0.65536, Jaccard score = 0.2493, loss = 0.047608, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 89 fit: [34.1 s]: Recall = 0.65787, Jaccard score = 0.2504, loss = 0.047341, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 90 fit: [34.1 s]: Recall = 0.65844, Jaccard score = 0.2507, loss = 0.047369, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 91 fit: [34.2 s]: Recall = 0.64576, Jaccard score = 0.2447, loss = 0.046738, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 92 fit: [34.1 s]: Recall = 0.65570, Jaccard score = 0.2494, loss = 0.046210, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 93 fit: [34.1 s]: Recall = 0.65444, Jaccard score = 0.2488, loss = 0.045937, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 94 fit: [34.1 s]: Recall = 0.65753, Jaccard score = 0.2503, loss = 0.045834, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 95 fit: [34.1 s]: Recall = 0.64987, Jaccard score = 0.2467, loss = 0.046023, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 96 fit: [34.1 s]: Recall = 0.64759, Jaccard score = 0.2456, loss = 0.044986, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 97 fit: [34.2 s]: Recall = 0.65113, Jaccard score = 0.2472, loss = 0.044741, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 98 fit: [34.1 s]: Recall = 0.65204, Jaccard score = 0.2477, loss = 0.044542, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 99 fit: [34.2 s]: Recall = 0.65890, Jaccard score = 0.2509, loss = 0.043694, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 100 fit: [34.1 s]: Recall = 0.65456, Jaccard score = 0.2489, loss = 0.043330, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 101 fit: [34.2 s]: Recall = 0.65444, Jaccard score = 0.2488, loss = 0.044321, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 102 fit: [34.1 s]: Recall = 0.65536, Jaccard score = 0.2493, loss = 0.043395, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 103 fit: [34.1 s]: Recall = 0.66118, Jaccard score = 0.2520, loss = 0.043268, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 104 fit: [34.2 s]: Recall = 0.65159, Jaccard score = 0.2475, loss = 0.043119, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 105 fit: [34.1 s]: Recall = 0.65604, Jaccard score = 0.2496, loss = 0.042162, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 106 fit: [34.1 s]: Recall = 0.65764, Jaccard score = 0.2503, loss = 0.042688, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 107 fit: [34.1 s]: Recall = 0.65627, Jaccard score = 0.2497, loss = 0.041711, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 108 fit: [34.1 s]: Recall = 0.65741, Jaccard score = 0.2502, loss = 0.040724, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 109 fit: [34.1 s]: Recall = 0.65410, Jaccard score = 0.2487, loss = 0.040614, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 110 fit: [34.2 s]: Recall = 0.65833, Jaccard score = 0.2507, loss = 0.040183, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 111 fit: [34.2 s]: Recall = 0.65387, Jaccard score = 0.2485, loss = 0.041305, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 112 fit: [34.1 s]: Recall = 0.65045, Jaccard score = 0.2469, loss = 0.040230, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 113 fit: [34.1 s]: Recall = 0.65490, Jaccard score = 0.2490, loss = 0.040503, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 114 fit: [34.1 s]: Recall = 0.65913, Jaccard score = 0.2510, loss = 0.039644, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 115 fit: [34.2 s]: Recall = 0.65422, Jaccard score = 0.2487, loss = 0.039902, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 116 fit: [34.1 s]: Recall = 0.65513, Jaccard score = 0.2491, loss = 0.039369, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 117 fit: [34.2 s]: Recall = 0.65262, Jaccard score = 0.2479, loss = 0.039183, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 118 fit: [34.1 s]: Recall = 0.65707, Jaccard score = 0.2501, loss = 0.039076, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 119 fit: [34.2 s]: Recall = 0.65501, Jaccard score = 0.2491, loss = 0.039159, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 120 fit: [34.1 s]: Recall = 0.65307, Jaccard score = 0.2482, loss = 0.039084, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 121 fit: [34.1 s]: Recall = 0.65182, Jaccard score = 0.2476, loss = 0.038546, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 122 fit: [34.1 s]: Recall = 0.65490, Jaccard score = 0.2490, loss = 0.038553, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 123 fit: [34.1 s]: Recall = 0.65239, Jaccard score = 0.2478, loss = 0.037678, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 124 fit: [34.1 s]: Recall = 0.64451, Jaccard score = 0.2441, loss = 0.037914, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 125 fit: [34.2 s]: Recall = 0.65227, Jaccard score = 0.2478, loss = 0.037669, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 126 fit: [34.2 s]: Recall = 0.65513, Jaccard score = 0.2491, loss = 0.037276, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 127 fit: [34.2 s]: Recall = 0.65182, Jaccard score = 0.2476, loss = 0.037622, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 128 fit: [34.1 s]: Recall = 0.65364, Jaccard score = 0.2484, loss = 0.037425, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 129 fit: [34.1 s]: Recall = 0.65387, Jaccard score = 0.2485, loss = 0.037035, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 130 fit: [34.1 s]: Recall = 0.65010, Jaccard score = 0.2468, loss = 0.036729, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 131 fit: [34.2 s]: Recall = 0.65079, Jaccard score = 0.2471, loss = 0.036183, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 132 fit: [34.2 s]: Recall = 0.65125, Jaccard score = 0.2473, loss = 0.037077, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 133 fit: [34.2 s]: Recall = 0.65536, Jaccard score = 0.2493, loss = 0.036016, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 134 fit: [34.2 s]: Recall = 0.65227, Jaccard score = 0.2478, loss = 0.036600, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 135 fit: [34.1 s]: Recall = 0.65410, Jaccard score = 0.2487, loss = 0.035438, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 136 fit: [34.1 s]: Recall = 0.64816, Jaccard score = 0.2458, loss = 0.035633, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 137 fit: [34.2 s]: Recall = 0.65204, Jaccard score = 0.2477, loss = 0.035362, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 138 fit: [34.1 s]: Recall = 0.65513, Jaccard score = 0.2491, loss = 0.035294, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 139 fit: [34.2 s]: Recall = 0.65399, Jaccard score = 0.2486, loss = 0.035369, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 140 fit: [34.1 s]: Recall = 0.65204, Jaccard score = 0.2477, loss = 0.035556, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 141 fit: [34.1 s]: Recall = 0.64336, Jaccard score = 0.2436, loss = 0.035916, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 142 fit: [34.1 s]: Recall = 0.65090, Jaccard score = 0.2471, loss = 0.035379, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 143 fit: [34.2 s]: Recall = 0.64736, Jaccard score = 0.2455, loss = 0.035726, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 144 fit: [34.1 s]: Recall = 0.65010, Jaccard score = 0.2468, loss = 0.034853, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 145 fit: [34.1 s]: Recall = 0.65216, Jaccard score = 0.2477, loss = 0.034532, gradient norm = 1.0000, eval: [8.8 s]
# Iteration 146 fit: [34.1 s]: Recall = 0.64965, Jaccard score = 0.2465, loss = 0.034277, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 147 fit: [34.2 s]: Recall = 0.64942, Jaccard score = 0.2464, loss = 0.034544, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 148 fit: [34.2 s]: Recall = 0.65227, Jaccard score = 0.2478, loss = 0.034144, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 149 fit: [34.2 s]: Recall = 0.65307, Jaccard score = 0.2482, loss = 0.034343, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 150 fit: [34.1 s]: Recall = 0.64359, Jaccard score = 0.2437, loss = 0.033620, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 151 fit: [34.2 s]: Recall = 0.64919, Jaccard score = 0.2463, loss = 0.034176, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 152 fit: [34.1 s]: Recall = 0.65102, Jaccard score = 0.2472, loss = 0.033766, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 153 fit: [34.2 s]: Recall = 0.64953, Jaccard score = 0.2465, loss = 0.033610, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 154 fit: [34.2 s]: Recall = 0.64565, Jaccard score = 0.2447, loss = 0.033934, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 155 fit: [34.2 s]: Recall = 0.64451, Jaccard score = 0.2441, loss = 0.033621, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 156 fit: [34.1 s]: Recall = 0.64188, Jaccard score = 0.2429, loss = 0.034010, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 157 fit: [34.2 s]: Recall = 0.65524, Jaccard score = 0.2492, loss = 0.033747, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 158 fit: [34.1 s]: Recall = 0.65284, Jaccard score = 0.2481, loss = 0.033907, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 159 fit: [34.2 s]: Recall = 0.65033, Jaccard score = 0.2469, loss = 0.033216, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 160 fit: [34.1 s]: Recall = 0.65159, Jaccard score = 0.2475, loss = 0.033872, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 161 fit: [34.2 s]: Recall = 0.64531, Jaccard score = 0.2445, loss = 0.033836, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 162 fit: [34.1 s]: Recall = 0.65422, Jaccard score = 0.2487, loss = 0.033350, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 163 fit: [34.2 s]: Recall = 0.64508, Jaccard score = 0.2444, loss = 0.032658, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 164 fit: [34.1 s]: Recall = 0.64576, Jaccard score = 0.2447, loss = 0.033190, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 165 fit: [34.1 s]: Recall = 0.64736, Jaccard score = 0.2455, loss = 0.033976, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 166 fit: [34.1 s]: Recall = 0.64610, Jaccard score = 0.2449, loss = 0.032339, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 167 fit: [34.1 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.032738, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 168 fit: [34.1 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.032959, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 169 fit: [34.1 s]: Recall = 0.65147, Jaccard score = 0.2474, loss = 0.032262, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 170 fit: [34.1 s]: Recall = 0.64816, Jaccard score = 0.2458, loss = 0.033072, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 171 fit: [34.2 s]: Recall = 0.64108, Jaccard score = 0.2425, loss = 0.032696, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 172 fit: [34.1 s]: Recall = 0.64725, Jaccard score = 0.2454, loss = 0.032562, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 173 fit: [34.2 s]: Recall = 0.63936, Jaccard score = 0.2417, loss = 0.032286, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 174 fit: [34.1 s]: Recall = 0.64485, Jaccard score = 0.2443, loss = 0.032496, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 175 fit: [34.1 s]: Recall = 0.64736, Jaccard score = 0.2455, loss = 0.032551, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 176 fit: [34.1 s]: Recall = 0.65102, Jaccard score = 0.2472, loss = 0.032047, gradient norm = 1.0000, eval: [8.8 s]
# Iteration 177 fit: [34.1 s]: Recall = 0.64393, Jaccard score = 0.2438, loss = 0.032577, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 178 fit: [34.2 s]: Recall = 0.64850, Jaccard score = 0.2460, loss = 0.031882, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 179 fit: [34.2 s]: Recall = 0.64668, Jaccard score = 0.2451, loss = 0.032526, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 180 fit: [34.1 s]: Recall = 0.64451, Jaccard score = 0.2441, loss = 0.031884, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 181 fit: [34.1 s]: Recall = 0.63879, Jaccard score = 0.2414, loss = 0.031471, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 182 fit: [34.1 s]: Recall = 0.64702, Jaccard score = 0.2453, loss = 0.031767, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 183 fit: [34.2 s]: Recall = 0.64942, Jaccard score = 0.2464, loss = 0.031818, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 184 fit: [34.1 s]: Recall = 0.64439, Jaccard score = 0.2441, loss = 0.032126, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 185 fit: [34.1 s]: Recall = 0.63674, Jaccard score = 0.2405, loss = 0.031648, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 186 fit: [34.2 s]: Recall = 0.64850, Jaccard score = 0.2460, loss = 0.031822, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 187 fit: [34.2 s]: Recall = 0.64508, Jaccard score = 0.2444, loss = 0.031971, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 188 fit: [34.1 s]: Recall = 0.64359, Jaccard score = 0.2437, loss = 0.032383, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 189 fit: [34.2 s]: Recall = 0.64633, Jaccard score = 0.2450, loss = 0.031715, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 190 fit: [34.2 s]: Recall = 0.64439, Jaccard score = 0.2441, loss = 0.031247, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 191 fit: [34.1 s]: Recall = 0.64199, Jaccard score = 0.2429, loss = 0.031829, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 192 fit: [34.2 s]: Recall = 0.64256, Jaccard score = 0.2432, loss = 0.032500, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 193 fit: [34.2 s]: Recall = 0.64199, Jaccard score = 0.2429, loss = 0.030690, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 194 fit: [34.1 s]: Recall = 0.63891, Jaccard score = 0.2415, loss = 0.031277, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 195 fit: [34.1 s]: Recall = 0.63674, Jaccard score = 0.2405, loss = 0.030807, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 196 fit: [34.2 s]: Recall = 0.63811, Jaccard score = 0.2411, loss = 0.031055, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 197 fit: [34.2 s]: Recall = 0.64371, Jaccard score = 0.2437, loss = 0.031193, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 198 fit: [34.1 s]: Recall = 0.64051, Jaccard score = 0.2422, loss = 0.031262, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 199 fit: [34.1 s]: Recall = 0.63845, Jaccard score = 0.2413, loss = 0.031372, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 200 fit: [34.1 s]: Recall = 0.65284, Jaccard score = 0.2481, loss = 0.030915, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 201 fit: [34.1 s]: Recall = 0.64508, Jaccard score = 0.2444, loss = 0.031103, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 202 fit: [34.1 s]: Recall = 0.64268, Jaccard score = 0.2433, loss = 0.030916, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 203 fit: [34.2 s]: Recall = 0.63411, Jaccard score = 0.2392, loss = 0.031075, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 204 fit: [34.1 s]: Recall = 0.65045, Jaccard score = 0.2469, loss = 0.031198, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 205 fit: [34.1 s]: Recall = 0.64291, Jaccard score = 0.2434, loss = 0.030747, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 206 fit: [34.2 s]: Recall = 0.63971, Jaccard score = 0.2419, loss = 0.031039, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 207 fit: [34.1 s]: Recall = 0.64371, Jaccard score = 0.2437, loss = 0.032120, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 208 fit: [34.1 s]: Recall = 0.63868, Jaccard score = 0.2414, loss = 0.030803, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 209 fit: [34.2 s]: Recall = 0.63982, Jaccard score = 0.2419, loss = 0.030916, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 210 fit: [34.1 s]: Recall = 0.63811, Jaccard score = 0.2411, loss = 0.030447, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 211 fit: [34.1 s]: Recall = 0.64736, Jaccard score = 0.2455, loss = 0.031073, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 212 fit: [34.1 s]: Recall = 0.63502, Jaccard score = 0.2397, loss = 0.030865, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 213 fit: [34.1 s]: Recall = 0.63674, Jaccard score = 0.2405, loss = 0.030747, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 214 fit: [34.1 s]: Recall = 0.63320, Jaccard score = 0.2388, loss = 0.030787, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 215 fit: [34.1 s]: Recall = 0.63125, Jaccard score = 0.2379, loss = 0.031160, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 216 fit: [34.1 s]: Recall = 0.63811, Jaccard score = 0.2411, loss = 0.030774, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 217 fit: [34.2 s]: Recall = 0.63491, Jaccard score = 0.2396, loss = 0.031501, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 218 fit: [34.2 s]: Recall = 0.63868, Jaccard score = 0.2414, loss = 0.031692, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 219 fit: [34.1 s]: Recall = 0.63445, Jaccard score = 0.2394, loss = 0.031082, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 220 fit: [34.1 s]: Recall = 0.63754, Jaccard score = 0.2408, loss = 0.031434, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 221 fit: [34.1 s]: Recall = 0.63617, Jaccard score = 0.2402, loss = 0.030739, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 222 fit: [34.1 s]: Recall = 0.63605, Jaccard score = 0.2401, loss = 0.030096, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 223 fit: [34.2 s]: Recall = 0.63605, Jaccard score = 0.2401, loss = 0.030095, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 224 fit: [34.2 s]: Recall = 0.63411, Jaccard score = 0.2392, loss = 0.032041, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 225 fit: [34.1 s]: Recall = 0.63594, Jaccard score = 0.2401, loss = 0.030237, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 226 fit: [34.1 s]: Recall = 0.63571, Jaccard score = 0.2400, loss = 0.030664, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 227 fit: [34.1 s]: Recall = 0.63137, Jaccard score = 0.2380, loss = 0.030214, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 228 fit: [34.2 s]: Recall = 0.63354, Jaccard score = 0.2390, loss = 0.029709, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 229 fit: [34.1 s]: Recall = 0.63731, Jaccard score = 0.2407, loss = 0.031102, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 230 fit: [34.1 s]: Recall = 0.63685, Jaccard score = 0.2405, loss = 0.030785, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 231 fit: [34.1 s]: Recall = 0.63114, Jaccard score = 0.2378, loss = 0.032483, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 232 fit: [34.2 s]: Recall = 0.63982, Jaccard score = 0.2419, loss = 0.031364, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 233 fit: [34.1 s]: Recall = 0.63811, Jaccard score = 0.2411, loss = 0.030956, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 234 fit: [34.1 s]: Recall = 0.63491, Jaccard score = 0.2396, loss = 0.031832, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 235 fit: [34.2 s]: Recall = 0.63731, Jaccard score = 0.2407, loss = 0.031214, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 236 fit: [34.1 s]: Recall = 0.63342, Jaccard score = 0.2389, loss = 0.032577, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 237 fit: [34.1 s]: Recall = 0.63639, Jaccard score = 0.2403, loss = 0.030759, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 238 fit: [34.1 s]: Recall = 0.63445, Jaccard score = 0.2394, loss = 0.030595, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 239 fit: [34.1 s]: Recall = 0.63537, Jaccard score = 0.2398, loss = 0.031676, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 240 fit: [34.2 s]: Recall = 0.63731, Jaccard score = 0.2407, loss = 0.030585, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 241 fit: [34.2 s]: Recall = 0.63639, Jaccard score = 0.2403, loss = 0.030001, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 242 fit: [34.2 s]: Recall = 0.63525, Jaccard score = 0.2398, loss = 0.030709, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 243 fit: [34.1 s]: Recall = 0.63365, Jaccard score = 0.2390, loss = 0.030265, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 244 fit: [34.2 s]: Recall = 0.63297, Jaccard score = 0.2387, loss = 0.030179, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 245 fit: [34.1 s]: Recall = 0.62337, Jaccard score = 0.2342, loss = 0.030463, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 246 fit: [34.1 s]: Recall = 0.63377, Jaccard score = 0.2391, loss = 0.030891, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 247 fit: [34.2 s]: Recall = 0.62520, Jaccard score = 0.2351, loss = 0.031758, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 248 fit: [34.2 s]: Recall = 0.63240, Jaccard score = 0.2384, loss = 0.029937, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 249 fit: [34.2 s]: Recall = 0.63605, Jaccard score = 0.2401, loss = 0.030710, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 250 fit: [34.1 s]: Recall = 0.63160, Jaccard score = 0.2381, loss = 0.030529, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 251 fit: [34.1 s]: Recall = 0.62988, Jaccard score = 0.2373, loss = 0.031667, gradient norm = 1.0000, eval: [8.7 s]
# Iteration 252 fit: [34.2 s]: Recall = 0.62966, Jaccard score = 0.2372, loss = 0.031048, gradient norm = 1.0000, eval: [8.6 s]
# Iteration 253 fit: [34.1 s]: Recall = 0.63468, Jaccard score = 0.2395, loss = 0.031573, gradient norm = 1.0000, eval: [8.6 s]
# End. Best Iteration 103:  Recall = 0.6612, Jaccard score = 0.2520. 
# The best NeuMF model has been saved to Pretrain/_MLP_8_[512,750,350,96]_1569446277.h5
