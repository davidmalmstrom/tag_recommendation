--nn_model: NeuMF
--is_tag: "1"
--eval_recall: "1"
--topk: "10"
--big_tag: "0"
--epochs: "600"
--lr: "0.00001"
--num_factors: "94"
--early_stopping: "600"
--layers: "[512,750,350,96]"
--reg_layers: "[0.000001,0.000001,0.000001,0.000001]"
--test_dataset: "1"
--mf_pretrain: "Pretrain/_GMF_94_[64,32,16,8]_1569324855.h5"
--mlp_pretrain: "Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5"


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=5e-05, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5', mlp_pretrain='Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0.000001,0.000001,0.000001,0.000001]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,750,350,96]_1569319072.h5
--weights_path: Pretrain/_NeuMF_94_[512,750,350,96]_1569319072.h5
# Load data done [1.6 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5) and MLP (Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      layer1[0][0]                     
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       layer2[0][0]                     
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 9,131,487
# Trainable params: 9,131,487
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.1856, Jaccard score = 0.1238
# Iteration 0 fit: [41.9 s]: Recall = 0.17626, Jaccard score = 0.1168, loss = 0.026837, gradient norm = 1.0000, eval: [43.3 s]


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=5e-05, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5', mlp_pretrain='Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0.000001,0.000001,0.000001,0.000001]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,750,350,96]_1569319251.h5
--weights_path: Pretrain/_NeuMF_94_[512,750,350,96]_1569319251.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5) and MLP (Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      layer1[0][0]                     
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       layer2[0][0]                     
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 9,131,487
# Trainable params: 9,131,487
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=1e-05, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5', mlp_pretrain='Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0.000001,0.000001,0.000001,0.000001]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,750,350,96]_1569319285.h5
--weights_path: Pretrain/_NeuMF_94_[512,750,350,96]_1569319285.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5) and MLP (Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      layer1[0][0]                     
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       layer2[0][0]                     
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 9,131,487
# Trainable params: 9,131,487
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.3249, Jaccard score = 0.1098
# Iteration 0 fit: [41.7 s]: Recall = 0.32351, Jaccard score = 0.1093, loss = 0.036222, gradient norm = 1.0000, eval: [44.1 s]
# Iteration 1 fit: [40.8 s]: Recall = 0.32214, Jaccard score = 0.1087, loss = 0.030564, gradient norm = 1.0000, eval: [44.3 s]
# Iteration 2 fit: [40.7 s]: Recall = 0.31837, Jaccard score = 0.1073, loss = 0.026440, gradient norm = 1.0000, eval: [43.6 s]
# Iteration 3 fit: [40.9 s]: Recall = 0.31654, Jaccard score = 0.1066, loss = 0.023438, gradient norm = 1.0000, eval: [44.5 s]
# Iteration 4 fit: [40.7 s]: Recall = 0.31483, Jaccard score = 0.1060, loss = 0.021062, gradient norm = 1.0000, eval: [44.2 s]
# Iteration 5 fit: [40.9 s]: Recall = 0.31197, Jaccard score = 0.1049, loss = 0.019129, gradient norm = 1.0000, eval: [44.3 s]
# Iteration 6 fit: [40.8 s]: Recall = 0.31049, Jaccard score = 0.1044, loss = 0.017646, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 7 fit: [40.8 s]: Recall = 0.31003, Jaccard score = 0.1042, loss = 0.016268, gradient norm = 1.0000, eval: [44.3 s]
# Iteration 8 fit: [40.9 s]: Recall = 0.30832, Jaccard score = 0.1036, loss = 0.015198, gradient norm = 1.0000, eval: [44.4 s]
# Iteration 9 fit: [40.7 s]: Recall = 0.30775, Jaccard score = 0.1034, loss = 0.014384, gradient norm = 1.0000, eval: [44.0 s]
# Iteration 10 fit: [40.8 s]: Recall = 0.30500, Jaccard score = 0.1024, loss = 0.013488, gradient norm = 1.0000, eval: [43.3 s]
# Iteration 11 fit: [40.9 s]: Recall = 0.30272, Jaccard score = 0.1015, loss = 0.012851, gradient norm = 1.0000, eval: [43.1 s]
# Iteration 12 fit: [41.0 s]: Recall = 0.30192, Jaccard score = 0.1012, loss = 0.012337, gradient norm = 1.0000, eval: [43.9 s]
# Iteration 13 fit: [41.1 s]: Recall = 0.30169, Jaccard score = 0.1011, loss = 0.011621, gradient norm = 1.0000, eval: [44.2 s]
# Iteration 14 fit: [40.9 s]: Recall = 0.30089, Jaccard score = 0.1008, loss = 0.011225, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 15 fit: [40.9 s]: Recall = 0.30101, Jaccard score = 0.1009, loss = 0.010740, gradient norm = 1.0000, eval: [44.1 s]
# Iteration 16 fit: [40.7 s]: Recall = 0.29986, Jaccard score = 0.1005, loss = 0.010403, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 17 fit: [40.7 s]: Recall = 0.29986, Jaccard score = 0.1005, loss = 0.010130, gradient norm = 1.0000, eval: [44.2 s]
# Iteration 18 fit: [40.9 s]: Recall = 0.29872, Jaccard score = 0.1000, loss = 0.009695, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 19 fit: [40.7 s]: Recall = 0.29735, Jaccard score = 0.0995, loss = 0.009381, gradient norm = 1.0000, eval: [44.2 s]
# Iteration 20 fit: [40.9 s]: Recall = 0.29609, Jaccard score = 0.0991, loss = 0.009114, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 21 fit: [40.6 s]: Recall = 0.29621, Jaccard score = 0.0991, loss = 0.008724, gradient norm = 1.0000, eval: [44.4 s]
# Iteration 22 fit: [41.0 s]: Recall = 0.29609, Jaccard score = 0.0991, loss = 0.008552, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 23 fit: [40.8 s]: Recall = 0.29746, Jaccard score = 0.0996, loss = 0.008325, gradient norm = 1.0000, eval: [44.4 s]
# Iteration 24 fit: [40.9 s]: Recall = 0.29678, Jaccard score = 0.0993, loss = 0.008018, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 25 fit: [41.0 s]: Recall = 0.29312, Jaccard score = 0.0980, loss = 0.007895, gradient norm = 1.0000, eval: [44.4 s]
# Iteration 26 fit: [40.7 s]: Recall = 0.29415, Jaccard score = 0.0984, loss = 0.007741, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 27 fit: [40.8 s]: Recall = 0.29152, Jaccard score = 0.0974, loss = 0.007596, gradient norm = 1.0000, eval: [44.2 s]
# Iteration 28 fit: [41.1 s]: Recall = 0.29072, Jaccard score = 0.0971, loss = 0.007374, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 29 fit: [40.8 s]: Recall = 0.29095, Jaccard score = 0.0972, loss = 0.007199, gradient norm = 1.0000, eval: [44.5 s]
# Iteration 30 fit: [40.9 s]: Recall = 0.29072, Jaccard score = 0.0971, loss = 0.007023, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 31 fit: [41.2 s]: Recall = 0.29095, Jaccard score = 0.0972, loss = 0.006848, gradient norm = 1.0000, eval: [44.4 s]
# Iteration 32 fit: [40.8 s]: Recall = 0.29221, Jaccard score = 0.0976, loss = 0.006747, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 33 fit: [40.8 s]: Recall = 0.29038, Jaccard score = 0.0970, loss = 0.006664, gradient norm = 1.0000, eval: [43.7 s]
# Iteration 34 fit: [40.8 s]: Recall = 0.29255, Jaccard score = 0.0978, loss = 0.006499, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 35 fit: [40.9 s]: Recall = 0.29072, Jaccard score = 0.0971, loss = 0.006430, gradient norm = 1.0000, eval: [44.0 s]
# Iteration 36 fit: [40.9 s]: Recall = 0.29015, Jaccard score = 0.0969, loss = 0.006245, gradient norm = 1.0000, eval: [43.3 s]
# Iteration 37 fit: [41.0 s]: Recall = 0.29015, Jaccard score = 0.0969, loss = 0.006271, gradient norm = 1.0000, eval: [43.1 s]
# Iteration 38 fit: [41.1 s]: Recall = 0.28970, Jaccard score = 0.0967, loss = 0.006120, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 39 fit: [41.3 s]: Recall = 0.28890, Jaccard score = 0.0964, loss = 0.005909, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 40 fit: [40.9 s]: Recall = 0.28810, Jaccard score = 0.0961, loss = 0.005908, gradient norm = 1.0000, eval: [43.3 s]
# Iteration 41 fit: [40.8 s]: Recall = 0.28844, Jaccard score = 0.0963, loss = 0.005849, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 42 fit: [40.8 s]: Recall = 0.28741, Jaccard score = 0.0959, loss = 0.005741, gradient norm = 1.0000, eval: [43.4 s]
# Iteration 43 fit: [40.8 s]: Recall = 0.28593, Jaccard score = 0.0953, loss = 0.005584, gradient norm = 1.0000, eval: [43.2 s]
# Iteration 44 fit: [41.7 s]: Recall = 0.28661, Jaccard score = 0.0956, loss = 0.005608, gradient norm = 1.0000, eval: [43.5 s]
# Iteration 45 fit: [40.7 s]: Recall = 0.28650, Jaccard score = 0.0956, loss = 0.005462, gradient norm = 1.0000, eval: [44.1 s]
# Iteration 46 fit: [40.8 s]: Recall = 0.28570, Jaccard score = 0.0953, loss = 0.005343, gradient norm = 1.0000, eval: [43.5 s]


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.0001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5', mlp_pretrain='Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0.000001,0.000001,0.000001,0.000001]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,750,350,96]_1569323640.h5
--weights_path: Pretrain/_NeuMF_94_[512,750,350,96]_1569323640.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1568836629.h5) and MLP (Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      layer1[0][0]                     
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       layer2[0][0]                     
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 9,131,487
# Trainable params: 9,131,487
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.3249, Jaccard score = 0.1098
# Iteration 0 fit: [41.7 s]: Recall = 0.29472, Jaccard score = 0.0986, loss = 0.021306, gradient norm = 1.0000, eval: [43.3 s]


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=0.0001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1569324855.h5', mlp_pretrain='Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0.000001,0.000001,0.000001,0.000001]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,750,350,96]_1569326241.h5
--weights_path: Pretrain/_NeuMF_94_[512,750,350,96]_1569326241.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1569324855.h5) and MLP (Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      layer1[0][0]                     
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       layer2[0][0]                     
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 9,131,487
# Trainable params: 9,131,487
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.3441, Jaccard score = 0.1170
# Iteration 0 fit: [43.2 s]: Recall = 0.33173, Jaccard score = 0.1123, loss = 0.247484, gradient norm = 1.0000, eval: [43.6 s]
# Iteration 1 fit: [42.3 s]: Recall = 0.32328, Jaccard score = 0.1092, loss = 0.216033, gradient norm = 1.0000, eval: [44.1 s]


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=600, epochs=600, eval_recall=1, is_tag=1, layers='[512,750,350,96]', learner='adam', lr=1e-05, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1569324855.h5', mlp_pretrain='Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0.000001,0.000001,0.000001,0.000001]', reg_mf=0, test_dataset=1, topk=10, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,750,350,96]_1569326480.h5
--weights_path: Pretrain/_NeuMF_94_[512,750,350,96]_1569326480.h5
# Load data done [1.8 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1569324855.h5) and MLP (Pretrain/_MLP_8_[512,750,350,96]_1569313396.h5) models done. 
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# mlp_embedding_user (Embedding)  (None, 1, 256)       5120000     user_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 256)          0           mlp_embedding_user[0][0]         
# __________________________________________________________________________________________________
# user_feature_input (InputLayer) (None, 1000)         0                                            
# __________________________________________________________________________________________________
# mlp_embedding_item (Embedding)  (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 1256)         0           flatten_3[0][0]                  
#                                                                  user_feature_input[0][0]         
# __________________________________________________________________________________________________
# flatten_4 (Flatten)             (None, 256)          0           mlp_embedding_item[0][0]         
# __________________________________________________________________________________________________
# concatenate_2 (Concatenate)     (None, 1512)         0           concatenate_1[0][0]              
#                                                                  flatten_4[0][0]                  
# __________________________________________________________________________________________________
# mf_embedding_user (Embedding)   (None, 1, 94)        1880000     user_input[0][0]                 
# __________________________________________________________________________________________________
# mf_embedding_item (Embedding)   (None, 1, 94)        188000      item_input[0][0]                 
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 750)          1134750     concatenate_2[0][0]              
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 94)           0           mf_embedding_user[0][0]          
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 94)           0           mf_embedding_item[0][0]          
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 350)          262850      layer1[0][0]                     
# __________________________________________________________________________________________________
# multiply_1 (Multiply)           (None, 94)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 96)           33696       layer2[0][0]                     
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 190)          0           multiply_1[0][0]                 
#                                                                  layer3[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            191         concatenate_3[0][0]              
# ==================================================================================================
# Total params: 9,131,487
# Trainable params: 9,131,487
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.3441, Jaccard score = 0.1170
# Iteration 0 fit: [43.3 s]: Recall = 0.34110, Jaccard score = 0.1159, loss = 0.273343, gradient norm = 1.0000, eval: [44.7 s]
# Iteration 1 fit: [41.9 s]: Recall = 0.33687, Jaccard score = 0.1143, loss = 0.266118, gradient norm = 1.0000, eval: [43.7 s]
# Iteration 2 fit: [42.4 s]: Recall = 0.33642, Jaccard score = 0.1141, loss = 0.261251, gradient norm = 1.0000, eval: [45.3 s]
# Iteration 3 fit: [42.5 s]: Recall = 0.33619, Jaccard score = 0.1140, loss = 0.256781, gradient norm = 1.0000, eval: [43.8 s]
# Model test performed 
# Recall score: 0.3425574648515956     Jaccard score: 0.11856944229877954