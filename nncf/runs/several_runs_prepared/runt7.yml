--nn_model: MLP
--is_tag: "1"
--eval_recall: "1"
--topk: "3"
--big_tag: "0"
--epochs: "300"
--layers: "[512,256]"
--reg_layers: "[0,0]"
--early_stopping: "35"
--test_dataset: "1"
--percentage: "0.0"
--dataset_name_prepend: "cold_0.0_"

# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[64,64]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[64,64]_1563978066.h5
# --weights_path: Pretrain/_MLP_8_[64,64]_1563978066.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0287, Jaccard score = 0.0219
# # Iteration 0 fit: [11.5 s]: Recall = 0.1593, Jaccard score = 0.1352, loss = 0.4435, eval: [6.6 s]
# # Iteration 1 fit: [11.2 s]: Recall = 0.1755, Jaccard score = 0.1511, loss = 0.4030, eval: [6.5 s]
# # Iteration 2 fit: [11.2 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.3880, eval: [6.6 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.3740, eval: [6.6 s]
# # Iteration 4 fit: [11.1 s]: Recall = 0.1879, Jaccard score = 0.1635, loss = 0.3624, eval: [6.5 s]
# # Iteration 5 fit: [11.2 s]: Recall = 0.1883, Jaccard score = 0.1639, loss = 0.3506, eval: [6.6 s]
# # Iteration 6 fit: [11.1 s]: Recall = 0.1873, Jaccard score = 0.1629, loss = 0.3403, eval: [6.5 s]
# # Iteration 7 fit: [11.1 s]: Recall = 0.1868, Jaccard score = 0.1624, loss = 0.3296, eval: [6.6 s]
# # Iteration 8 fit: [11.8 s]: Recall = 0.1833, Jaccard score = 0.1589, loss = 0.3201, eval: [6.6 s]
# # Iteration 9 fit: [11.1 s]: Recall = 0.1783, Jaccard score = 0.1539, loss = 0.3105, eval: [6.5 s]
# # Iteration 10 fit: [11.3 s]: Recall = 0.1751, Jaccard score = 0.1507, loss = 0.3022, eval: [6.5 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[16,300]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[16,300]_1563978295.h5
# --weights_path: Pretrain/_MLP_8_[16,300]_1563978295.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0238, Jaccard score = 0.0181
# # Iteration 0 fit: [11.3 s]: Recall = 0.1468, Jaccard score = 0.1233, loss = 0.4618, eval: [6.5 s]
# # Iteration 1 fit: [10.9 s]: Recall = 0.1610, Jaccard score = 0.1369, loss = 0.4169, eval: [6.5 s]
# # Iteration 2 fit: [11.6 s]: Recall = 0.1725, Jaccard score = 0.1482, loss = 0.4040, eval: [6.7 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1755, Jaccard score = 0.1511, loss = 0.3947, eval: [6.6 s]
# # Iteration 4 fit: [10.9 s]: Recall = 0.1813, Jaccard score = 0.1569, loss = 0.3851, eval: [6.6 s]
# # Iteration 5 fit: [11.1 s]: Recall = 0.1867, Jaccard score = 0.1623, loss = 0.3758, eval: [6.6 s]
# # Iteration 6 fit: [11.0 s]: Recall = 0.1855, Jaccard score = 0.1610, loss = 0.3670, eval: [6.6 s]
# # Iteration 7 fit: [11.1 s]: Recall = 0.1859, Jaccard score = 0.1614, loss = 0.3585, eval: [6.6 s]
# # Iteration 8 fit: [11.1 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3504, eval: [6.5 s]
# # Iteration 9 fit: [11.1 s]: Recall = 0.1851, Jaccard score = 0.1607, loss = 0.3424, eval: [6.7 s]
# # Iteration 10 fit: [11.0 s]: Recall = 0.1862, Jaccard score = 0.1618, loss = 0.3346, eval: [6.7 s]
# # Iteration 11 fit: [11.0 s]: Recall = 0.1829, Jaccard score = 0.1584, loss = 0.3287, eval: [6.7 s]
# # Iteration 12 fit: [11.1 s]: Recall = 0.1827, Jaccard score = 0.1583, loss = 0.3214, eval: [6.7 s]
# # Iteration 13 fit: [11.6 s]: Recall = 0.1820, Jaccard score = 0.1575, loss = 0.3152, eval: [6.5 s]
# # Iteration 14 fit: [11.0 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.3083, eval: [6.7 s]
# # Iteration 15 fit: [11.1 s]: Recall = 0.1780, Jaccard score = 0.1536, loss = 0.3030, eval: [6.5 s]
# # Iteration 16 fit: [11.1 s]: Recall = 0.1776, Jaccard score = 0.1532, loss = 0.2980, eval: [6.6 s]
# # Iteration 17 fit: [11.1 s]: Recall = 0.1729, Jaccard score = 0.1485, loss = 0.2920, eval: [6.5 s]
# # Iteration 18 fit: [11.1 s]: Recall = 0.1742, Jaccard score = 0.1498, loss = 0.2868, eval: [6.8 s]
# # Iteration 19 fit: [12.2 s]: Recall = 0.1718, Jaccard score = 0.1474, loss = 0.2822, eval: [6.5 s]
# # Iteration 20 fit: [11.2 s]: Recall = 0.1674, Jaccard score = 0.1431, loss = 0.2767, eval: [6.6 s]
# # Iteration 21 fit: [11.0 s]: Recall = 0.1696, Jaccard score = 0.1453, loss = 0.2732, eval: [6.7 s]
# # Model test performed 
# # Recall score: 0.055224867724867725     Jaccard score: 0.04329789992221934

# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[16,200]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[16,200]_1563978794.h5
# --weights_path: Pretrain/_MLP_8_[16,200]_1563978794.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0271, Jaccard score = 0.0207
# # Iteration 0 fit: [10.8 s]: Recall = 0.1406, Jaccard score = 0.1175, loss = 0.4647, eval: [6.7 s]
# # Iteration 1 fit: [11.0 s]: Recall = 0.1601, Jaccard score = 0.1360, loss = 0.4172, eval: [6.7 s]
# # Iteration 2 fit: [10.5 s]: Recall = 0.1699, Jaccard score = 0.1456, loss = 0.4052, eval: [6.6 s]
# # Iteration 3 fit: [10.7 s]: Recall = 0.1747, Jaccard score = 0.1503, loss = 0.3955, eval: [6.6 s]
# # Iteration 4 fit: [10.7 s]: Recall = 0.1829, Jaccard score = 0.1584, loss = 0.3858, eval: [6.7 s]
# # Iteration 5 fit: [10.5 s]: Recall = 0.1860, Jaccard score = 0.1616, loss = 0.3773, eval: [6.7 s]
# # Iteration 6 fit: [10.5 s]: Recall = 0.1860, Jaccard score = 0.1616, loss = 0.3687, eval: [6.6 s]
# # Iteration 7 fit: [10.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3609, eval: [6.7 s]
# # Iteration 8 fit: [10.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3533, eval: [6.7 s]
# # Iteration 9 fit: [10.5 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.3458, eval: [6.5 s]
# # Iteration 10 fit: [10.7 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3387, eval: [6.5 s]
# # Iteration 11 fit: [10.5 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3321, eval: [6.6 s]
# # Iteration 12 fit: [10.6 s]: Recall = 0.1863, Jaccard score = 0.1619, loss = 0.3260, eval: [6.7 s]
# # Iteration 13 fit: [10.7 s]: Recall = 0.1868, Jaccard score = 0.1624, loss = 0.3201, eval: [6.6 s]
# # Iteration 14 fit: [10.5 s]: Recall = 0.1820, Jaccard score = 0.1575, loss = 0.3151, eval: [6.6 s]
# # Iteration 15 fit: [10.3 s]: Recall = 0.1839, Jaccard score = 0.1595, loss = 0.3098, eval: [6.7 s]
# # Iteration 16 fit: [11.2 s]: Recall = 0.1830, Jaccard score = 0.1586, loss = 0.3040, eval: [6.5 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,200]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[32,200]_1563979110.h5
# --weights_path: Pretrain/_MLP_8_[32,200]_1563979110.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0299, Jaccard score = 0.0229
# # Iteration 0 fit: [12.1 s]: Recall = 0.1593, Jaccard score = 0.1353, loss = 0.4492, eval: [6.7 s]
# # Iteration 1 fit: [11.1 s]: Recall = 0.1708, Jaccard score = 0.1464, loss = 0.4073, eval: [6.7 s]
# # Iteration 2 fit: [11.1 s]: Recall = 0.1833, Jaccard score = 0.1588, loss = 0.3931, eval: [6.7 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3807, eval: [6.7 s]
# # Iteration 4 fit: [11.1 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3688, eval: [6.7 s]
# # Iteration 5 fit: [11.1 s]: Recall = 0.1889, Jaccard score = 0.1646, loss = 0.3583, eval: [6.5 s]
# # Iteration 6 fit: [11.2 s]: Recall = 0.1918, Jaccard score = 0.1674, loss = 0.3471, eval: [6.6 s]
# # Iteration 7 fit: [11.1 s]: Recall = 0.1909, Jaccard score = 0.1666, loss = 0.3372, eval: [6.7 s]
# # Iteration 8 fit: [11.1 s]: Recall = 0.1907, Jaccard score = 0.1664, loss = 0.3283, eval: [6.7 s]
# # Iteration 9 fit: [11.1 s]: Recall = 0.1909, Jaccard score = 0.1666, loss = 0.3185, eval: [6.7 s]
# # Iteration 10 fit: [11.1 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3101, eval: [6.7 s]
# # Iteration 11 fit: [11.2 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.3019, eval: [6.7 s]
# # Iteration 12 fit: [11.2 s]: Recall = 0.1823, Jaccard score = 0.1578, loss = 0.2942, eval: [6.7 s]
# # Iteration 13 fit: [11.1 s]: Recall = 0.1797, Jaccard score = 0.1552, loss = 0.2864, eval: [6.7 s]
# # Iteration 14 fit: [11.2 s]: Recall = 0.1789, Jaccard score = 0.1545, loss = 0.2788, eval: [6.7 s]
# # Iteration 15 fit: [11.1 s]: Recall = 0.1761, Jaccard score = 0.1517, loss = 0.2720, eval: [6.7 s]
# # Iteration 16 fit: [11.1 s]: Recall = 0.1753, Jaccard score = 0.1509, loss = 0.2657, eval: [6.7 s]
# # Iteration 17 fit: [11.1 s]: Recall = 0.1679, Jaccard score = 0.1436, loss = 0.2589, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1,1024]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[1,1024]_1563979483.h5
# --weights_path: Pretrain/_MLP_8_[1,1024]_1563979483.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'ValueError'>: The shape of the input to "Flatten" is not fully defined (got (1, 0). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,1024]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,1024]_1563979516.h5
# --weights_path: Pretrain/_MLP_8_[4,1024]_1563979516.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 2)         40000       user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 2)            0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 2)         4000        item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1002)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 2)            0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1004)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 1024)         1029120     concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            1025        layer1[0][0]                     
# # ==================================================================================================
# # Total params: 1,074,145
# # Trainable params: 1,074,145
# # Non-trainable params: 0
# # __________________________________________________________________________________________________


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,1024]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,1024]_1563979535.h5
# --weights_path: Pretrain/_MLP_8_[4,1024]_1563979535.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0265, Jaccard score = 0.0202
# # Iteration 0 fit: [12.6 s]: Recall = 0.1217, Jaccard score = 0.1001, loss = 0.4847, eval: [6.7 s]
# # Iteration 1 fit: [12.6 s]: Recall = 0.1442, Jaccard score = 0.1209, loss = 0.4350, eval: [6.7 s]
# # Iteration 2 fit: [12.5 s]: Recall = 0.1496, Jaccard score = 0.1259, loss = 0.4204, eval: [6.8 s]
# # Iteration 3 fit: [12.5 s]: Recall = 0.1525, Jaccard score = 0.1288, loss = 0.4152, eval: [6.7 s]
# # Iteration 4 fit: [12.5 s]: Recall = 0.1544, Jaccard score = 0.1306, loss = 0.4117, eval: [6.9 s]
# # Iteration 5 fit: [12.7 s]: Recall = 0.1567, Jaccard score = 0.1327, loss = 0.4083, eval: [6.9 s]
# # Iteration 6 fit: [12.6 s]: Recall = 0.1551, Jaccard score = 0.1312, loss = 0.4055, eval: [6.9 s]
# # Iteration 7 fit: [12.6 s]: Recall = 0.1581, Jaccard score = 0.1341, loss = 0.4029, eval: [6.9 s]
# # Iteration 8 fit: [12.5 s]: Recall = 0.1575, Jaccard score = 0.1336, loss = 0.3997, eval: [6.8 s]
# # Iteration 9 fit: [12.6 s]: Recall = 0.1569, Jaccard score = 0.1330, loss = 0.3965, eval: [6.8 s]
# # Iteration 10 fit: [12.6 s]: Recall = 0.1558, Jaccard score = 0.1319, loss = 0.3935, eval: [6.8 s]
# # Iteration 11 fit: [12.5 s]: Recall = 0.1606, Jaccard score = 0.1365, loss = 0.3904, eval: [6.7 s]
# # Iteration 12 fit: [12.5 s]: Recall = 0.1589, Jaccard score = 0.1349, loss = 0.3879, eval: [6.9 s]
# # Iteration 13 fit: [12.6 s]: Recall = 0.1596, Jaccard score = 0.1356, loss = 0.3852, eval: [6.7 s]
# # Iteration 14 fit: [12.6 s]: Recall = 0.1599, Jaccard score = 0.1358, loss = 0.3823, eval: [6.7 s]
# # Iteration 15 fit: [12.5 s]: Recall = 0.1569, Jaccard score = 0.1329, loss = 0.3794, eval: [6.9 s]
# # Iteration 16 fit: [12.5 s]: Recall = 0.1591, Jaccard score = 0.1350, loss = 0.3770, eval: [6.7 s]
# # Iteration 17 fit: [12.6 s]: Recall = 0.1555, Jaccard score = 0.1316, loss = 0.3739, eval: [6.9 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,512,512]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,512,512]_1563979921.h5
# --weights_path: Pretrain/_MLP_8_[4,512,512]_1563979921.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'AssertionError'>: 


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,512,512]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,512,512]_1563979934.h5
# --weights_path: Pretrain/_MLP_8_[4,512,512]_1563979934.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0244, Jaccard score = 0.0186
# # Iteration 0 fit: [13.0 s]: Recall = 0.1319, Jaccard score = 0.1094, loss = 0.4769, eval: [6.8 s]
# # Iteration 1 fit: [12.3 s]: Recall = 0.1438, Jaccard score = 0.1205, loss = 0.4295, eval: [6.8 s]
# # Iteration 2 fit: [12.9 s]: Recall = 0.1523, Jaccard score = 0.1286, loss = 0.4166, eval: [6.8 s]
# # Iteration 3 fit: [12.3 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.4102, eval: [6.8 s]
# # Iteration 4 fit: [12.3 s]: Recall = 0.1584, Jaccard score = 0.1344, loss = 0.4043, eval: [6.8 s]
# # Iteration 5 fit: [12.3 s]: Recall = 0.1595, Jaccard score = 0.1354, loss = 0.3988, eval: [6.8 s]
# # Iteration 6 fit: [12.6 s]: Recall = 0.1604, Jaccard score = 0.1363, loss = 0.3926, eval: [6.9 s]
# # Iteration 7 fit: [12.4 s]: Recall = 0.1589, Jaccard score = 0.1349, loss = 0.3862, eval: [6.8 s]
# # Iteration 8 fit: [12.3 s]: Recall = 0.1626, Jaccard score = 0.1385, loss = 0.3800, eval: [6.8 s]
# # Iteration 9 fit: [12.3 s]: Recall = 0.1630, Jaccard score = 0.1388, loss = 0.3733, eval: [6.8 s]
# # Iteration 10 fit: [12.3 s]: Recall = 0.1620, Jaccard score = 0.1378, loss = 0.3678, eval: [6.7 s]
# # Iteration 11 fit: [12.3 s]: Recall = 0.1632, Jaccard score = 0.1390, loss = 0.3621, eval: [6.8 s]
# # Iteration 12 fit: [12.3 s]: Recall = 0.1648, Jaccard score = 0.1406, loss = 0.3566, eval: [6.8 s]
# # Iteration 13 fit: [12.6 s]: Recall = 0.1634, Jaccard score = 0.1393, loss = 0.3512, eval: [6.8 s]
# # Iteration 14 fit: [12.3 s]: Recall = 0.1600, Jaccard score = 0.1359, loss = 0.3463, eval: [6.8 s]
# # Iteration 15 fit: [12.4 s]: Recall = 0.1571, Jaccard score = 0.1332, loss = 0.3413, eval: [6.8 s]
# # Iteration 16 fit: [12.3 s]: Recall = 0.1611, Jaccard score = 0.1370, loss = 0.3370, eval: [6.8 s]
# # Iteration 17 fit: [12.3 s]: Recall = 0.1615, Jaccard score = 0.1373, loss = 0.3323, eval: [6.7 s]
# # Iteration 18 fit: [12.3 s]: Recall = 0.1592, Jaccard score = 0.1352, loss = 0.3282, eval: [6.8 s]
# # Iteration 19 fit: [12.3 s]: Recall = 0.1546, Jaccard score = 0.1308, loss = 0.3239, eval: [6.8 s]
# # Iteration 20 fit: [12.3 s]: Recall = 0.1573, Jaccard score = 0.1333, loss = 0.3202, eval: [6.7 s]
# # Iteration 21 fit: [12.3 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.3160, eval: [6.7 s]
# # Iteration 22 fit: [12.3 s]: Recall = 0.1534, Jaccard score = 0.1296, loss = 0.3117, eval: [6.7 s]
# # Iteration 23 fit: [12.2 s]: Recall = 0.1543, Jaccard score = 0.1304, loss = 0.3094, eval: [6.8 s]
# # Iteration 24 fit: [12.3 s]: Recall = 0.1528, Jaccard score = 0.1290, loss = 0.3056, eval: [6.8 s]
# # Iteration 25 fit: [12.3 s]: Recall = 0.1541, Jaccard score = 0.1302, loss = 0.3016, eval: [6.8 s]
# # Iteration 26 fit: [12.3 s]: Recall = 0.1502, Jaccard score = 0.1265, loss = 0.2994, eval: [6.8 s]
# # Iteration 27 fit: [12.3 s]: Recall = 0.1506, Jaccard score = 0.1269, loss = 0.2969, eval: [6.7 s]
# # Iteration 28 fit: [12.3 s]: Recall = 0.1496, Jaccard score = 0.1259, loss = 0.2932, eval: [6.8 s]
# # Iteration 29 fit: [12.3 s]: Recall = 0.1516, Jaccard score = 0.1279, loss = 0.2909, eval: [6.8 s]
# # Iteration 30 fit: [12.3 s]: Recall = 0.1465, Jaccard score = 0.1230, loss = 0.2873, eval: [6.8 s]
# # Iteration 31 fit: [12.3 s]: Recall = 0.1478, Jaccard score = 0.1242, loss = 0.2858, eval: [6.8 s]
# # Iteration 32 fit: [12.2 s]: Recall = 0.1489, Jaccard score = 0.1254, loss = 0.2831, eval: [6.8 s]
# # Iteration 33 fit: [12.3 s]: Recall = 0.1451, Jaccard score = 0.1217, loss = 0.2811, eval: [6.8 s]
# # Iteration 34 fit: [12.3 s]: Recall = 0.1474, Jaccard score = 0.1239, loss = 0.2785, eval: [6.8 s]
# # Iteration 35 fit: [12.3 s]: Recall = 0.1467, Jaccard score = 0.1233, loss = 0.2763, eval: [6.8 s]
# # Iteration 36 fit: [12.3 s]: Recall = 0.1426, Jaccard score = 0.1194, loss = 0.2740, eval: [6.8 s]
# # Iteration 37 fit: [12.3 s]: Recall = 0.1413, Jaccard score = 0.1182, loss = 0.2722, eval: [6.8 s]
# # Iteration 38 fit: [12.3 s]: Recall = 0.1450, Jaccard score = 0.1216, loss = 0.2701, eval: [6.8 s]
# # Iteration 39 fit: [12.3 s]: Recall = 0.1415, Jaccard score = 0.1184, loss = 0.2680, eval: [6.8 s]
# # Iteration 40 fit: [12.3 s]: Recall = 0.1379, Jaccard score = 0.1150, loss = 0.2657, eval: [6.7 s]
# # Iteration 41 fit: [12.3 s]: Recall = 0.1437, Jaccard score = 0.1204, loss = 0.2651, eval: [6.8 s]
# # Iteration 42 fit: [12.3 s]: Recall = 0.1421, Jaccard score = 0.1189, loss = 0.2637, eval: [6.7 s]
# # Iteration 43 fit: [12.3 s]: Recall = 0.1396, Jaccard score = 0.1165, loss = 0.2612, eval: [6.7 s]
# # Iteration 44 fit: [12.2 s]: Recall = 0.1385, Jaccard score = 0.1155, loss = 0.2595, eval: [6.8 s]
# # Iteration 45 fit: [12.3 s]: Recall = 0.1369, Jaccard score = 0.1141, loss = 0.2574, eval: [6.8 s]
# # Iteration 46 fit: [12.4 s]: Recall = 0.1403, Jaccard score = 0.1173, loss = 0.2567, eval: [6.8 s]
# # Iteration 47 fit: [12.3 s]: Recall = 0.1378, Jaccard score = 0.1149, loss = 0.2550, eval: [6.8 s]
# # End. Best Iteration 12:  Recall = 0.1648, Jaccard score = 0.1406. 
# # The best NeuMF model has been saved to Pretrain/_MLP_8_[4,512,512]_1563979934.h5


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,128,128,128]_1563995964.h5
# --weights_path: Pretrain/_MLP_8_[4,128,128,128]_1563995964.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'AssertionError'>: 


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,128,128,128]_1563995977.h5
# --weights_path: Pretrain/_MLP_8_[4,128,128,128]_1563995977.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0272, Jaccard score = 0.0208
# # Iteration 0 fit: [11.7 s]: Recall = 0.1220, Jaccard score = 0.1004, loss = 0.4743, eval: [6.7 s]
# # Iteration 1 fit: [11.4 s]: Recall = 0.1376, Jaccard score = 0.1148, loss = 0.4303, eval: [6.7 s]
# # Iteration 2 fit: [11.4 s]: Recall = 0.1471, Jaccard score = 0.1236, loss = 0.4173, eval: [6.9 s]
# # Iteration 3 fit: [11.4 s]: Recall = 0.1516, Jaccard score = 0.1279, loss = 0.4108, eval: [6.9 s]
# # Iteration 4 fit: [11.5 s]: Recall = 0.1543, Jaccard score = 0.1305, loss = 0.4057, eval: [6.8 s]
# # Iteration 5 fit: [11.4 s]: Recall = 0.1568, Jaccard score = 0.1329, loss = 0.4009, eval: [6.9 s]
# # Iteration 6 fit: [11.5 s]: Recall = 0.1606, Jaccard score = 0.1365, loss = 0.3959, eval: [6.8 s]
# # Iteration 7 fit: [11.5 s]: Recall = 0.1598, Jaccard score = 0.1358, loss = 0.3915, eval: [6.9 s]
# # Iteration 8 fit: [11.5 s]: Recall = 0.1603, Jaccard score = 0.1362, loss = 0.3874, eval: [6.8 s]
# # Iteration 9 fit: [11.5 s]: Recall = 0.1614, Jaccard score = 0.1372, loss = 0.3832, eval: [6.8 s]
# # Iteration 10 fit: [11.8 s]: Recall = 0.1618, Jaccard score = 0.1376, loss = 0.3777, eval: [6.9 s]
# # Iteration 11 fit: [11.6 s]: Recall = 0.1615, Jaccard score = 0.1374, loss = 0.3740, eval: [6.9 s]
# # Iteration 12 fit: [11.6 s]: Recall = 0.1608, Jaccard score = 0.1367, loss = 0.3699, eval: [6.9 s]
# # Iteration 13 fit: [11.5 s]: Recall = 0.1619, Jaccard score = 0.1377, loss = 0.3666, eval: [6.9 s]
# # Iteration 14 fit: [11.4 s]: Recall = 0.1650, Jaccard score = 0.1407, loss = 0.3625, eval: [6.9 s]
# # Iteration 15 fit: [11.6 s]: Recall = 0.1600, Jaccard score = 0.1359, loss = 0.3596, eval: [6.9 s]
# # Iteration 16 fit: [11.5 s]: Recall = 0.1616, Jaccard score = 0.1375, loss = 0.3561, eval: [6.9 s]
# # Iteration 17 fit: [11.4 s]: Recall = 0.1613, Jaccard score = 0.1372, loss = 0.3532, eval: [6.9 s]
# # Iteration 18 fit: [11.4 s]: Recall = 0.1614, Jaccard score = 0.1373, loss = 0.3501, eval: [6.7 s]
# # Iteration 19 fit: [11.6 s]: Recall = 0.1612, Jaccard score = 0.1371, loss = 0.3474, eval: [6.9 s]
# # Iteration 20 fit: [11.4 s]: Recall = 0.1592, Jaccard score = 0.1352, loss = 0.3448, eval: [6.8 s]
# # Iteration 21 fit: [11.4 s]: Recall = 0.1586, Jaccard score = 0.1346, loss = 0.3418, eval: [6.8 s]
# # Iteration 22 fit: [11.5 s]: Recall = 0.1600, Jaccard score = 0.1359, loss = 0.3394, eval: [6.8 s]
# # Iteration 23 fit: [11.4 s]: Recall = 0.1566, Jaccard score = 0.1326, loss = 0.3369, eval: [6.9 s]
# # Iteration 24 fit: [11.4 s]: Recall = 0.1563, Jaccard score = 0.1324, loss = 0.3353, eval: [6.9 s]
# # Iteration 25 fit: [11.4 s]: Recall = 0.1580, Jaccard score = 0.1340, loss = 0.3329, eval: [6.9 s]
# # Iteration 26 fit: [11.4 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.3307, eval: [6.8 s]
# # Iteration 27 fit: [11.4 s]: Recall = 0.1576, Jaccard score = 0.1337, loss = 0.3287, eval: [6.9 s]
# # Iteration 28 fit: [11.4 s]: Recall = 0.1606, Jaccard score = 0.1365, loss = 0.3267, eval: [6.9 s]
# # Iteration 29 fit: [11.6 s]: Recall = 0.1541, Jaccard score = 0.1302, loss = 0.3247, eval: [7.2 s]
# # Iteration 30 fit: [11.5 s]: Recall = 0.1547, Jaccard score = 0.1309, loss = 0.3228, eval: [6.9 s]
# # Iteration 31 fit: [11.4 s]: Recall = 0.1568, Jaccard score = 0.1328, loss = 0.3211, eval: [6.9 s]
# # Iteration 32 fit: [11.5 s]: Recall = 0.1527, Jaccard score = 0.1289, loss = 0.3193, eval: [6.7 s]
# # Iteration 33 fit: [11.4 s]: Recall = 0.1496, Jaccard score = 0.1260, loss = 0.3176, eval: [6.9 s]
# # Iteration 34 fit: [11.4 s]: Recall = 0.1521, Jaccard score = 0.1284, loss = 0.3160, eval: [6.8 s]
# # Iteration 35 fit: [11.5 s]: Recall = 0.1485, Jaccard score = 0.1250, loss = 0.3142, eval: [6.9 s]
# # Iteration 36 fit: [11.6 s]: Recall = 0.1496, Jaccard score = 0.1260, loss = 0.3131, eval: [7.0 s]
# # Iteration 37 fit: [11.5 s]: Recall = 0.1485, Jaccard score = 0.1250, loss = 0.3118, eval: [6.9 s]
# # Iteration 38 fit: [11.5 s]: Recall = 0.1533, Jaccard score = 0.1295, loss = 0.3099, eval: [7.0 s]
# # Iteration 39 fit: [12.8 s]: Recall = 0.1505, Jaccard score = 0.1268, loss = 0.3088, eval: [6.9 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,128,128,128]_1563996727.h5
# --weights_path: Pretrain/_MLP_8_[4,128,128,128]_1563996727.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # <class 'tensorflow.python.framework.errors_impl.InternalError'>: Blas GEMM launch failed : a.shape=(100, 1004), b.shape=(1004, 128), m=100, n=128, k=1004 	 [[{{node layer1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](concatenate_2/concat, layer1/kernel/read)]] 	 [[{{node prediction/Sigmoid/_115}} = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_85_prediction/Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()]]
# # Iteration 40 fit: [12.2 s]: Recall = 0.1527, Jaccard score = 0.1289, loss = 0.3077, eval: [7.0 s]
# # Iteration 41 fit: [11.5 s]: Recall = 0.1472, Jaccard score = 0.1237, loss = 0.3065, eval: [6.9 s]
# # Iteration 42 fit: [11.5 s]: Recall = 0.1448, Jaccard score = 0.1215, loss = 0.3050, eval: [6.9 s]
# # Iteration 43 fit: [11.6 s]: Recall = 0.1480, Jaccard score = 0.1245, loss = 0.3039, eval: [6.9 s]
# # Iteration 44 fit: [11.6 s]: Recall = 0.1489, Jaccard score = 0.1253, loss = 0.3021, eval: [6.9 s]
# # Iteration 45 fit: [11.4 s]: Recall = 0.1510, Jaccard score = 0.1273, loss = 0.3014, eval: [6.8 s]
# # Iteration 46 fit: [11.4 s]: Recall = 0.1516, Jaccard score = 0.1279, loss = 0.3002, eval: [6.9 s]
# # Iteration 47 fit: [11.4 s]: Recall = 0.1503, Jaccard score = 0.1266, loss = 0.2985, eval: [6.8 s]
# # Iteration 48 fit: [11.4 s]: Recall = 0.1469, Jaccard score = 0.1234, loss = 0.2979, eval: [7.0 s]
# # Iteration 49 fit: [11.4 s]: Recall = 0.1433, Jaccard score = 0.1201, loss = 0.2970, eval: [6.8 s]
# # End. Best Iteration 14:  Recall = 0.1650, Jaccard score = 0.1407. 
# # The best NeuMF model has been saved to Pretrain/_MLP_8_[4,128,128,128]_1563995977.h5


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[2,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[2,128,128,128]_1563998004.h5
# --weights_path: Pretrain/_MLP_8_[2,128,128,128]_1563998004.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0261, Jaccard score = 0.0199
# # Iteration 0 fit: [11.9 s]: Recall = 0.1043, Jaccard score = 0.0846, loss = 0.4881, eval: [6.8 s]
# # Iteration 1 fit: [13.8 s]: Recall = 0.1324, Jaccard score = 0.1099, loss = 0.4443, eval: [8.9 s]
# # Iteration 2 fit: [11.5 s]: Recall = 0.1416, Jaccard score = 0.1185, loss = 0.4275, eval: [6.9 s]
# # Iteration 3 fit: [11.6 s]: Recall = 0.1438, Jaccard score = 0.1205, loss = 0.4201, eval: [6.9 s]
# # Iteration 4 fit: [11.5 s]: Recall = 0.1467, Jaccard score = 0.1232, loss = 0.4145, eval: [6.8 s]
# # Iteration 5 fit: [12.4 s]: Recall = 0.1446, Jaccard score = 0.1213, loss = 0.4101, eval: [6.8 s]
# # Iteration 6 fit: [11.5 s]: Recall = 0.1483, Jaccard score = 0.1248, loss = 0.4059, eval: [6.9 s]
# # Iteration 7 fit: [12.9 s]: Recall = 0.1490, Jaccard score = 0.1254, loss = 0.4027, eval: [8.8 s]
# # Iteration 8 fit: [12.1 s]: Recall = 0.1511, Jaccard score = 0.1274, loss = 0.3995, eval: [6.9 s]
# # Iteration 9 fit: [11.5 s]: Recall = 0.1466, Jaccard score = 0.1232, loss = 0.3955, eval: [6.8 s]
# # Iteration 10 fit: [12.1 s]: Recall = 0.1444, Jaccard score = 0.1211, loss = 0.3919, eval: [6.9 s]
# # Iteration 11 fit: [11.6 s]: Recall = 0.1493, Jaccard score = 0.1257, loss = 0.3882, eval: [6.9 s]
# # Iteration 12 fit: [11.5 s]: Recall = 0.1505, Jaccard score = 0.1268, loss = 0.3849, eval: [6.9 s]
# # Iteration 13 fit: [11.4 s]: Recall = 0.1460, Jaccard score = 0.1225, loss = 0.3823, eval: [7.0 s]
# # Iteration 14 fit: [11.6 s]: Recall = 0.1489, Jaccard score = 0.1254, loss = 0.3801, eval: [6.9 s]
# # Iteration 15 fit: [11.5 s]: Recall = 0.1478, Jaccard score = 0.1243, loss = 0.3774, eval: [6.9 s]
# # Iteration 16 fit: [11.5 s]: Recall = 0.1475, Jaccard score = 0.1240, loss = 0.3753, eval: [6.9 s]
# # Iteration 17 fit: [11.6 s]: Recall = 0.1479, Jaccard score = 0.1243, loss = 0.3734, eval: [6.9 s]
# # Iteration 18 fit: [11.4 s]: Recall = 0.1485, Jaccard score = 0.1249, loss = 0.3716, eval: [6.9 s]
# # Iteration 19 fit: [11.5 s]: Recall = 0.1480, Jaccard score = 0.1245, loss = 0.3698, eval: [6.8 s]
# # Iteration 20 fit: [11.5 s]: Recall = 0.1467, Jaccard score = 0.1232, loss = 0.3679, eval: [6.9 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1563999947.h5
# --weights_path: Pretrain/_MLP_8_[1024,128]_1563999947.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0269, Jaccard score = 0.0205
# # Iteration 0 fit: [35.9 s]: Recall = 0.1571, Jaccard score = 0.1331, loss = 0.4326, eval: [6.5 s]
# # Iteration 1 fit: [35.1 s]: Recall = 0.1789, Jaccard score = 0.1545, loss = 0.3912, eval: [6.7 s]
# # Iteration 2 fit: [35.2 s]: Recall = 0.1792, Jaccard score = 0.1547, loss = 0.3563, eval: [6.5 s]
# # Iteration 3 fit: [35.3 s]: Recall = 0.1767, Jaccard score = 0.1523, loss = 0.3220, eval: [6.6 s]
# # Iteration 4 fit: [35.2 s]: Recall = 0.1686, Jaccard score = 0.1443, loss = 0.2878, eval: [6.6 s]
# # Iteration 5 fit: [35.3 s]: Recall = 0.1652, Jaccard score = 0.1410, loss = 0.2548, eval: [6.7 s]
# # Iteration 6 fit: [35.3 s]: Recall = 0.1561, Jaccard score = 0.1322, loss = 0.2230, eval: [6.5 s]
# # Iteration 7 fit: [35.2 s]: Recall = 0.1465, Jaccard score = 0.1231, loss = 0.1946, eval: [6.6 s]
# # Iteration 8 fit: [35.3 s]: Recall = 0.1440, Jaccard score = 0.1207, loss = 0.1684, eval: [6.6 s]
# # Iteration 9 fit: [35.2 s]: Recall = 0.1415, Jaccard score = 0.1183, loss = 0.1476, eval: [6.5 s]
# # Iteration 10 fit: [35.2 s]: Recall = 0.1373, Jaccard score = 0.1144, loss = 0.1294, eval: [6.7 s]
# # Iteration 11 fit: [35.3 s]: Recall = 0.1301, Jaccard score = 0.1078, loss = 0.1138, eval: [8.5 s]
# # Iteration 12 fit: [35.8 s]: Recall = 0.1298, Jaccard score = 0.1075, loss = 0.1014, eval: [6.8 s]
# # Iteration 13 fit: [35.5 s]: Recall = 0.1271, Jaccard score = 0.1051, loss = 0.0910, eval: [6.6 s]
# # Iteration 14 fit: [35.3 s]: Recall = 0.1293, Jaccard score = 0.1070, loss = 0.0838, eval: [6.6 s]
# # Iteration 15 fit: [35.4 s]: Recall = 0.1317, Jaccard score = 0.1093, loss = 0.0760, eval: [7.1 s]
# # Iteration 16 fit: [36.0 s]: Recall = 0.1261, Jaccard score = 0.1042, loss = 0.0699, eval: [8.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564000714.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564000714.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'TypeError'>: The `BatchNormalization` layer does not accept positional arguments. Use keyword arguments instead.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564046630.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564046630.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0267, Jaccard score = 0.0204
# # Iteration 0 fit: [14.8 s]: Recall = 0.1668, Jaccard score = 0.1425, loss = 0.4372, eval: [7.2 s]
# # Iteration 1 fit: [14.2 s]: Recall = 0.1833, Jaccard score = 0.1588, loss = 0.3983, eval: [7.2 s]
# # Iteration 2 fit: [14.2 s]: Recall = 0.1901, Jaccard score = 0.1657, loss = 0.3796, eval: [7.3 s]
# # Iteration 3 fit: [14.2 s]: Recall = 0.1920, Jaccard score = 0.1677, loss = 0.3632, eval: [7.3 s]
# # Iteration 4 fit: [14.2 s]: Recall = 0.1923, Jaccard score = 0.1680, loss = 0.3473, eval: [7.3 s]
# # Iteration 5 fit: [14.3 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.3327, eval: [7.3 s]
# # Iteration 6 fit: [14.2 s]: Recall = 0.1866, Jaccard score = 0.1622, loss = 0.3162, eval: [7.3 s]
# # Iteration 7 fit: [14.2 s]: Recall = 0.1805, Jaccard score = 0.1560, loss = 0.3011, eval: [7.3 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564046841.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564046841.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0239, Jaccard score = 0.0182
# # Iteration 0 fit: [26.1 s]: Recall = 0.1619, Jaccard score = 0.1377, loss = 0.4327, eval: [7.2 s]
# # Iteration 1 fit: [24.4 s]: Recall = 0.1820, Jaccard score = 0.1576, loss = 0.3929, eval: [7.4 s]
# # Iteration 2 fit: [24.4 s]: Recall = 0.1875, Jaccard score = 0.1631, loss = 0.3648, eval: [7.3 s]
# # Iteration 3 fit: [24.4 s]: Recall = 0.1852, Jaccard score = 0.1608, loss = 0.3367, eval: [7.2 s]
# # Iteration 4 fit: [24.4 s]: Recall = 0.1799, Jaccard score = 0.1555, loss = 0.3087, eval: [7.2 s]
# # Iteration 5 fit: [24.5 s]: Recall = 0.1734, Jaccard score = 0.1490, loss = 0.2826, eval: [7.3 s]
# # Iteration 6 fit: [24.4 s]: Recall = 0.1679, Jaccard score = 0.1436, loss = 0.2587, eval: [7.2 s]
# # Iteration 7 fit: [24.5 s]: Recall = 0.1568, Jaccard score = 0.1329, loss = 0.2365, eval: [7.3 s]
# # Iteration 8 fit: [24.4 s]: Recall = 0.1530, Jaccard score = 0.1292, loss = 0.2151, eval: [7.2 s]
# # Iteration 9 fit: [24.4 s]: Recall = 0.1486, Jaccard score = 0.1250, loss = 0.1959, eval: [7.3 s]
# # Iteration 10 fit: [24.6 s]: Recall = 0.1439, Jaccard score = 0.1206, loss = 0.1782, eval: [7.4 s]
# # Iteration 11 fit: [24.4 s]: Recall = 0.1409, Jaccard score = 0.1177, loss = 0.1620, eval: [7.2 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564047326.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564047326.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0271, Jaccard score = 0.0207


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564048816.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564048816.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0253, Jaccard score = 0.0193
# # Iteration 0 fit: [23.8 s]: Recall = 0.1653, Jaccard score = 0.1411, loss = 0.4310, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564048880.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564048880.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0229, Jaccard score = 0.0174
# # Iteration 0 fit: [13.0 s]: Recall = 0.1693, Jaccard score = 0.1450, loss = 0.4352, eval: [6.6 s]
# # Iteration 1 fit: [12.6 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3941, eval: [6.7 s]
# # Iteration 2 fit: [12.8 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3728, eval: [6.6 s]
# # Iteration 3 fit: [12.6 s]: Recall = 0.1923, Jaccard score = 0.1679, loss = 0.3553, eval: [6.7 s]
# # Iteration 4 fit: [12.6 s]: Recall = 0.1955, Jaccard score = 0.1712, loss = 0.3388, eval: [6.7 s]
# # Iteration 5 fit: [12.6 s]: Recall = 0.1925, Jaccard score = 0.1682, loss = 0.3231, eval: [6.6 s]
# # Iteration 6 fit: [12.6 s]: Recall = 0.1891, Jaccard score = 0.1647, loss = 0.3066, eval: [6.5 s]
# # Iteration 7 fit: [12.8 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.2914, eval: [6.7 s]
# # Iteration 8 fit: [12.6 s]: Recall = 0.1807, Jaccard score = 0.1563, loss = 0.2774, eval: [7.8 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564049087.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564049087.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0275, Jaccard score = 0.0210
# # Iteration 0 fit: [14.8 s]: Recall = 0.1690, Jaccard score = 0.1447, loss = 0.4409, eval: [7.1 s]
# # Iteration 1 fit: [14.3 s]: Recall = 0.1844, Jaccard score = 0.1600, loss = 0.3964, eval: [7.3 s]
# # Iteration 2 fit: [15.7 s]: Recall = 0.1905, Jaccard score = 0.1661, loss = 0.3765, eval: [8.7 s]
# # Iteration 3 fit: [14.3 s]: Recall = 0.1929, Jaccard score = 0.1686, loss = 0.3611, eval: [7.1 s]
# # Iteration 4 fit: [14.3 s]: Recall = 0.1932, Jaccard score = 0.1689, loss = 0.3450, eval: [7.2 s]
# # Iteration 5 fit: [14.3 s]: Recall = 0.1880, Jaccard score = 0.1636, loss = 0.3310, eval: [7.1 s]
# # Iteration 6 fit: [14.3 s]: Recall = 0.1887, Jaccard score = 0.1643, loss = 0.3155, eval: [7.2 s]
# # Iteration 7 fit: [14.6 s]: Recall = 0.1843, Jaccard score = 0.1599, loss = 0.3002, eval: [7.2 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564049294.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564049294.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0266, Jaccard score = 0.0203
# # Iteration 0 fit: [14.5 s]: Recall = 0.1493, Jaccard score = 0.1257, loss = 0.4497, eval: [6.8 s]
# # Iteration 1 fit: [13.0 s]: Recall = 0.1665, Jaccard score = 0.1423, loss = 0.4164, eval: [6.9 s]
# # Iteration 2 fit: [13.0 s]: Recall = 0.1809, Jaccard score = 0.1565, loss = 0.4038, eval: [6.8 s]
# # Iteration 3 fit: [13.1 s]: Recall = 0.1841, Jaccard score = 0.1597, loss = 0.3909, eval: [6.7 s]
# # Iteration 4 fit: [13.0 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3802, eval: [6.7 s]
# # Iteration 5 fit: [13.1 s]: Recall = 0.1915, Jaccard score = 0.1672, loss = 0.3690, eval: [6.8 s]
# # Iteration 6 fit: [13.0 s]: Recall = 0.1913, Jaccard score = 0.1670, loss = 0.3581, eval: [6.8 s]
# # Iteration 7 fit: [13.0 s]: Recall = 0.1919, Jaccard score = 0.1675, loss = 0.3486, eval: [6.7 s]
# # Iteration 8 fit: [13.0 s]: Recall = 0.1890, Jaccard score = 0.1646, loss = 0.3393, eval: [6.8 s]
# # Iteration 9 fit: [13.0 s]: Recall = 0.1889, Jaccard score = 0.1646, loss = 0.3311, eval: [6.8 s]
# # Iteration 10 fit: [12.9 s]: Recall = 0.1871, Jaccard score = 0.1627, loss = 0.3236, eval: [6.8 s]
# # Iteration 11 fit: [13.0 s]: Recall = 0.1879, Jaccard score = 0.1635, loss = 0.3170, eval: [6.9 s]
# # Iteration 12 fit: [12.9 s]: Recall = 0.1834, Jaccard score = 0.1589, loss = 0.3109, eval: [6.7 s]
# # Iteration 13 fit: [13.0 s]: Recall = 0.1837, Jaccard score = 0.1592, loss = 0.3041, eval: [6.8 s]
# # Iteration 14 fit: [13.0 s]: Recall = 0.1814, Jaccard score = 0.1569, loss = 0.2991, eval: [6.7 s]
# # Iteration 15 fit: [13.0 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.2937, eval: [6.7 s]
# # Iteration 16 fit: [12.9 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.2896, eval: [6.7 s]
# # Iteration 17 fit: [13.0 s]: Recall = 0.1749, Jaccard score = 0.1505, loss = 0.2845, eval: [6.8 s]
# # Iteration 18 fit: [12.9 s]: Recall = 0.1745, Jaccard score = 0.1501, loss = 0.2792, eval: [6.8 s]
# # Iteration 19 fit: [12.9 s]: Recall = 0.1739, Jaccard score = 0.1495, loss = 0.2754, eval: [6.7 s]
# # Iteration 20 fit: [13.0 s]: Recall = 0.1728, Jaccard score = 0.1484, loss = 0.2719, eval: [6.7 s]
# # Iteration 21 fit: [13.0 s]: Recall = 0.1690, Jaccard score = 0.1447, loss = 0.2681, eval: [6.8 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564057538.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564057538.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0281, Jaccard score = 0.0215
# # Iteration 0 fit: [11.8 s]: Recall = 0.1589, Jaccard score = 0.1349, loss = 0.4470, eval: [6.6 s]
# # Iteration 1 fit: [11.7 s]: Recall = 0.1727, Jaccard score = 0.1483, loss = 0.4133, eval: [6.7 s]
# # Iteration 2 fit: [11.3 s]: Recall = 0.1841, Jaccard score = 0.1597, loss = 0.3998, eval: [6.7 s]
# # Iteration 3 fit: [11.4 s]: Recall = 0.1869, Jaccard score = 0.1625, loss = 0.3892, eval: [6.7 s]
# # Iteration 4 fit: [11.4 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3795, eval: [6.7 s]
# # Iteration 5 fit: [12.4 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3714, eval: [8.5 s]
# # Iteration 6 fit: [12.9 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3636, eval: [6.6 s]
# # Iteration 7 fit: [11.4 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3569, eval: [6.7 s]
# # Iteration 8 fit: [11.9 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3495, eval: [6.6 s]
# # Iteration 9 fit: [11.4 s]: Recall = 0.1951, Jaccard score = 0.1708, loss = 0.3432, eval: [6.6 s]
# # Iteration 10 fit: [11.7 s]: Recall = 0.1955, Jaccard score = 0.1713, loss = 0.3371, eval: [6.7 s]
# # Iteration 11 fit: [11.4 s]: Recall = 0.1936, Jaccard score = 0.1693, loss = 0.3315, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564057782.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564057782.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <keras.engine.training.Model object at 0x7f0f6a95d2b0>
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0249, Jaccard score = 0.0190


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564057804.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564057804.h5
# # Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 10)        200000      user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 10)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1010)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1074)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          137600      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # dropout_1 (Dropout)             (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           dropout_1[0][0]                  
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 465,729
# # Trainable params: 465,729
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0263, Jaccard score = 0.0201
# # Iteration 0 fit: [11.5 s]: Recall = 0.1578, Jaccard score = 0.1338, loss = 0.4435, eval: [6.6 s]
# # Iteration 1 fit: [10.7 s]: Recall = 0.1750, Jaccard score = 0.1506, loss = 0.4133, eval: [6.6 s]
# # Iteration 2 fit: [10.8 s]: Recall = 0.1813, Jaccard score = 0.1569, loss = 0.3990, eval: [6.7 s]
# # Iteration 3 fit: [10.7 s]: Recall = 0.1864, Jaccard score = 0.1620, loss = 0.3892, eval: [6.6 s]
# # Iteration 4 fit: [10.7 s]: Recall = 0.1912, Jaccard score = 0.1668, loss = 0.3802, eval: [6.7 s]
# # Iteration 5 fit: [10.8 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3725, eval: [6.6 s]
# # Iteration 6 fit: [10.7 s]: Recall = 0.1971, Jaccard score = 0.1729, loss = 0.3651, eval: [6.6 s]
# # Iteration 7 fit: [10.7 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3591, eval: [6.7 s]
# # Iteration 8 fit: [10.7 s]: Recall = 0.1978, Jaccard score = 0.1736, loss = 0.3536, eval: [6.8 s]
# # Iteration 9 fit: [10.7 s]: Recall = 0.1977, Jaccard score = 0.1735, loss = 0.3477, eval: [6.8 s]
# # Iteration 10 fit: [10.7 s]: Recall = 0.1967, Jaccard score = 0.1725, loss = 0.3429, eval: [6.6 s]
# # Iteration 11 fit: [10.8 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.3380, eval: [6.6 s]
# # Iteration 12 fit: [10.7 s]: Recall = 0.1940, Jaccard score = 0.1697, loss = 0.3331, eval: [6.9 s]
# # Iteration 13 fit: [10.8 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3291, eval: [6.6 s]
# # Iteration 14 fit: [10.7 s]: Recall = 0.1966, Jaccard score = 0.1724, loss = 0.3253, eval: [6.7 s]
# # Iteration 15 fit: [10.7 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3207, eval: [6.8 s]
# # Iteration 16 fit: [10.8 s]: Recall = 0.1971, Jaccard score = 0.1729, loss = 0.3177, eval: [6.6 s]
# # Iteration 17 fit: [10.7 s]: Recall = 0.1948, Jaccard score = 0.1705, loss = 0.3142, eval: [6.6 s]
# # Iteration 18 fit: [10.7 s]: Recall = 0.1922, Jaccard score = 0.1679, loss = 0.3112, eval: [6.6 s]
# # Iteration 19 fit: [10.8 s]: Recall = 0.1918, Jaccard score = 0.1675, loss = 0.3081, eval: [6.6 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058172.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058172.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 10)        200000      user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 10)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1010)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1074)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          137600      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # dropout_1 (Dropout)             (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           dropout_1[0][0]                  
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # dropout_2 (Dropout)             (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           dropout_2[0][0]                  
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 482,241
# # Trainable params: 482,241
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0271, Jaccard score = 0.0207
# # Iteration 0 fit: [12.0 s]: Recall = 0.1711, Jaccard score = 0.1467, loss = 0.4493, eval: [6.7 s]
# # Iteration 1 fit: [11.5 s]: Recall = 0.1861, Jaccard score = 0.1617, loss = 0.4120, eval: [6.9 s]
# # Iteration 2 fit: [11.5 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.4011, eval: [6.9 s]
# # Iteration 3 fit: [11.9 s]: Recall = 0.1952, Jaccard score = 0.1710, loss = 0.3915, eval: [6.9 s]
# # Iteration 4 fit: [11.6 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3841, eval: [6.9 s]
# # Iteration 5 fit: [11.9 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3775, eval: [6.9 s]
# # Iteration 6 fit: [11.5 s]: Recall = 0.1992, Jaccard score = 0.1751, loss = 0.3721, eval: [6.9 s]
# # Iteration 7 fit: [11.5 s]: Recall = 0.1983, Jaccard score = 0.1741, loss = 0.3662, eval: [6.9 s]
# # Iteration 8 fit: [12.0 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3614, eval: [6.9 s]
# # Iteration 9 fit: [11.5 s]: Recall = 0.2000, Jaccard score = 0.1758, loss = 0.3564, eval: [6.8 s]
# # Iteration 10 fit: [11.5 s]: Recall = 0.1991, Jaccard score = 0.1749, loss = 0.3521, eval: [6.8 s]
# # Iteration 11 fit: [11.6 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3470, eval: [6.9 s]
# # Iteration 12 fit: [11.5 s]: Recall = 0.1968, Jaccard score = 0.1726, loss = 0.3427, eval: [6.8 s]
# # Iteration 13 fit: [11.5 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3383, eval: [6.9 s]
# # Iteration 14 fit: [11.5 s]: Recall = 0.1944, Jaccard score = 0.1701, loss = 0.3345, eval: [6.7 s]
# # Iteration 15 fit: [11.5 s]: Recall = 0.1975, Jaccard score = 0.1733, loss = 0.3310, eval: [6.9 s]
# # Iteration 16 fit: [11.5 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3274, eval: [6.7 s]
# # Iteration 17 fit: [11.5 s]: Recall = 0.1959, Jaccard score = 0.1717, loss = 0.3239, eval: [6.9 s]
# # Iteration 18 fit: [11.9 s]: Recall = 0.1951, Jaccard score = 0.1709, loss = 0.3206, eval: [6.9 s]
# # Iteration 19 fit: [11.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3178, eval: [8.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058569.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058569.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1064)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1128)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          144512      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 1,569,153
# # Trainable params: 1,569,153
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0296, Jaccard score = 0.0226
# # Iteration 0 fit: [13.5 s]: Recall = 0.1769, Jaccard score = 0.1525, loss = 0.4295, eval: [6.8 s]
# # Iteration 1 fit: [13.0 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.3854, eval: [6.8 s]
# # Iteration 2 fit: [13.0 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3648, eval: [6.9 s]
# # Iteration 3 fit: [13.1 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3482, eval: [6.8 s]
# # Iteration 4 fit: [13.1 s]: Recall = 0.1941, Jaccard score = 0.1698, loss = 0.3322, eval: [6.9 s]
# # Iteration 5 fit: [13.1 s]: Recall = 0.1920, Jaccard score = 0.1677, loss = 0.3167, eval: [6.7 s]
# # Iteration 6 fit: [13.1 s]: Recall = 0.1877, Jaccard score = 0.1633, loss = 0.3011, eval: [6.8 s]
# # Iteration 7 fit: [13.1 s]: Recall = 0.1853, Jaccard score = 0.1609, loss = 0.2862, eval: [6.7 s]
# # Iteration 8 fit: [15.0 s]: Recall = 0.1803, Jaccard score = 0.1559, loss = 0.2713, eval: [7.6 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058767.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058767.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'ValueError'>: Graph disconnected: cannot obtain value for tensor Tensor("user_features:0", shape=(?, 1000), dtype=float32) at layer "user_features". The following previous layers were accessed without issue: ['user_input', 'item_input']


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058944.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058944.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'TypeError'>: Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059632.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059632.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'TypeError'>: Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059642.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059642.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059662.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059662.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059710.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059710.h5
# # Load data done [4.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059729.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059729.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060094.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060094.h5
# # Load data done [3.9 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060232.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060232.h5
# # Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 256)          0           dense_feature_layer[0][0]        
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 320)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          41088       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 313,857
# # Trainable params: 313,857
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0273, Jaccard score = 0.0208
# # Iteration 0 fit: [11.1 s]: Recall = 0.1861, Jaccard score = 0.1617, loss = 0.4188, eval: [6.8 s]
# # Iteration 1 fit: [11.2 s]: Recall = 0.1961, Jaccard score = 0.1718, loss = 0.3824, eval: [6.7 s]
# # Iteration 2 fit: [11.1 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3670, eval: [6.8 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1989, Jaccard score = 0.1747, loss = 0.3558, eval: [6.7 s]
# # Iteration 4 fit: [11.2 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3474, eval: [6.8 s]
# # Iteration 5 fit: [11.2 s]: Recall = 0.2022, Jaccard score = 0.1782, loss = 0.3401, eval: [6.6 s]
# # Iteration 6 fit: [11.0 s]: Recall = 0.2020, Jaccard score = 0.1780, loss = 0.3328, eval: [6.8 s]
# # Iteration 7 fit: [11.2 s]: Recall = 0.1972, Jaccard score = 0.1730, loss = 0.3273, eval: [6.8 s]
# # Iteration 8 fit: [11.2 s]: Recall = 0.1997, Jaccard score = 0.1756, loss = 0.3217, eval: [6.7 s]
# # Iteration 9 fit: [14.1 s]: Recall = 0.1980, Jaccard score = 0.1738, loss = 0.3161, eval: [6.7 s]
# # Iteration 10 fit: [10.7 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3111, eval: [6.8 s]
# # Iteration 11 fit: [11.1 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3056, eval: [6.6 s]
# # Iteration 12 fit: [11.1 s]: Recall = 0.1967, Jaccard score = 0.1725, loss = 0.3012, eval: [6.8 s]
# # Iteration 13 fit: [11.6 s]: Recall = 0.1953, Jaccard score = 0.1710, loss = 0.2971, eval: [6.8 s]
# # Iteration 14 fit: [11.2 s]: Recall = 0.1955, Jaccard score = 0.1712, loss = 0.2932, eval: [6.8 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060531.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060531.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 256)          0           dense_feature_layer[0][0]        
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 320)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          41088       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 313,857
# # Trainable params: 313,857
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0225, Jaccard score = 0.0171
# # Iteration 0 fit: [11.6 s]: Recall = 0.1847, Jaccard score = 0.1602, loss = 0.4185, eval: [8.4 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060587.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060587.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 256)          0           dense_feature_layer[0][0]        
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 320)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          41088       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 313,857
# # Trainable params: 313,857
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060656.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060656.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 192)          0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 256)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          32896       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 1,585,665
# # Trainable params: 1,585,665
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0303, Jaccard score = 0.0232
# # Iteration 0 fit: [13.9 s]: Recall = 0.1758, Jaccard score = 0.1514, loss = 0.4315, eval: [6.8 s]
# # Iteration 1 fit: [13.5 s]: Recall = 0.1879, Jaccard score = 0.1635, loss = 0.3885, eval: [6.8 s]
# # Iteration 2 fit: [13.4 s]: Recall = 0.1960, Jaccard score = 0.1717, loss = 0.3683, eval: [6.8 s]
# # Iteration 3 fit: [13.4 s]: Recall = 0.1961, Jaccard score = 0.1718, loss = 0.3525, eval: [6.9 s]
# # Iteration 4 fit: [13.8 s]: Recall = 0.1962, Jaccard score = 0.1720, loss = 0.3388, eval: [8.7 s]
# # Iteration 5 fit: [14.5 s]: Recall = 0.1917, Jaccard score = 0.1674, loss = 0.3255, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060810.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060810.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer2 (Dense)    (None, 128)          16512       dense_feature_layer1[0][0]       
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 192)          0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer2[0][0]       
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 256)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          32896       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 1,602,177
# # Trainable params: 1,602,177
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0313, Jaccard score = 0.0240
# # Iteration 0 fit: [14.8 s]: Recall = 0.1758, Jaccard score = 0.1514, loss = 0.4315, eval: [6.9 s]
# # Iteration 1 fit: [14.3 s]: Recall = 0.1893, Jaccard score = 0.1650, loss = 0.3903, eval: [7.0 s]
# # Iteration 2 fit: [14.2 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3724, eval: [7.0 s]
# # Iteration 3 fit: [14.3 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3572, eval: [6.9 s]
# # Iteration 4 fit: [14.6 s]: Recall = 0.1916, Jaccard score = 0.1673, loss = 0.3446, eval: [6.9 s]
# # Iteration 5 fit: [14.2 s]: Recall = 0.1893, Jaccard score = 0.1650, loss = 0.3315, eval: [7.0 s]
# # Iteration 6 fit: [14.2 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3185, eval: [6.9 s]
# # Iteration 7 fit: [14.4 s]: Recall = 0.1837, Jaccard score = 0.1592, loss = 0.3057, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564061014.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564061014.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 192)          0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer1[0][0]       
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 256)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          32896       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 1,569,153
# # Trainable params: 1,569,153
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0243, Jaccard score = 0.0185
# # Iteration 0 fit: [13.4 s]: Recall = 0.1684, Jaccard score = 0.1441, loss = 0.4355, eval: [6.7 s]
# # Iteration 1 fit: [13.0 s]: Recall = 0.1821, Jaccard score = 0.1577, loss = 0.3938, eval: [6.7 s]
# # Iteration 2 fit: [13.0 s]: Recall = 0.1915, Jaccard score = 0.1671, loss = 0.3728, eval: [6.7 s]
# # Iteration 3 fit: [13.0 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3571, eval: [6.7 s]
# # Iteration 4 fit: [13.0 s]: Recall = 0.1928, Jaccard score = 0.1685, loss = 0.3420, eval: [6.7 s]
# # Iteration 5 fit: [13.0 s]: Recall = 0.1925, Jaccard score = 0.1682, loss = 0.3280, eval: [6.8 s]
# # Iteration 6 fit: [13.0 s]: Recall = 0.1878, Jaccard score = 0.1634, loss = 0.3134, eval: [6.7 s]
# # Iteration 7 fit: [13.0 s]: Recall = 0.1818, Jaccard score = 0.1573, loss = 0.2987, eval: [6.8 s]
# # Iteration 8 fit: [13.0 s]: Recall = 0.1776, Jaccard score = 0.1532, loss = 0.2838, eval: [6.6 s]
# # Iteration 9 fit: [13.0 s]: Recall = 0.1751, Jaccard score = 0.1507, loss = 0.2716, eval: [6.8 s]
# # Iteration 10 fit: [13.0 s]: Recall = 0.1747, Jaccard score = 0.1503, loss = 0.2583, eval: [6.6 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564061555.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564061555.h5
# # Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1088)         0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer1[0][0]       
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1152)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          147584      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 2,580,737
# # Trainable params: 2,580,737
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0334, Jaccard score = 0.0256
# # Iteration 0 fit: [16.4 s]: Recall = 0.1649, Jaccard score = 0.1407, loss = 0.4361, eval: [6.8 s]
# # Iteration 1 fit: [16.1 s]: Recall = 0.1835, Jaccard score = 0.1591, loss = 0.3981, eval: [6.7 s]
# # Iteration 2 fit: [16.2 s]: Recall = 0.1915, Jaccard score = 0.1671, loss = 0.3786, eval: [6.8 s]
# # Iteration 3 fit: [16.2 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3626, eval: [6.9 s]
# # Iteration 4 fit: [16.2 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3482, eval: [7.0 s]
# # Iteration 5 fit: [16.1 s]: Recall = 0.1940, Jaccard score = 0.1697, loss = 0.3344, eval: [8.6 s]
# # Iteration 6 fit: [17.0 s]: Recall = 0.1906, Jaccard score = 0.1662, loss = 0.3209, eval: [7.0 s]
# # Iteration 7 fit: [16.0 s]: Recall = 0.1867, Jaccard score = 0.1623, loss = 0.3080, eval: [6.8 s]
# # Iteration 8 fit: [15.8 s]: Recall = 0.1836, Jaccard score = 0.1592, loss = 0.2955, eval: [7.0 s]
# # Iteration 9 fit: [16.1 s]: Recall = 0.1806, Jaccard score = 0.1561, loss = 0.2838, eval: [6.8 s]
# # Iteration 10 fit: [16.1 s]: Recall = 0.1765, Jaccard score = 0.1520, loss = 0.2729, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564061882.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564061882.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_3 (Concatenate)     (None, 1088)         0           dense_feature_layer1[0][0]       
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          139392      concatenate_3[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 1,292,545
# # Trainable params: 1,292,545
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0338, Jaccard score = 0.0260
# # Iteration 0 fit: [13.1 s]: Recall = 0.1759, Jaccard score = 0.1514, loss = 0.4314, eval: [6.8 s]
# # Iteration 1 fit: [12.7 s]: Recall = 0.1865, Jaccard score = 0.1621, loss = 0.3941, eval: [6.9 s]
# # Iteration 2 fit: [12.8 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3777, eval: [6.9 s]
# # Iteration 3 fit: [13.0 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3645, eval: [6.8 s]
# # Iteration 4 fit: [12.7 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3554, eval: [6.8 s]
# # Iteration 5 fit: [13.0 s]: Recall = 0.1993, Jaccard score = 0.1751, loss = 0.3477, eval: [7.0 s]
# # Iteration 6 fit: [12.8 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3408, eval: [6.9 s]
# # Iteration 7 fit: [12.8 s]: Recall = 0.1999, Jaccard score = 0.1758, loss = 0.3355, eval: [6.9 s]
# # Iteration 8 fit: [12.9 s]: Recall = 0.2019, Jaccard score = 0.1779, loss = 0.3303, eval: [6.9 s]
# # Iteration 9 fit: [12.7 s]: Recall = 0.2019, Jaccard score = 0.1779, loss = 0.3259, eval: [7.0 s]
# # Iteration 10 fit: [12.7 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3209, eval: [6.8 s]
# # Iteration 11 fit: [13.0 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3164, eval: [7.0 s]
# # Iteration 12 fit: [12.7 s]: Recall = 0.2000, Jaccard score = 0.1759, loss = 0.3122, eval: [6.9 s]
# # Iteration 13 fit: [12.7 s]: Recall = 0.2027, Jaccard score = 0.1786, loss = 0.3087, eval: [6.8 s]
# # Iteration 14 fit: [12.7 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3045, eval: [6.9 s]
# # Iteration 15 fit: [12.7 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3014, eval: [6.9 s]
# # Iteration 16 fit: [12.7 s]: Recall = 0.1996, Jaccard score = 0.1754, loss = 0.2978, eval: [6.8 s]
# # Iteration 17 fit: [12.8 s]: Recall = 0.1992, Jaccard score = 0.1750, loss = 0.2942, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564062257.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564062257.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_3 (Concatenate)     (None, 1280)         0           dense_feature_layer1[0][0]       
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          163968      concatenate_3[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 1,701,121
# # Trainable params: 1,701,121
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0286, Jaccard score = 0.0219
# # Iteration 0 fit: [14.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.4109, eval: [6.9 s]
# # Iteration 1 fit: [14.2 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3717, eval: [6.9 s]
# # Iteration 2 fit: [14.2 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3541, eval: [7.0 s]
# # Iteration 3 fit: [14.1 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3431, eval: [6.8 s]
# # Iteration 4 fit: [14.1 s]: Recall = 0.2019, Jaccard score = 0.1779, loss = 0.3337, eval: [7.0 s]
# # Iteration 5 fit: [14.1 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3258, eval: [7.0 s]
# # Iteration 6 fit: [14.2 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3193, eval: [6.9 s]
# # Iteration 7 fit: [14.1 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.3117, eval: [6.9 s]
# # Iteration 8 fit: [14.1 s]: Recall = 0.2034, Jaccard score = 0.1795, loss = 0.3056, eval: [7.0 s]
# # Iteration 9 fit: [14.1 s]: Recall = 0.2046, Jaccard score = 0.1807, loss = 0.2996, eval: [6.8 s]
# # Iteration 10 fit: [14.0 s]: Recall = 0.2069, Jaccard score = 0.1831, loss = 0.2942, eval: [7.0 s]
# # Iteration 11 fit: [14.3 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.2882, eval: [7.0 s]
# # Iteration 12 fit: [14.0 s]: Recall = 0.2005, Jaccard score = 0.1764, loss = 0.2833, eval: [7.0 s]
# # Iteration 13 fit: [14.1 s]: Recall = 0.2001, Jaccard score = 0.1760, loss = 0.2786, eval: [6.8 s]
# # Iteration 14 fit: [14.1 s]: Recall = 0.1999, Jaccard score = 0.1758, loss = 0.2735, eval: [7.0 s]
# # Iteration 15 fit: [14.1 s]: Recall = 0.2015, Jaccard score = 0.1774, loss = 0.2692, eval: [6.8 s]
# # Iteration 16 fit: [14.1 s]: Recall = 0.1991, Jaccard score = 0.1750, loss = 0.2655, eval: [7.0 s]
# # Iteration 17 fit: [14.3 s]: Recall = 0.1971, Jaccard score = 0.1729, loss = 0.2614, eval: [6.9 s]
# # Iteration 18 fit: [14.1 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.2570, eval: [7.0 s]
# # Iteration 19 fit: [14.1 s]: Recall = 0.1975, Jaccard score = 0.1733, loss = 0.2528, eval: [6.9 s]
# # Iteration 20 fit: [14.1 s]: Recall = 0.1981, Jaccard score = 0.1739, loss = 0.2494, eval: [7.0 s]
# # Iteration 21 fit: [14.1 s]: Recall = 0.1972, Jaccard score = 0.1730, loss = 0.2468, eval: [6.8 s]
# # Iteration 22 fit: [14.1 s]: Recall = 0.1944, Jaccard score = 0.1702, loss = 0.2432, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1564062791.h5
# --weights_path: Pretrain/_MLP_8_[1024,128]_1564062791.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_3 (Concatenate)     (None, 1536)         0           dense_feature_layer1[0][0]       
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          196736      concatenate_3[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 2,245,889
# # Trainable params: 2,245,889
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0289, Jaccard score = 0.0221
# # Iteration 0 fit: [15.9 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.4040, eval: [7.0 s]
# # Iteration 1 fit: [15.3 s]: Recall = 0.2020, Jaccard score = 0.1779, loss = 0.3644, eval: [7.0 s]
# # Iteration 2 fit: [15.3 s]: Recall = 0.2078, Jaccard score = 0.1840, loss = 0.3477, eval: [7.0 s]
# # Iteration 3 fit: [15.2 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.3368, eval: [7.0 s]
# # Iteration 4 fit: [15.6 s]: Recall = 0.2066, Jaccard score = 0.1827, loss = 0.3274, eval: [6.9 s]
# # Iteration 5 fit: [15.4 s]: Recall = 0.2057, Jaccard score = 0.1818, loss = 0.3193, eval: [7.0 s]
# # Iteration 6 fit: [15.4 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.3123, eval: [6.8 s]
# # Iteration 7 fit: [15.3 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3053, eval: [7.0 s]
# # Iteration 8 fit: [15.5 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.2978, eval: [6.9 s]
# # Iteration 9 fit: [15.3 s]: Recall = 0.2057, Jaccard score = 0.1818, loss = 0.2923, eval: [7.0 s]
# # Iteration 10 fit: [15.3 s]: Recall = 0.2031, Jaccard score = 0.1791, loss = 0.2860, eval: [7.0 s]
# # Iteration 11 fit: [15.3 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.2807, eval: [6.9 s]
# # Iteration 12 fit: [15.3 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.2745, eval: [7.0 s]
# # Iteration 13 fit: [15.6 s]: Recall = 0.2000, Jaccard score = 0.1758, loss = 0.2688, eval: [7.0 s]
# # Iteration 14 fit: [15.2 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.2637, eval: [7.0 s]
# # Iteration 15 fit: [15.4 s]: Recall = 0.1967, Jaccard score = 0.1725, loss = 0.2588, eval: [6.9 s]
# # Iteration 16 fit: [15.3 s]: Recall = 0.1992, Jaccard score = 0.1750, loss = 0.2544, eval: [7.0 s]
# # Iteration 17 fit: [15.6 s]: Recall = 0.1980, Jaccard score = 0.1738, loss = 0.2496, eval: [7.0 s]
# # Iteration 18 fit: [15.3 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.2456, eval: [7.1 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adagrad', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1564063268.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1564063268.h5
# Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1536)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          196736      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 2,245,889
# Trainable params: 2,245,889
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0292, Jaccard score = 0.0223
# Iteration 0 fit: [13.8 s]: Recall = 0.1492, Jaccard score = 0.1256, loss = 0.4409, eval: [7.4 s]
# Iteration 1 fit: [15.6 s]: Recall = 0.1542, Jaccard score = 0.1304, loss = 0.4199, eval: [7.0 s]
# Iteration 2 fit: [13.8 s]: Recall = 0.1593, Jaccard score = 0.1352, loss = 0.4134, eval: [6.8 s]
# Iteration 3 fit: [13.6 s]: Recall = 0.1627, Jaccard score = 0.1385, loss = 0.4097, eval: [7.1 s]
# Iteration 4 fit: [15.8 s]: Recall = 0.1692, Jaccard score = 0.1449, loss = 0.4064, eval: [6.9 s]
# Iteration 5 fit: [13.9 s]: Recall = 0.1696, Jaccard score = 0.1452, loss = 0.4036, eval: [6.9 s]
# Iteration 6 fit: [13.8 s]: Recall = 0.1721, Jaccard score = 0.1478, loss = 0.4018, eval: [7.0 s]
# Iteration 7 fit: [13.8 s]: Recall = 0.1714, Jaccard score = 0.1470, loss = 0.3996, eval: [6.9 s]
# Iteration 8 fit: [13.8 s]: Recall = 0.1734, Jaccard score = 0.1490, loss = 0.3979, eval: [6.8 s]
# Iteration 9 fit: [13.8 s]: Recall = 0.1781, Jaccard score = 0.1537, loss = 0.3962, eval: [7.0 s]
# Iteration 10 fit: [13.7 s]: Recall = 0.1772, Jaccard score = 0.1528, loss = 0.3947, eval: [7.0 s]
# Iteration 11 fit: [13.8 s]: Recall = 0.1784, Jaccard score = 0.1539, loss = 0.3932, eval: [7.1 s]
# Iteration 12 fit: [13.7 s]: Recall = 0.1791, Jaccard score = 0.1546, loss = 0.3920, eval: [6.8 s]
# Iteration 13 fit: [13.8 s]: Recall = 0.1796, Jaccard score = 0.1552, loss = 0.3909, eval: [6.8 s]
# Iteration 14 fit: [14.1 s]: Recall = 0.1819, Jaccard score = 0.1575, loss = 0.3897, eval: [8.2 s]
# Iteration 15 fit: [14.7 s]: Recall = 0.1828, Jaccard score = 0.1583, loss = 0.3888, eval: [6.8 s]
# Iteration 16 fit: [15.1 s]: Recall = 0.1819, Jaccard score = 0.1575, loss = 0.3880, eval: [8.6 s]
# Iteration 17 fit: [15.8 s]: Recall = 0.1850, Jaccard score = 0.1606, loss = 0.3868, eval: [7.0 s]
# Iteration 18 fit: [14.1 s]: Recall = 0.1838, Jaccard score = 0.1594, loss = 0.3855, eval: [6.9 s]
# Iteration 19 fit: [13.6 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.3846, eval: [6.9 s]
# Iteration 20 fit: [13.8 s]: Recall = 0.1866, Jaccard score = 0.1622, loss = 0.3840, eval: [6.8 s]
# Iteration 21 fit: [13.8 s]: Recall = 0.1847, Jaccard score = 0.1603, loss = 0.3830, eval: [7.0 s]
# Iteration 22 fit: [13.9 s]: Recall = 0.1842, Jaccard score = 0.1598, loss = 0.3822, eval: [6.9 s]
# Iteration 23 fit: [13.8 s]: Recall = 0.1873, Jaccard score = 0.1629, loss = 0.3815, eval: [6.8 s]
# Iteration 24 fit: [13.8 s]: Recall = 0.1884, Jaccard score = 0.1640, loss = 0.3803, eval: [7.0 s]
# Iteration 25 fit: [13.7 s]: Recall = 0.1875, Jaccard score = 0.1631, loss = 0.3797, eval: [6.9 s]
# Iteration 26 fit: [13.8 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3794, eval: [6.8 s]
# Iteration 27 fit: [14.0 s]: Recall = 0.1886, Jaccard score = 0.1642, loss = 0.3788, eval: [7.0 s]
# Iteration 28 fit: [13.8 s]: Recall = 0.1897, Jaccard score = 0.1654, loss = 0.3782, eval: [6.8 s]
# Iteration 29 fit: [13.8 s]: Recall = 0.1897, Jaccard score = 0.1653, loss = 0.3772, eval: [7.0 s]
# Iteration 30 fit: [13.8 s]: Recall = 0.1906, Jaccard score = 0.1663, loss = 0.3765, eval: [6.9 s]
# Iteration 31 fit: [14.2 s]: Recall = 0.1910, Jaccard score = 0.1667, loss = 0.3757, eval: [6.9 s]
# Iteration 32 fit: [13.8 s]: Recall = 0.1917, Jaccard score = 0.1674, loss = 0.3760, eval: [6.9 s]
# Iteration 33 fit: [13.8 s]: Recall = 0.1895, Jaccard score = 0.1651, loss = 0.3746, eval: [6.9 s]
# Iteration 34 fit: [13.8 s]: Recall = 0.1919, Jaccard score = 0.1675, loss = 0.3743, eval: [6.8 s]
# Iteration 35 fit: [13.8 s]: Recall = 0.1927, Jaccard score = 0.1683, loss = 0.3735, eval: [6.8 s]
# Iteration 36 fit: [13.8 s]: Recall = 0.1916, Jaccard score = 0.1673, loss = 0.3728, eval: [6.8 s]
# Iteration 37 fit: [13.8 s]: Recall = 0.1890, Jaccard score = 0.1646, loss = 0.3725, eval: [6.9 s]
# Iteration 38 fit: [13.8 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3720, eval: [6.8 s]
# Iteration 39 fit: [13.8 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3715, eval: [7.0 s]
# Iteration 40 fit: [14.1 s]: Recall = 0.1948, Jaccard score = 0.1705, loss = 0.3712, eval: [6.9 s]
# Iteration 41 fit: [13.8 s]: Recall = 0.1945, Jaccard score = 0.1702, loss = 0.3705, eval: [6.9 s]
# Iteration 42 fit: [13.7 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3702, eval: [6.8 s]
# Iteration 43 fit: [14.1 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3697, eval: [7.0 s]
# Iteration 44 fit: [13.7 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3693, eval: [6.8 s]
# Iteration 45 fit: [13.8 s]: Recall = 0.1931, Jaccard score = 0.1688, loss = 0.3686, eval: [6.9 s]
# Iteration 46 fit: [13.8 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3682, eval: [6.8 s]
# Iteration 47 fit: [13.8 s]: Recall = 0.1957, Jaccard score = 0.1714, loss = 0.3681, eval: [7.0 s]
# Iteration 48 fit: [14.0 s]: Recall = 0.1944, Jaccard score = 0.1701, loss = 0.3670, eval: [6.9 s]
# Iteration 49 fit: [13.7 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3671, eval: [6.9 s]
# Iteration 50 fit: [13.6 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3664, eval: [7.0 s]
# Iteration 51 fit: [13.8 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3662, eval: [6.9 s]
# Iteration 52 fit: [13.9 s]: Recall = 0.1964, Jaccard score = 0.1721, loss = 0.3657, eval: [6.9 s]
# Iteration 53 fit: [13.6 s]: Recall = 0.1948, Jaccard score = 0.1706, loss = 0.3650, eval: [7.0 s]
# Iteration 54 fit: [13.9 s]: Recall = 0.1983, Jaccard score = 0.1742, loss = 0.3650, eval: [7.0 s]
# Iteration 55 fit: [13.8 s]: Recall = 0.1953, Jaccard score = 0.1710, loss = 0.3646, eval: [6.9 s]
# Iteration 56 fit: [13.8 s]: Recall = 0.1966, Jaccard score = 0.1724, loss = 0.3643, eval: [7.0 s]
# Iteration 57 fit: [13.8 s]: Recall = 0.1991, Jaccard score = 0.1750, loss = 0.3635, eval: [7.0 s]
# Iteration 58 fit: [13.8 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3636, eval: [7.0 s]
# Iteration 59 fit: [14.2 s]: Recall = 0.1978, Jaccard score = 0.1736, loss = 0.3630, eval: [7.0 s]
# Iteration 60 fit: [13.8 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3625, eval: [6.8 s]
# Iteration 61 fit: [14.0 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3625, eval: [7.0 s]
# Iteration 62 fit: [13.7 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3617, eval: [6.8 s]
# Iteration 63 fit: [13.5 s]: Recall = 0.1983, Jaccard score = 0.1741, loss = 0.3616, eval: [6.8 s]
# Iteration 64 fit: [13.6 s]: Recall = 0.1984, Jaccard score = 0.1743, loss = 0.3612, eval: [6.8 s]
# Iteration 65 fit: [14.1 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3611, eval: [6.8 s]
# Iteration 66 fit: [13.8 s]: Recall = 0.1989, Jaccard score = 0.1747, loss = 0.3609, eval: [6.9 s]
# Iteration 67 fit: [13.8 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3599, eval: [6.9 s]
# Iteration 68 fit: [13.9 s]: Recall = 0.1999, Jaccard score = 0.1758, loss = 0.3600, eval: [6.8 s]
# Iteration 69 fit: [13.6 s]: Recall = 0.2000, Jaccard score = 0.1758, loss = 0.3599, eval: [6.9 s]
# Iteration 70 fit: [13.8 s]: Recall = 0.1991, Jaccard score = 0.1749, loss = 0.3594, eval: [7.0 s]
# Iteration 71 fit: [13.6 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.3590, eval: [6.8 s]
# Iteration 72 fit: [13.9 s]: Recall = 0.1991, Jaccard score = 0.1749, loss = 0.3586, eval: [6.9 s]
# Iteration 73 fit: [13.8 s]: Recall = 0.2023, Jaccard score = 0.1782, loss = 0.3584, eval: [6.8 s]
# Iteration 74 fit: [13.8 s]: Recall = 0.2007, Jaccard score = 0.1767, loss = 0.3580, eval: [6.9 s]
# Iteration 75 fit: [13.8 s]: Recall = 0.2001, Jaccard score = 0.1760, loss = 0.3576, eval: [6.9 s]
# Iteration 76 fit: [14.1 s]: Recall = 0.2024, Jaccard score = 0.1784, loss = 0.3578, eval: [7.0 s]
# Iteration 77 fit: [13.6 s]: Recall = 0.2000, Jaccard score = 0.1759, loss = 0.3572, eval: [6.8 s]
# Iteration 78 fit: [13.8 s]: Recall = 0.1983, Jaccard score = 0.1741, loss = 0.3570, eval: [6.9 s]
# Iteration 79 fit: [13.8 s]: Recall = 0.2017, Jaccard score = 0.1776, loss = 0.3568, eval: [6.8 s]
# Iteration 80 fit: [13.8 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.3570, eval: [6.9 s]
# Iteration 81 fit: [13.8 s]: Recall = 0.2016, Jaccard score = 0.1775, loss = 0.3560, eval: [6.8 s]
# Iteration 82 fit: [13.9 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3557, eval: [7.0 s]
# Iteration 83 fit: [13.8 s]: Recall = 0.2025, Jaccard score = 0.1785, loss = 0.3552, eval: [6.8 s]
# Iteration 84 fit: [13.8 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3552, eval: [6.8 s]
# Iteration 85 fit: [13.7 s]: Recall = 0.2015, Jaccard score = 0.1774, loss = 0.3551, eval: [6.8 s]
# Iteration 86 fit: [13.6 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3552, eval: [7.0 s]
# Iteration 87 fit: [13.8 s]: Recall = 0.2012, Jaccard score = 0.1771, loss = 0.3545, eval: [6.8 s]
# Iteration 88 fit: [13.5 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3540, eval: [6.8 s]
# Iteration 89 fit: [13.6 s]: Recall = 0.2000, Jaccard score = 0.1759, loss = 0.3544, eval: [7.0 s]
# Iteration 90 fit: [13.7 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3540, eval: [7.0 s]
# Iteration 91 fit: [13.9 s]: Recall = 0.2014, Jaccard score = 0.1774, loss = 0.3535, eval: [6.8 s]
# Iteration 92 fit: [13.7 s]: Recall = 0.2020, Jaccard score = 0.1779, loss = 0.3529, eval: [7.0 s]
# Iteration 93 fit: [13.8 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3533, eval: [6.8 s]
# Iteration 94 fit: [13.8 s]: Recall = 0.2050, Jaccard score = 0.1811, loss = 0.3526, eval: [7.0 s]
# Iteration 95 fit: [13.8 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3526, eval: [6.8 s]
# Iteration 96 fit: [13.8 s]: Recall = 0.2026, Jaccard score = 0.1786, loss = 0.3522, eval: [7.0 s]
# Iteration 97 fit: [14.0 s]: Recall = 0.2023, Jaccard score = 0.1783, loss = 0.3517, eval: [6.9 s]
# Iteration 98 fit: [13.8 s]: Recall = 0.2005, Jaccard score = 0.1764, loss = 0.3518, eval: [6.8 s]
# Iteration 99 fit: [13.6 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.3515, eval: [7.0 s]
# Iteration 100 fit: [13.9 s]: Recall = 0.2030, Jaccard score = 0.1790, loss = 0.3510, eval: [6.9 s]
# Iteration 101 fit: [13.9 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3509, eval: [6.8 s]
# Iteration 102 fit: [13.9 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3509, eval: [7.0 s]
# Iteration 103 fit: [13.8 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3513, eval: [6.8 s]
# Iteration 104 fit: [14.2 s]: Recall = 0.2044, Jaccard score = 0.1805, loss = 0.3508, eval: [7.0 s]
# Iteration 105 fit: [13.5 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3501, eval: [7.0 s]
# Iteration 106 fit: [14.0 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3499, eval: [6.9 s]
# Iteration 107 fit: [13.8 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3494, eval: [6.8 s]
# Iteration 108 fit: [13.5 s]: Recall = 0.2018, Jaccard score = 0.1777, loss = 0.3497, eval: [6.8 s]
# Iteration 109 fit: [13.7 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3495, eval: [6.9 s]
# Iteration 110 fit: [13.8 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3491, eval: [6.8 s]
# Iteration 111 fit: [13.8 s]: Recall = 0.2044, Jaccard score = 0.1804, loss = 0.3488, eval: [6.9 s]
# Iteration 112 fit: [13.6 s]: Recall = 0.2039, Jaccard score = 0.1800, loss = 0.3486, eval: [7.0 s]
# Iteration 113 fit: [14.1 s]: Recall = 0.2039, Jaccard score = 0.1799, loss = 0.3488, eval: [6.9 s]
# Iteration 114 fit: [13.5 s]: Recall = 0.2026, Jaccard score = 0.1786, loss = 0.3484, eval: [7.0 s]
# Iteration 115 fit: [13.9 s]: Recall = 0.2031, Jaccard score = 0.1791, loss = 0.3479, eval: [7.0 s]
# Iteration 116 fit: [13.9 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3477, eval: [6.9 s]
# Iteration 117 fit: [13.8 s]: Recall = 0.2047, Jaccard score = 0.1808, loss = 0.3478, eval: [6.8 s]
# Iteration 118 fit: [13.8 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.3474, eval: [6.9 s]
# Iteration 119 fit: [13.8 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3469, eval: [6.9 s]
# Iteration 120 fit: [13.8 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.3467, eval: [7.0 s]
# Iteration 121 fit: [14.0 s]: Recall = 0.2037, Jaccard score = 0.1797, loss = 0.3467, eval: [7.0 s]
# Iteration 122 fit: [13.8 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3467, eval: [6.9 s]
# Iteration 123 fit: [13.9 s]: Recall = 0.2031, Jaccard score = 0.1791, loss = 0.3459, eval: [6.9 s]
# Iteration 124 fit: [13.6 s]: Recall = 0.2047, Jaccard score = 0.1807, loss = 0.3463, eval: [6.9 s]
# Iteration 125 fit: [13.8 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3457, eval: [7.0 s]
# Iteration 126 fit: [13.9 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.3456, eval: [6.9 s]
# Iteration 127 fit: [14.0 s]: Recall = 0.2034, Jaccard score = 0.1794, loss = 0.3458, eval: [6.8 s]
# Iteration 128 fit: [13.9 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3453, eval: [7.0 s]
# Iteration 129 fit: [13.8 s]: Recall = 0.2015, Jaccard score = 0.1775, loss = 0.3453, eval: [6.9 s]
# Iteration 130 fit: [13.8 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3454, eval: [6.9 s]
# Iteration 131 fit: [13.5 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3445, eval: [6.9 s]
# Iteration 132 fit: [13.8 s]: Recall = 0.2035, Jaccard score = 0.1795, loss = 0.3445, eval: [6.8 s]
# Iteration 133 fit: [13.8 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.3449, eval: [7.0 s]
# Iteration 134 fit: [13.5 s]: Recall = 0.2038, Jaccard score = 0.1798, loss = 0.3447, eval: [6.9 s]
# Iteration 135 fit: [13.7 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3441, eval: [7.0 s]
# Iteration 136 fit: [13.8 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3439, eval: [6.9 s]
# Iteration 137 fit: [13.5 s]: Recall = 0.2068, Jaccard score = 0.1829, loss = 0.3441, eval: [6.9 s]
# Iteration 138 fit: [13.8 s]: Recall = 0.2054, Jaccard score = 0.1815, loss = 0.3438, eval: [6.9 s]
# Iteration 139 fit: [13.7 s]: Recall = 0.2050, Jaccard score = 0.1810, loss = 0.3431, eval: [6.9 s]
# Iteration 140 fit: [14.0 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.3434, eval: [6.9 s]
# Iteration 141 fit: [13.9 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3429, eval: [6.8 s]
# Iteration 142 fit: [13.6 s]: Recall = 0.2038, Jaccard score = 0.1798, loss = 0.3429, eval: [6.9 s]
# Iteration 143 fit: [13.9 s]: Recall = 0.2046, Jaccard score = 0.1806, loss = 0.3427, eval: [7.0 s]
# Iteration 144 fit: [13.8 s]: Recall = 0.2044, Jaccard score = 0.1804, loss = 0.3423, eval: [7.0 s]
# Iteration 145 fit: [13.8 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3425, eval: [6.9 s]
# Iteration 146 fit: [13.8 s]: Recall = 0.2050, Jaccard score = 0.1811, loss = 0.3420, eval: [6.9 s]
# Iteration 147 fit: [13.7 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3423, eval: [6.8 s]
# Iteration 148 fit: [13.7 s]: Recall = 0.2068, Jaccard score = 0.1829, loss = 0.3417, eval: [6.9 s]
# Iteration 149 fit: [13.5 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3417, eval: [7.0 s]
# Iteration 150 fit: [13.3 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3414, eval: [6.9 s]
# Iteration 151 fit: [13.9 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.3415, eval: [7.0 s]
# Iteration 152 fit: [13.5 s]: Recall = 0.2088, Jaccard score = 0.1851, loss = 0.3413, eval: [6.8 s]
# Iteration 153 fit: [13.9 s]: Recall = 0.2047, Jaccard score = 0.1807, loss = 0.3411, eval: [6.9 s]
# Iteration 154 fit: [13.8 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3410, eval: [6.8 s]
# Iteration 155 fit: [13.5 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.3411, eval: [6.9 s]
# Iteration 156 fit: [13.8 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.3410, eval: [6.9 s]
# Iteration 157 fit: [13.8 s]: Recall = 0.2043, Jaccard score = 0.1803, loss = 0.3403, eval: [6.9 s]
# Iteration 158 fit: [13.9 s]: Recall = 0.2037, Jaccard score = 0.1797, loss = 0.3398, eval: [7.0 s]
# Iteration 159 fit: [13.9 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.3402, eval: [6.9 s]
# Iteration 160 fit: [13.8 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3400, eval: [7.0 s]
# Iteration 161 fit: [13.9 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3395, eval: [7.0 s]
# Iteration 162 fit: [13.7 s]: Recall = 0.2060, Jaccard score = 0.1821, loss = 0.3397, eval: [7.0 s]
# Iteration 163 fit: [13.9 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3398, eval: [7.0 s]
# Iteration 164 fit: [13.5 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3391, eval: [6.9 s]
# Iteration 165 fit: [13.9 s]: Recall = 0.2047, Jaccard score = 0.1808, loss = 0.3391, eval: [7.0 s]
# Iteration 166 fit: [13.8 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3392, eval: [6.9 s]
# Iteration 167 fit: [13.9 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3389, eval: [7.0 s]
# Iteration 168 fit: [13.7 s]: Recall = 0.2066, Jaccard score = 0.1828, loss = 0.3391, eval: [6.9 s]
# Iteration 169 fit: [13.8 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3386, eval: [6.9 s]
# Iteration 170 fit: [13.8 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3385, eval: [6.9 s]
# Iteration 171 fit: [13.7 s]: Recall = 0.2057, Jaccard score = 0.1818, loss = 0.3384, eval: [7.0 s]
# Iteration 172 fit: [13.8 s]: Recall = 0.2073, Jaccard score = 0.1835, loss = 0.3386, eval: [6.8 s]
# Iteration 173 fit: [13.8 s]: Recall = 0.2083, Jaccard score = 0.1846, loss = 0.3380, eval: [7.0 s]
# Iteration 174 fit: [13.8 s]: Recall = 0.2066, Jaccard score = 0.1828, loss = 0.3380, eval: [6.8 s]
# Iteration 175 fit: [13.8 s]: Recall = 0.2050, Jaccard score = 0.1810, loss = 0.3381, eval: [6.9 s]
# Iteration 176 fit: [13.7 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3373, eval: [6.8 s]
# Iteration 177 fit: [13.8 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3376, eval: [6.9 s]
# Iteration 178 fit: [13.8 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3374, eval: [6.8 s]
# Iteration 179 fit: [13.6 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3371, eval: [6.8 s]
# Iteration 180 fit: [13.6 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.3373, eval: [6.9 s]
# Iteration 181 fit: [13.8 s]: Recall = 0.2077, Jaccard score = 0.1839, loss = 0.3369, eval: [6.9 s]
# Iteration 182 fit: [14.1 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3369, eval: [6.9 s]
# Iteration 183 fit: [13.7 s]: Recall = 0.2070, Jaccard score = 0.1832, loss = 0.3365, eval: [6.9 s]
# Iteration 184 fit: [13.7 s]: Recall = 0.2081, Jaccard score = 0.1843, loss = 0.3365, eval: [6.9 s]
# Iteration 185 fit: [13.8 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3360, eval: [6.9 s]
# Iteration 186 fit: [13.7 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3361, eval: [6.9 s]
# Iteration 187 fit: [13.8 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3361, eval: [6.9 s]
# End. Best Iteration 152:  Recall = 0.2088, Jaccard score = 0.1851. 
# The best NeuMF model has been saved to Pretrain/_MLP_8_[1024,128]_1564063268.h5
# Model test performed 
# Recall score: 0.06872795414462081     Jaccard score: 0.05446128313752893

# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1565598224.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1565598224.h5
# Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 512)          512512      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 512)          0           dense_feature_layer1[0][0]       
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 512)          0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1024)         0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          131200      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 1,667,841
# Trainable params: 1,667,841
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
#  Detta var med dropout och utan activation layer fr features
# Performing k-fold 1
# Init: Recall = 0.0241, Jaccard score = 0.0184
# Iteration 0 fit: [15.8 s]: Recall = 0.1439, Jaccard score = 0.1206, loss = 0.4701, eval: [6.8 s]
# Iteration 1 fit: [14.2 s]: Recall = 0.1544, Jaccard score = 0.1306, loss = 0.4391, eval: [7.0 s]
# Iteration 2 fit: [14.3 s]: Recall = 0.1676, Jaccard score = 0.1433, loss = 0.4290, eval: [6.9 s]
# Iteration 3 fit: [14.3 s]: Recall = 0.1747, Jaccard score = 0.1503, loss = 0.4214, eval: [7.0 s]
# Iteration 4 fit: [14.2 s]: Recall = 0.1803, Jaccard score = 0.1559, loss = 0.4153, eval: [7.0 s]
# Iteration 5 fit: [13.9 s]: Recall = 0.1868, Jaccard score = 0.1624, loss = 0.4104, eval: [7.0 s]
# Iteration 6 fit: [14.3 s]: Recall = 0.1901, Jaccard score = 0.1657, loss = 0.4058, eval: [6.9 s]
# Iteration 7 fit: [14.3 s]: Recall = 0.1926, Jaccard score = 0.1683, loss = 0.4013, eval: [6.9 s]
# Iteration 8 fit: [14.3 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3979, eval: [6.8 s]
# Iteration 9 fit: [14.2 s]: Recall = 0.1995, Jaccard score = 0.1754, loss = 0.3946, eval: [6.9 s]
# Iteration 10 fit: [14.2 s]: Recall = 0.1972, Jaccard score = 0.1730, loss = 0.3914, eval: [6.9 s]
# Iteration 11 fit: [14.3 s]: Recall = 0.2006, Jaccard score = 0.1765, loss = 0.3887, eval: [7.0 s]
# Iteration 12 fit: [14.2 s]: Recall = 0.2011, Jaccard score = 0.1771, loss = 0.3858, eval: [6.8 s]
# Iteration 13 fit: [14.3 s]: Recall = 0.2015, Jaccard score = 0.1775, loss = 0.3838, eval: [6.9 s]
# Iteration 14 fit: [14.2 s]: Recall = 0.2047, Jaccard score = 0.1807, loss = 0.3811, eval: [6.9 s]
# Iteration 15 fit: [14.2 s]: Recall = 0.2039, Jaccard score = 0.1800, loss = 0.3786, eval: [6.9 s]
# Iteration 16 fit: [14.3 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3771, eval: [6.8 s]
# Iteration 17 fit: [14.2 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3749, eval: [6.9 s]
# Iteration 18 fit: [14.4 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3724, eval: [6.9 s]
# Iteration 19 fit: [14.2 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3712, eval: [6.9 s]
# Iteration 20 fit: [14.2 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3700, eval: [6.8 s]
# Iteration 21 fit: [14.3 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3675, eval: [6.9 s]
# Iteration 22 fit: [14.3 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3666, eval: [7.0 s]
# Iteration 23 fit: [14.2 s]: Recall = 0.2064, Jaccard score = 0.1826, loss = 0.3657, eval: [7.0 s]
# Iteration 24 fit: [14.5 s]: Recall = 0.2074, Jaccard score = 0.1836, loss = 0.3634, eval: [6.9 s]
# Iteration 25 fit: [14.3 s]: Recall = 0.2101, Jaccard score = 0.1864, loss = 0.3621, eval: [6.9 s]
# Iteration 26 fit: [14.2 s]: Recall = 0.2093, Jaccard score = 0.1856, loss = 0.3615, eval: [6.9 s]
# Iteration 27 fit: [14.3 s]: Recall = 0.2096, Jaccard score = 0.1859, loss = 0.3601, eval: [6.9 s]
# Iteration 28 fit: [14.2 s]: Recall = 0.2108, Jaccard score = 0.1872, loss = 0.3587, eval: [7.0 s]
# Iteration 29 fit: [13.9 s]: Recall = 0.2092, Jaccard score = 0.1854, loss = 0.3573, eval: [6.9 s]
# Iteration 30 fit: [14.2 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3566, eval: [6.9 s]
# Iteration 31 fit: [13.9 s]: Recall = 0.2083, Jaccard score = 0.1846, loss = 0.3552, eval: [6.9 s]
# Iteration 32 fit: [14.2 s]: Recall = 0.2080, Jaccard score = 0.1843, loss = 0.3546, eval: [6.9 s]
# Iteration 33 fit: [14.1 s]: Recall = 0.2104, Jaccard score = 0.1867, loss = 0.3536, eval: [6.9 s]
# Iteration 34 fit: [14.2 s]: Recall = 0.2100, Jaccard score = 0.1863, loss = 0.3523, eval: [6.9 s]
# Iteration 35 fit: [13.9 s]: Recall = 0.2086, Jaccard score = 0.1848, loss = 0.3516, eval: [6.9 s]
# Iteration 36 fit: [14.2 s]: Recall = 0.2093, Jaccard score = 0.1856, loss = 0.3501, eval: [6.9 s]
# Iteration 37 fit: [13.9 s]: Recall = 0.2107, Jaccard score = 0.1871, loss = 0.3495, eval: [6.9 s]
# Iteration 38 fit: [14.2 s]: Recall = 0.2093, Jaccard score = 0.1856, loss = 0.3481, eval: [7.0 s]
# Iteration 39 fit: [13.9 s]: Recall = 0.2115, Jaccard score = 0.1879, loss = 0.3477, eval: [7.0 s]
# Iteration 40 fit: [14.3 s]: Recall = 0.2101, Jaccard score = 0.1864, loss = 0.3474, eval: [7.0 s]
# Iteration 41 fit: [14.6 s]: Recall = 0.2110, Jaccard score = 0.1874, loss = 0.3463, eval: [8.7 s]
# Iteration 42 fit: [14.7 s]: Recall = 0.2114, Jaccard score = 0.1878, loss = 0.3456, eval: [6.9 s]
# Iteration 43 fit: [13.9 s]: Recall = 0.2129, Jaccard score = 0.1894, loss = 0.3442, eval: [7.0 s]
# Iteration 44 fit: [14.2 s]: Recall = 0.2120, Jaccard score = 0.1885, loss = 0.3440, eval: [6.9 s]
# Iteration 45 fit: [13.9 s]: Recall = 0.2116, Jaccard score = 0.1880, loss = 0.3428, eval: [6.9 s]
# Iteration 46 fit: [14.2 s]: Recall = 0.2107, Jaccard score = 0.1871, loss = 0.3423, eval: [7.0 s]
# Iteration 47 fit: [13.9 s]: Recall = 0.2142, Jaccard score = 0.1907, loss = 0.3413, eval: [7.0 s]
# Iteration 48 fit: [14.2 s]: Recall = 0.2108, Jaccard score = 0.1872, loss = 0.3409, eval: [6.9 s]
# Iteration 49 fit: [13.9 s]: Recall = 0.2115, Jaccard score = 0.1879, loss = 0.3397, eval: [6.9 s]
# Iteration 50 fit: [14.2 s]: Recall = 0.2121, Jaccard score = 0.1886, loss = 0.3390, eval: [6.9 s]
# Iteration 51 fit: [13.9 s]: Recall = 0.2083, Jaccard score = 0.1846, loss = 0.3380, eval: [6.9 s]
# Iteration 52 fit: [14.2 s]: Recall = 0.2109, Jaccard score = 0.1873, loss = 0.3388, eval: [6.9 s]
# Iteration 53 fit: [13.9 s]: Recall = 0.2116, Jaccard score = 0.1880, loss = 0.3375, eval: [6.9 s]
# Iteration 54 fit: [14.2 s]: Recall = 0.2115, Jaccard score = 0.1879, loss = 0.3366, eval: [6.9 s]
# Iteration 55 fit: [13.9 s]: Recall = 0.2110, Jaccard score = 0.1873, loss = 0.3367, eval: [6.9 s]
# Iteration 56 fit: [14.2 s]: Recall = 0.2114, Jaccard score = 0.1878, loss = 0.3356, eval: [6.9 s]
# Iteration 57 fit: [13.9 s]: Recall = 0.2116, Jaccard score = 0.1880, loss = 0.3357, eval: [6.9 s]
# Iteration 58 fit: [14.2 s]: Recall = 0.2107, Jaccard score = 0.1871, loss = 0.3341, eval: [6.9 s]
# Iteration 59 fit: [13.9 s]: Recall = 0.2100, Jaccard score = 0.1863, loss = 0.3337, eval: [7.0 s]
# Iteration 60 fit: [14.2 s]: Recall = 0.2111, Jaccard score = 0.1875, loss = 0.3326, eval: [6.9 s]
# Iteration 61 fit: [14.3 s]: Recall = 0.2119, Jaccard score = 0.1883, loss = 0.3330, eval: [6.9 s]
# Iteration 62 fit: [14.2 s]: Recall = 0.2092, Jaccard score = 0.1854, loss = 0.3324, eval: [7.0 s]
# Iteration 63 fit: [13.9 s]: Recall = 0.2123, Jaccard score = 0.1887, loss = 0.3318, eval: [7.2 s]
# Iteration 64 fit: [16.7 s]: Recall = 0.2110, Jaccard score = 0.1874, loss = 0.3312, eval: [8.2 s]
# Iteration 65 fit: [15.5 s]: Recall = 0.2109, Jaccard score = 0.1873, loss = 0.3300, eval: [6.9 s]
# Iteration 66 fit: [14.2 s]: Recall = 0.2102, Jaccard score = 0.1865, loss = 0.3299, eval: [7.0 s]
# Iteration 67 fit: [13.9 s]: Recall = 0.2108, Jaccard score = 0.1872, loss = 0.3303, eval: [6.9 s]
# Iteration 68 fit: [14.2 s]: Recall = 0.2111, Jaccard score = 0.1875, loss = 0.3293, eval: [6.9 s]
# Iteration 69 fit: [13.9 s]: Recall = 0.2120, Jaccard score = 0.1885, loss = 0.3283, eval: [6.9 s]
# Iteration 70 fit: [14.2 s]: Recall = 0.2130, Jaccard score = 0.1895, loss = 0.3271, eval: [7.0 s]
# Iteration 71 fit: [13.9 s]: Recall = 0.2133, Jaccard score = 0.1898, loss = 0.3279, eval: [6.9 s]
# Iteration 72 fit: [14.2 s]: Recall = 0.2118, Jaccard score = 0.1882, loss = 0.3269, eval: [6.9 s]
# Iteration 73 fit: [13.9 s]: Recall = 0.2119, Jaccard score = 0.1883, loss = 0.3271, eval: [6.9 s]
# Iteration 74 fit: [14.2 s]: Recall = 0.2115, Jaccard score = 0.1879, loss = 0.3260, eval: [7.0 s]
# Iteration 75 fit: [13.9 s]: Recall = 0.2114, Jaccard score = 0.1878, loss = 0.3258, eval: [6.9 s]
# Iteration 76 fit: [14.3 s]: Recall = 0.2110, Jaccard score = 0.1874, loss = 0.3242, eval: [7.0 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1565599907.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1565599907.h5
# Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 512)          512512      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1024)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          131200      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 1,667,841
# Trainable params: 1,667,841
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0282, Jaccard score = 0.0215
# Iteration 0 fit: [14.1 s]: Recall = 0.1543, Jaccard score = 0.1304, loss = 0.4362, eval: [6.7 s]
# Iteration 1 fit: [13.6 s]: Recall = 0.1752, Jaccard score = 0.1508, loss = 0.4061, eval: [6.9 s]
# Iteration 2 fit: [13.8 s]: Recall = 0.1880, Jaccard score = 0.1636, loss = 0.3902, eval: [6.8 s]
# Iteration 3 fit: [13.6 s]: Recall = 0.1919, Jaccard score = 0.1675, loss = 0.3776, eval: [6.9 s]
# Iteration 4 fit: [13.6 s]: Recall = 0.1991, Jaccard score = 0.1749, loss = 0.3677, eval: [6.8 s]
# Iteration 5 fit: [13.6 s]: Recall = 0.1992, Jaccard score = 0.1750, loss = 0.3591, eval: [6.8 s]
# Iteration 6 fit: [13.6 s]: Recall = 0.2012, Jaccard score = 0.1771, loss = 0.3514, eval: [6.9 s]
# Iteration 7 fit: [13.6 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3446, eval: [6.8 s]
# Iteration 8 fit: [13.6 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3388, eval: [6.9 s]
# Iteration 9 fit: [14.1 s]: Recall = 0.2061, Jaccard score = 0.1823, loss = 0.3336, eval: [6.9 s]
# Iteration 10 fit: [13.6 s]: Recall = 0.2086, Jaccard score = 0.1849, loss = 0.3283, eval: [6.9 s]
# Iteration 11 fit: [13.6 s]: Recall = 0.2087, Jaccard score = 0.1849, loss = 0.3235, eval: [6.9 s]
# Iteration 12 fit: [13.7 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3192, eval: [6.8 s]
# Iteration 13 fit: [13.6 s]: Recall = 0.2068, Jaccard score = 0.1830, loss = 0.3142, eval: [6.9 s]
# Iteration 14 fit: [13.6 s]: Recall = 0.2066, Jaccard score = 0.1827, loss = 0.3098, eval: [6.8 s]
# Iteration 15 fit: [13.6 s]: Recall = 0.2057, Jaccard score = 0.1818, loss = 0.3059, eval: [6.9 s]
# Iteration 16 fit: [13.6 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3016, eval: [6.8 s]
# Iteration 17 fit: [13.6 s]: Recall = 0.2069, Jaccard score = 0.1830, loss = 0.2981, eval: [6.9 s]
# Iteration 18 fit: [13.6 s]: Recall = 0.2070, Jaccard score = 0.1831, loss = 0.2932, eval: [6.9 s]
# Iteration 19 fit: [13.6 s]: Recall = 0.2066, Jaccard score = 0.1827, loss = 0.2899, eval: [6.8 s]
# Iteration 20 fit: [13.6 s]: Recall = 0.2077, Jaccard score = 0.1839, loss = 0.2861, eval: [6.8 s]
# Iteration 21 fit: [13.6 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.2826, eval: [6.8 s]
# Iteration 22 fit: [13.6 s]: Recall = 0.2074, Jaccard score = 0.1836, loss = 0.2788, eval: [6.8 s]
# Iteration 23 fit: [13.6 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.2750, eval: [6.9 s]
# Iteration 24 fit: [13.6 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.2718, eval: [6.8 s]
# Iteration 25 fit: [13.6 s]: Recall = 0.2066, Jaccard score = 0.1827, loss = 0.2677, eval: [6.8 s]
# Iteration 26 fit: [13.6 s]: Recall = 0.2042, Jaccard score = 0.1802, loss = 0.2643, eval: [6.8 s]
# Iteration 27 fit: [13.6 s]: Recall = 0.2073, Jaccard score = 0.1835, loss = 0.2609, eval: [6.8 s]
# Iteration 28 fit: [13.6 s]: Recall = 0.2073, Jaccard score = 0.1834, loss = 0.2580, eval: [6.8 s]
# Iteration 29 fit: [13.6 s]: Recall = 0.2038, Jaccard score = 0.1798, loss = 0.2542, eval: [6.8 s]
# Iteration 30 fit: [13.7 s]: Recall = 0.1998, Jaccard score = 0.1757, loss = 0.2513, eval: [6.9 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1565600567.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1565600567.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 512)          512512      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 512)          0           dense_feature_layer1[0][0]       
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 512)          0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1024)         0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          131200      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 1,667,841
# Trainable params: 1,667,841
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0325, Jaccard score = 0.0249
# Iteration 0 fit: [14.4 s]: Recall = 0.1388, Jaccard score = 0.1158, loss = 0.4792, eval: [6.8 s]
# Iteration 1 fit: [13.9 s]: Recall = 0.1415, Jaccard score = 0.1183, loss = 0.4417, eval: [6.8 s]
# Iteration 2 fit: [13.9 s]: Recall = 0.1520, Jaccard score = 0.1283, loss = 0.4328, eval: [6.7 s]
# Iteration 3 fit: [13.9 s]: Recall = 0.1580, Jaccard score = 0.1340, loss = 0.4270, eval: [6.8 s]
# Iteration 4 fit: [13.9 s]: Recall = 0.1642, Jaccard score = 0.1400, loss = 0.4215, eval: [6.8 s]
# Iteration 5 fit: [13.9 s]: Recall = 0.1740, Jaccard score = 0.1496, loss = 0.4163, eval: [6.8 s]
# Iteration 6 fit: [13.9 s]: Recall = 0.1807, Jaccard score = 0.1562, loss = 0.4112, eval: [6.8 s]
# Iteration 7 fit: [13.9 s]: Recall = 0.1833, Jaccard score = 0.1589, loss = 0.4066, eval: [6.8 s]
# Iteration 8 fit: [13.9 s]: Recall = 0.1873, Jaccard score = 0.1629, loss = 0.4025, eval: [6.8 s]
# Iteration 9 fit: [13.9 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.3988, eval: [6.8 s]
# Iteration 10 fit: [13.9 s]: Recall = 0.1950, Jaccard score = 0.1707, loss = 0.3951, eval: [6.8 s]
# Iteration 11 fit: [13.9 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3921, eval: [6.8 s]
# Iteration 12 fit: [13.9 s]: Recall = 0.1951, Jaccard score = 0.1708, loss = 0.3892, eval: [6.8 s]
# Iteration 13 fit: [13.9 s]: Recall = 0.1982, Jaccard score = 0.1740, loss = 0.3863, eval: [6.8 s]
# Iteration 14 fit: [13.9 s]: Recall = 0.1992, Jaccard score = 0.1750, loss = 0.3830, eval: [6.9 s]
# Iteration 15 fit: [13.9 s]: Recall = 0.2011, Jaccard score = 0.1771, loss = 0.3807, eval: [6.8 s]
# Iteration 16 fit: [14.4 s]: Recall = 0.2023, Jaccard score = 0.1782, loss = 0.3782, eval: [6.8 s]
# Iteration 17 fit: [13.9 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3761, eval: [6.8 s]
# Iteration 18 fit: [13.9 s]: Recall = 0.2024, Jaccard score = 0.1783, loss = 0.3741, eval: [6.8 s]
# Iteration 19 fit: [13.9 s]: Recall = 0.2028, Jaccard score = 0.1788, loss = 0.3722, eval: [6.8 s]
# Iteration 20 fit: [13.9 s]: Recall = 0.2046, Jaccard score = 0.1806, loss = 0.3702, eval: [6.8 s]
# Iteration 21 fit: [13.9 s]: Recall = 0.2034, Jaccard score = 0.1795, loss = 0.3685, eval: [6.8 s]
# Iteration 22 fit: [13.9 s]: Recall = 0.2063, Jaccard score = 0.1824, loss = 0.3670, eval: [6.8 s]
# Iteration 23 fit: [13.9 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3650, eval: [6.8 s]
# Iteration 24 fit: [13.9 s]: Recall = 0.2064, Jaccard score = 0.1826, loss = 0.3629, eval: [6.8 s]
# Iteration 25 fit: [13.9 s]: Recall = 0.2054, Jaccard score = 0.1815, loss = 0.3619, eval: [6.8 s]
# Iteration 26 fit: [13.9 s]: Recall = 0.2065, Jaccard score = 0.1826, loss = 0.3605, eval: [6.8 s]
# Iteration 27 fit: [13.9 s]: Recall = 0.2076, Jaccard score = 0.1838, loss = 0.3590, eval: [6.8 s]
# Iteration 28 fit: [13.9 s]: Recall = 0.2070, Jaccard score = 0.1831, loss = 0.3572, eval: [6.8 s]
# Iteration 29 fit: [14.0 s]: Recall = 0.2081, Jaccard score = 0.1843, loss = 0.3560, eval: [6.8 s]
# Iteration 30 fit: [13.9 s]: Recall = 0.2072, Jaccard score = 0.1834, loss = 0.3543, eval: [6.8 s]
# Iteration 31 fit: [13.9 s]: Recall = 0.2089, Jaccard score = 0.1852, loss = 0.3528, eval: [6.8 s]
# Iteration 32 fit: [13.9 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3523, eval: [6.8 s]
# Iteration 33 fit: [13.9 s]: Recall = 0.2092, Jaccard score = 0.1854, loss = 0.3508, eval: [6.8 s]
# Iteration 34 fit: [13.9 s]: Recall = 0.2078, Jaccard score = 0.1840, loss = 0.3490, eval: [6.8 s]
# Iteration 35 fit: [13.9 s]: Recall = 0.2091, Jaccard score = 0.1854, loss = 0.3483, eval: [6.8 s]
# Iteration 36 fit: [13.9 s]: Recall = 0.2078, Jaccard score = 0.1840, loss = 0.3471, eval: [6.8 s]
# Iteration 37 fit: [14.0 s]: Recall = 0.2084, Jaccard score = 0.1846, loss = 0.3461, eval: [6.8 s]
# Iteration 38 fit: [14.2 s]: Recall = 0.2087, Jaccard score = 0.1849, loss = 0.3451, eval: [6.8 s]
# Iteration 39 fit: [13.9 s]: Recall = 0.2096, Jaccard score = 0.1859, loss = 0.3439, eval: [6.8 s]
# Iteration 40 fit: [14.0 s]: Recall = 0.2086, Jaccard score = 0.1848, loss = 0.3427, eval: [6.9 s]
# Iteration 41 fit: [13.9 s]: Recall = 0.2077, Jaccard score = 0.1839, loss = 0.3411, eval: [6.8 s]
# Iteration 42 fit: [14.0 s]: Recall = 0.2103, Jaccard score = 0.1867, loss = 0.3401, eval: [6.8 s]
# Iteration 43 fit: [14.0 s]: Recall = 0.2097, Jaccard score = 0.1860, loss = 0.3390, eval: [6.8 s]
# Iteration 44 fit: [13.9 s]: Recall = 0.2074, Jaccard score = 0.1836, loss = 0.3383, eval: [6.8 s]
# Iteration 45 fit: [13.9 s]: Recall = 0.2118, Jaccard score = 0.1882, loss = 0.3382, eval: [6.8 s]
# Iteration 46 fit: [14.1 s]: Recall = 0.2110, Jaccard score = 0.1873, loss = 0.3364, eval: [6.8 s]
# Iteration 47 fit: [13.9 s]: Recall = 0.2101, Jaccard score = 0.1864, loss = 0.3357, eval: [6.8 s]
# Iteration 48 fit: [14.5 s]: Recall = 0.2105, Jaccard score = 0.1868, loss = 0.3344, eval: [6.8 s]
# Iteration 49 fit: [14.0 s]: Recall = 0.2094, Jaccard score = 0.1857, loss = 0.3336, eval: [6.8 s]
# Iteration 50 fit: [13.9 s]: Recall = 0.2114, Jaccard score = 0.1878, loss = 0.3327, eval: [6.8 s]
# Iteration 51 fit: [13.9 s]: Recall = 0.2087, Jaccard score = 0.1850, loss = 0.3322, eval: [6.8 s]
# Iteration 52 fit: [13.9 s]: Recall = 0.2107, Jaccard score = 0.1871, loss = 0.3306, eval: [6.8 s]
# Iteration 53 fit: [13.9 s]: Recall = 0.2080, Jaccard score = 0.1843, loss = 0.3298, eval: [6.8 s]
# Iteration 54 fit: [13.9 s]: Recall = 0.2094, Jaccard score = 0.1857, loss = 0.3292, eval: [6.8 s]
# Iteration 55 fit: [14.0 s]: Recall = 0.2115, Jaccard score = 0.1879, loss = 0.3282, eval: [6.8 s]
# Iteration 56 fit: [13.9 s]: Recall = 0.2107, Jaccard score = 0.1871, loss = 0.3271, eval: [6.8 s]
# Iteration 57 fit: [13.9 s]: Recall = 0.2113, Jaccard score = 0.1877, loss = 0.3257, eval: [6.8 s]
# Iteration 58 fit: [13.9 s]: Recall = 0.2095, Jaccard score = 0.1858, loss = 0.3258, eval: [6.8 s]
# Iteration 59 fit: [13.9 s]: Recall = 0.2123, Jaccard score = 0.1888, loss = 0.3250, eval: [6.8 s]
# Iteration 60 fit: [13.9 s]: Recall = 0.2098, Jaccard score = 0.1861, loss = 0.3238, eval: [6.8 s]
# Iteration 61 fit: [13.9 s]: Recall = 0.2112, Jaccard score = 0.1876, loss = 0.3235, eval: [6.8 s]
# Iteration 62 fit: [13.9 s]: Recall = 0.2112, Jaccard score = 0.1876, loss = 0.3223, eval: [6.9 s]
# Iteration 63 fit: [14.6 s]: Recall = 0.2099, Jaccard score = 0.1862, loss = 0.3210, eval: [6.8 s]
# Iteration 64 fit: [13.9 s]: Recall = 0.2116, Jaccard score = 0.1880, loss = 0.3208, eval: [6.8 s]
# Iteration 65 fit: [13.9 s]: Recall = 0.2103, Jaccard score = 0.1867, loss = 0.3195, eval: [6.8 s]
# Iteration 66 fit: [13.9 s]: Recall = 0.2129, Jaccard score = 0.1894, loss = 0.3191, eval: [6.8 s]
# Iteration 67 fit: [13.9 s]: Recall = 0.2102, Jaccard score = 0.1865, loss = 0.3182, eval: [6.9 s]
# Iteration 68 fit: [14.1 s]: Recall = 0.2120, Jaccard score = 0.1885, loss = 0.3172, eval: [6.8 s]
# Iteration 69 fit: [13.9 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3160, eval: [6.8 s]
# Iteration 70 fit: [13.9 s]: Recall = 0.2107, Jaccard score = 0.1871, loss = 0.3157, eval: [6.8 s]
# Iteration 71 fit: [14.3 s]: Recall = 0.2114, Jaccard score = 0.1878, loss = 0.3155, eval: [6.8 s]
# Iteration 72 fit: [14.0 s]: Recall = 0.2094, Jaccard score = 0.1857, loss = 0.3145, eval: [6.8 s]
# Iteration 73 fit: [14.0 s]: Recall = 0.2101, Jaccard score = 0.1864, loss = 0.3140, eval: [6.8 s]
# Iteration 74 fit: [13.9 s]: Recall = 0.2114, Jaccard score = 0.1878, loss = 0.3131, eval: [6.8 s]
# Iteration 75 fit: [13.9 s]: Recall = 0.2074, Jaccard score = 0.1836, loss = 0.3119, eval: [6.8 s]
# Iteration 76 fit: [13.9 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3113, eval: [6.8 s]
# Iteration 77 fit: [13.9 s]: Recall = 0.2114, Jaccard score = 0.1878, loss = 0.3095, eval: [6.8 s]
# Iteration 78 fit: [14.0 s]: Recall = 0.2103, Jaccard score = 0.1866, loss = 0.3099, eval: [6.8 s]
# Iteration 79 fit: [13.9 s]: Recall = 0.2102, Jaccard score = 0.1866, loss = 0.3089, eval: [6.8 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1565602260.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1565602260.h5
# Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 256)          256256      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           dense_feature_layer1[0][0]       
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 512)          0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 768)          0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          98432       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 1,378,817
# Trainable params: 1,378,817
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0290, Jaccard score = 0.0222
# Iteration 0 fit: [14.1 s]: Recall = 0.1383, Jaccard score = 0.1154, loss = 0.4738, eval: [6.8 s]
# Iteration 1 fit: [13.4 s]: Recall = 0.1412, Jaccard score = 0.1181, loss = 0.4430, eval: [6.7 s]
# Iteration 2 fit: [13.0 s]: Recall = 0.1425, Jaccard score = 0.1193, loss = 0.4350, eval: [6.7 s]
# Iteration 3 fit: [13.1 s]: Recall = 0.1506, Jaccard score = 0.1270, loss = 0.4308, eval: [6.7 s]
# Iteration 4 fit: [13.0 s]: Recall = 0.1576, Jaccard score = 0.1336, loss = 0.4263, eval: [6.8 s]
# Iteration 5 fit: [13.1 s]: Recall = 0.1625, Jaccard score = 0.1383, loss = 0.4219, eval: [6.8 s]
# Iteration 6 fit: [13.0 s]: Recall = 0.1683, Jaccard score = 0.1440, loss = 0.4178, eval: [6.8 s]
# Iteration 7 fit: [13.0 s]: Recall = 0.1715, Jaccard score = 0.1472, loss = 0.4128, eval: [6.8 s]
# Iteration 8 fit: [13.0 s]: Recall = 0.1791, Jaccard score = 0.1547, loss = 0.4087, eval: [6.8 s]
# Iteration 9 fit: [13.0 s]: Recall = 0.1808, Jaccard score = 0.1564, loss = 0.4056, eval: [6.8 s]
# Iteration 10 fit: [13.0 s]: Recall = 0.1865, Jaccard score = 0.1621, loss = 0.4025, eval: [6.8 s]
# Iteration 11 fit: [13.1 s]: Recall = 0.1866, Jaccard score = 0.1622, loss = 0.3986, eval: [6.8 s]
# Iteration 12 fit: [13.0 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.3959, eval: [6.7 s]
# Iteration 13 fit: [13.1 s]: Recall = 0.1927, Jaccard score = 0.1683, loss = 0.3932, eval: [6.8 s]
# Iteration 14 fit: [13.0 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3908, eval: [6.8 s]
# Iteration 15 fit: [13.1 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3882, eval: [6.8 s]
# Iteration 16 fit: [13.1 s]: Recall = 0.1940, Jaccard score = 0.1697, loss = 0.3857, eval: [6.7 s]
# Iteration 17 fit: [13.1 s]: Recall = 0.1961, Jaccard score = 0.1719, loss = 0.3841, eval: [6.8 s]
# Iteration 18 fit: [13.1 s]: Recall = 0.2007, Jaccard score = 0.1766, loss = 0.3813, eval: [6.8 s]
# Iteration 19 fit: [13.0 s]: Recall = 0.1984, Jaccard score = 0.1743, loss = 0.3801, eval: [6.8 s]
# Iteration 20 fit: [13.1 s]: Recall = 0.1985, Jaccard score = 0.1743, loss = 0.3777, eval: [6.7 s]
# Iteration 21 fit: [13.1 s]: Recall = 0.2034, Jaccard score = 0.1794, loss = 0.3759, eval: [6.8 s]
# Iteration 22 fit: [13.0 s]: Recall = 0.2015, Jaccard score = 0.1774, loss = 0.3743, eval: [6.8 s]
# Iteration 23 fit: [13.1 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3729, eval: [6.7 s]
# Iteration 24 fit: [13.1 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3712, eval: [6.8 s]
# Iteration 25 fit: [13.1 s]: Recall = 0.2014, Jaccard score = 0.1773, loss = 0.3698, eval: [6.8 s]
# Iteration 26 fit: [13.1 s]: Recall = 0.2037, Jaccard score = 0.1797, loss = 0.3684, eval: [6.8 s]
# Iteration 27 fit: [13.1 s]: Recall = 0.2025, Jaccard score = 0.1785, loss = 0.3672, eval: [6.7 s]
# Iteration 28 fit: [13.1 s]: Recall = 0.2008, Jaccard score = 0.1767, loss = 0.3655, eval: [6.8 s]
# Iteration 29 fit: [13.1 s]: Recall = 0.2041, Jaccard score = 0.1802, loss = 0.3641, eval: [6.8 s]
# Iteration 30 fit: [13.0 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3628, eval: [6.8 s]
# Iteration 31 fit: [13.1 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.3617, eval: [6.7 s]
# Iteration 32 fit: [13.2 s]: Recall = 0.2039, Jaccard score = 0.1800, loss = 0.3613, eval: [6.8 s]
# Iteration 33 fit: [13.1 s]: Recall = 0.2062, Jaccard score = 0.1823, loss = 0.3597, eval: [6.9 s]
# Iteration 34 fit: [13.1 s]: Recall = 0.2066, Jaccard score = 0.1828, loss = 0.3588, eval: [6.9 s]
# Iteration 35 fit: [13.1 s]: Recall = 0.2065, Jaccard score = 0.1826, loss = 0.3570, eval: [6.8 s]
# Iteration 36 fit: [13.1 s]: Recall = 0.2062, Jaccard score = 0.1823, loss = 0.3563, eval: [6.9 s]
# Iteration 37 fit: [13.2 s]: Recall = 0.2067, Jaccard score = 0.1829, loss = 0.3552, eval: [7.0 s]
# Iteration 38 fit: [13.2 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3542, eval: [6.8 s]
# Iteration 39 fit: [13.1 s]: Recall = 0.2064, Jaccard score = 0.1825, loss = 0.3540, eval: [6.7 s]
# Iteration 40 fit: [13.0 s]: Recall = 0.2097, Jaccard score = 0.1860, loss = 0.3520, eval: [6.7 s]
# Iteration 41 fit: [13.5 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3516, eval: [6.8 s]
# Iteration 42 fit: [13.0 s]: Recall = 0.2084, Jaccard score = 0.1846, loss = 0.3510, eval: [6.8 s]
# Iteration 43 fit: [13.1 s]: Recall = 0.2105, Jaccard score = 0.1869, loss = 0.3505, eval: [6.7 s]
# Iteration 44 fit: [13.1 s]: Recall = 0.2073, Jaccard score = 0.1834, loss = 0.3489, eval: [6.8 s]
# Iteration 45 fit: [13.2 s]: Recall = 0.2064, Jaccard score = 0.1825, loss = 0.3482, eval: [6.7 s]
# Iteration 46 fit: [13.1 s]: Recall = 0.2096, Jaccard score = 0.1859, loss = 0.3476, eval: [6.7 s]
# Iteration 47 fit: [13.1 s]: Recall = 0.2077, Jaccard score = 0.1839, loss = 0.3465, eval: [6.9 s]
# Iteration 48 fit: [13.0 s]: Recall = 0.2077, Jaccard score = 0.1839, loss = 0.3456, eval: [6.8 s]
# Iteration 49 fit: [13.1 s]: Recall = 0.2069, Jaccard score = 0.1831, loss = 0.3455, eval: [6.7 s]
# Iteration 50 fit: [13.1 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3435, eval: [6.8 s]
# Iteration 51 fit: [13.1 s]: Recall = 0.2094, Jaccard score = 0.1857, loss = 0.3431, eval: [6.8 s]
# Iteration 52 fit: [13.1 s]: Recall = 0.2106, Jaccard score = 0.1870, loss = 0.3427, eval: [6.8 s]
# Iteration 53 fit: [13.1 s]: Recall = 0.2092, Jaccard score = 0.1855, loss = 0.3429, eval: [6.7 s]
# Iteration 54 fit: [13.0 s]: Recall = 0.2088, Jaccard score = 0.1851, loss = 0.3415, eval: [6.7 s]
# Iteration 55 fit: [13.0 s]: Recall = 0.2094, Jaccard score = 0.1857, loss = 0.3408, eval: [6.8 s]
# Iteration 56 fit: [13.0 s]: Recall = 0.2101, Jaccard score = 0.1864, loss = 0.3400, eval: [6.8 s]
# Iteration 57 fit: [13.1 s]: Recall = 0.2095, Jaccard score = 0.1858, loss = 0.3390, eval: [6.7 s]
# Iteration 58 fit: [13.0 s]: Recall = 0.2099, Jaccard score = 0.1862, loss = 0.3388, eval: [6.8 s]


# Launched by terminal.


# Launched by terminal.


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1565603528.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1565603528.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 256)          256256      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           dense_feature_layer1[0][0]       
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 512)          0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 768)          0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          98432       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 1,378,817
# Trainable params: 1,378,817
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0329, Jaccard score = 0.0252
# Iteration 0 fit: [13.7 s]: Recall = 0.1386, Jaccard score = 0.1156, loss = 0.4725, eval: [6.7 s]
# Iteration 1 fit: [13.5 s]: Recall = 0.1405, Jaccard score = 0.1174, loss = 0.4406, eval: [6.8 s]
# Iteration 2 fit: [14.2 s]: Recall = 0.1442, Jaccard score = 0.1208, loss = 0.4328, eval: [6.7 s]
# Iteration 3 fit: [13.5 s]: Recall = 0.1543, Jaccard score = 0.1304, loss = 0.4281, eval: [6.8 s]
# Iteration 4 fit: [13.6 s]: Recall = 0.1650, Jaccard score = 0.1408, loss = 0.4238, eval: [6.7 s]
# Iteration 5 fit: [13.5 s]: Recall = 0.1715, Jaccard score = 0.1472, loss = 0.4183, eval: [6.9 s]
# Iteration 6 fit: [13.4 s]: Recall = 0.1769, Jaccard score = 0.1524, loss = 0.4132, eval: [6.7 s]
# Iteration 7 fit: [13.4 s]: Recall = 0.1793, Jaccard score = 0.1548, loss = 0.4092, eval: [6.8 s]
# Iteration 8 fit: [13.4 s]: Recall = 0.1850, Jaccard score = 0.1605, loss = 0.4045, eval: [6.7 s]
# Iteration 9 fit: [13.5 s]: Recall = 0.1855, Jaccard score = 0.1610, loss = 0.4015, eval: [6.8 s]
# Iteration 10 fit: [13.4 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3985, eval: [6.7 s]
# Iteration 11 fit: [13.5 s]: Recall = 0.1904, Jaccard score = 0.1660, loss = 0.3951, eval: [6.7 s]
# Iteration 12 fit: [13.5 s]: Recall = 0.1929, Jaccard score = 0.1686, loss = 0.3929, eval: [6.7 s]
# Iteration 13 fit: [13.4 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3901, eval: [6.8 s]
# Iteration 14 fit: [13.5 s]: Recall = 0.1952, Jaccard score = 0.1709, loss = 0.3874, eval: [6.7 s]
# Iteration 15 fit: [13.4 s]: Recall = 0.1960, Jaccard score = 0.1718, loss = 0.3852, eval: [6.9 s]
# Iteration 16 fit: [13.4 s]: Recall = 0.1977, Jaccard score = 0.1735, loss = 0.3829, eval: [6.7 s]
# Iteration 17 fit: [13.4 s]: Recall = 0.1982, Jaccard score = 0.1740, loss = 0.3808, eval: [6.8 s]
# Iteration 18 fit: [13.4 s]: Recall = 0.1998, Jaccard score = 0.1757, loss = 0.3787, eval: [6.7 s]
# Iteration 19 fit: [13.5 s]: Recall = 0.2016, Jaccard score = 0.1776, loss = 0.3768, eval: [6.9 s]
# Iteration 20 fit: [13.4 s]: Recall = 0.2003, Jaccard score = 0.1762, loss = 0.3759, eval: [6.8 s]
# Iteration 21 fit: [13.4 s]: Recall = 0.2000, Jaccard score = 0.1758, loss = 0.3745, eval: [6.7 s]
# Iteration 22 fit: [13.5 s]: Recall = 0.2034, Jaccard score = 0.1795, loss = 0.3721, eval: [6.8 s]
# Iteration 23 fit: [13.5 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3704, eval: [6.7 s]
# Iteration 24 fit: [13.5 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3694, eval: [6.8 s]
# Iteration 25 fit: [13.5 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3678, eval: [6.7 s]
# Iteration 26 fit: [13.5 s]: Recall = 0.2050, Jaccard score = 0.1810, loss = 0.3664, eval: [6.8 s]
# Iteration 27 fit: [14.1 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3648, eval: [6.8 s]
# Iteration 28 fit: [13.8 s]: Recall = 0.2046, Jaccard score = 0.1806, loss = 0.3639, eval: [6.8 s]
# Iteration 29 fit: [13.5 s]: Recall = 0.2050, Jaccard score = 0.1811, loss = 0.3626, eval: [6.7 s]
# Iteration 30 fit: [13.6 s]: Recall = 0.2034, Jaccard score = 0.1794, loss = 0.3618, eval: [6.8 s]
# Iteration 31 fit: [13.6 s]: Recall = 0.2041, Jaccard score = 0.1802, loss = 0.3609, eval: [6.8 s]
# Iteration 32 fit: [13.4 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3597, eval: [6.8 s]
# Iteration 33 fit: [13.5 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3580, eval: [6.8 s]
# Iteration 34 fit: [13.4 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3570, eval: [6.7 s]
# Iteration 35 fit: [14.0 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3558, eval: [6.9 s]
# Iteration 36 fit: [13.4 s]: Recall = 0.2069, Jaccard score = 0.1831, loss = 0.3549, eval: [6.7 s]
# Iteration 37 fit: [13.5 s]: Recall = 0.2080, Jaccard score = 0.1842, loss = 0.3543, eval: [6.8 s]
# Iteration 38 fit: [13.4 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3535, eval: [6.7 s]
# Iteration 39 fit: [13.5 s]: Recall = 0.2060, Jaccard score = 0.1821, loss = 0.3521, eval: [6.8 s]
# Iteration 40 fit: [13.4 s]: Recall = 0.2083, Jaccard score = 0.1845, loss = 0.3510, eval: [6.7 s]
# Iteration 41 fit: [13.4 s]: Recall = 0.2083, Jaccard score = 0.1846, loss = 0.3510, eval: [6.9 s]
# Iteration 42 fit: [13.5 s]: Recall = 0.2097, Jaccard score = 0.1860, loss = 0.3499, eval: [6.7 s]
# Iteration 43 fit: [13.7 s]: Recall = 0.2100, Jaccard score = 0.1863, loss = 0.3496, eval: [6.8 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1565604441.h5
--weights_path: Pretrain/_MLP_8_[512,128]_1565604441.h5
# Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 256)          256256      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# dropout_1 (Dropout)             (None, 256)          0           dense_feature_layer1[0][0]       
# __________________________________________________________________________________________________
# dropout_2 (Dropout)             (None, 256)          0           flatten_2[0][0]                  
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 512)          0           dropout_1[0][0]                  
#                                                                  dropout_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          65664       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 834,049
# Trainable params: 834,049
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0307, Jaccard score = 0.0235
# Iteration 0 fit: [12.5 s]: Recall = 0.1412, Jaccard score = 0.1181, loss = 0.4825, eval: [6.8 s]
# Iteration 1 fit: [12.1 s]: Recall = 0.1450, Jaccard score = 0.1216, loss = 0.4492, eval: [6.9 s]
# Iteration 2 fit: [12.1 s]: Recall = 0.1487, Jaccard score = 0.1251, loss = 0.4377, eval: [6.8 s]
# Iteration 3 fit: [12.1 s]: Recall = 0.1543, Jaccard score = 0.1304, loss = 0.4324, eval: [6.8 s]
# Iteration 4 fit: [12.4 s]: Recall = 0.1596, Jaccard score = 0.1356, loss = 0.4285, eval: [6.8 s]
# Iteration 5 fit: [12.4 s]: Recall = 0.1644, Jaccard score = 0.1402, loss = 0.4250, eval: [6.8 s]
# Iteration 6 fit: [12.3 s]: Recall = 0.1652, Jaccard score = 0.1409, loss = 0.4213, eval: [6.8 s]
# Iteration 7 fit: [12.1 s]: Recall = 0.1725, Jaccard score = 0.1482, loss = 0.4182, eval: [6.9 s]
# Iteration 8 fit: [12.6 s]: Recall = 0.1778, Jaccard score = 0.1534, loss = 0.4155, eval: [6.8 s]
# Iteration 9 fit: [12.5 s]: Recall = 0.1777, Jaccard score = 0.1532, loss = 0.4125, eval: [6.9 s]
# Iteration 10 fit: [12.4 s]: Recall = 0.1822, Jaccard score = 0.1578, loss = 0.4106, eval: [6.8 s]
# Iteration 11 fit: [12.3 s]: Recall = 0.1816, Jaccard score = 0.1571, loss = 0.4074, eval: [6.9 s]
# Iteration 12 fit: [12.5 s]: Recall = 0.1847, Jaccard score = 0.1603, loss = 0.4052, eval: [6.8 s]
# Iteration 13 fit: [12.3 s]: Recall = 0.1905, Jaccard score = 0.1661, loss = 0.4035, eval: [6.9 s]
# Iteration 14 fit: [12.5 s]: Recall = 0.1862, Jaccard score = 0.1618, loss = 0.4007, eval: [6.8 s]
# Iteration 15 fit: [12.3 s]: Recall = 0.1902, Jaccard score = 0.1659, loss = 0.3985, eval: [6.9 s]
# Iteration 16 fit: [12.5 s]: Recall = 0.1905, Jaccard score = 0.1661, loss = 0.3965, eval: [6.8 s]
# Iteration 17 fit: [12.3 s]: Recall = 0.1926, Jaccard score = 0.1683, loss = 0.3947, eval: [6.9 s]
# Iteration 18 fit: [12.5 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3926, eval: [6.8 s]
# Iteration 19 fit: [12.3 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3906, eval: [6.8 s]
# Iteration 20 fit: [12.5 s]: Recall = 0.1924, Jaccard score = 0.1681, loss = 0.3891, eval: [6.8 s]
# Iteration 21 fit: [12.5 s]: Recall = 0.1946, Jaccard score = 0.1703, loss = 0.3873, eval: [6.8 s]
# Iteration 22 fit: [12.3 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3858, eval: [6.8 s]
# Iteration 23 fit: [12.2 s]: Recall = 0.1982, Jaccard score = 0.1740, loss = 0.3841, eval: [6.9 s]
# Iteration 24 fit: [12.5 s]: Recall = 0.1975, Jaccard score = 0.1733, loss = 0.3825, eval: [6.8 s]
# Iteration 25 fit: [12.3 s]: Recall = 0.2008, Jaccard score = 0.1767, loss = 0.3818, eval: [6.8 s]
# Iteration 26 fit: [12.4 s]: Recall = 0.2005, Jaccard score = 0.1764, loss = 0.3799, eval: [6.8 s]
# Iteration 27 fit: [12.2 s]: Recall = 0.1996, Jaccard score = 0.1755, loss = 0.3788, eval: [6.8 s]
# Iteration 28 fit: [12.5 s]: Recall = 0.2001, Jaccard score = 0.1760, loss = 0.3776, eval: [6.8 s]
# Iteration 29 fit: [12.3 s]: Recall = 0.1984, Jaccard score = 0.1743, loss = 0.3759, eval: [6.9 s]
# Iteration 30 fit: [12.3 s]: Recall = 0.2015, Jaccard score = 0.1774, loss = 0.3753, eval: [6.8 s]
# Iteration 31 fit: [12.5 s]: Recall = 0.2026, Jaccard score = 0.1786, loss = 0.3735, eval: [6.8 s]
# Iteration 32 fit: [12.4 s]: Recall = 0.2001, Jaccard score = 0.1760, loss = 0.3728, eval: [6.9 s]
# Iteration 33 fit: [12.2 s]: Recall = 0.2002, Jaccard score = 0.1761, loss = 0.3717, eval: [6.8 s]
# Iteration 34 fit: [12.4 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3700, eval: [6.8 s]
# Iteration 35 fit: [12.5 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3687, eval: [6.8 s]
# Iteration 36 fit: [12.5 s]: Recall = 0.2037, Jaccard score = 0.1797, loss = 0.3684, eval: [6.8 s]
# Iteration 37 fit: [12.2 s]: Recall = 0.2014, Jaccard score = 0.1773, loss = 0.3668, eval: [6.8 s]
# Iteration 38 fit: [12.3 s]: Recall = 0.2035, Jaccard score = 0.1795, loss = 0.3664, eval: [6.8 s]
# Iteration 39 fit: [12.4 s]: Recall = 0.2029, Jaccard score = 0.1789, loss = 0.3648, eval: [6.8 s]
# Iteration 40 fit: [12.1 s]: Recall = 0.2035, Jaccard score = 0.1795, loss = 0.3641, eval: [6.7 s]
# Iteration 41 fit: [12.4 s]: Recall = 0.2028, Jaccard score = 0.1788, loss = 0.3633, eval: [6.9 s]
# Iteration 42 fit: [12.1 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.3610, eval: [6.8 s]
# Iteration 43 fit: [12.5 s]: Recall = 0.2023, Jaccard score = 0.1783, loss = 0.3608, eval: [6.8 s]
# Iteration 44 fit: [12.5 s]: Recall = 0.2018, Jaccard score = 0.1777, loss = 0.3599, eval: [6.8 s]
# Iteration 45 fit: [12.5 s]: Recall = 0.2047, Jaccard score = 0.1808, loss = 0.3593, eval: [6.8 s]
# Iteration 46 fit: [12.5 s]: Recall = 0.2066, Jaccard score = 0.1827, loss = 0.3586, eval: [6.8 s]
# Iteration 47 fit: [12.4 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3572, eval: [6.9 s]
# Iteration 48 fit: [12.4 s]: Recall = 0.2073, Jaccard score = 0.1835, loss = 0.3570, eval: [6.8 s]
# Iteration 49 fit: [12.5 s]: Recall = 0.2063, Jaccard score = 0.1824, loss = 0.3553, eval: [6.8 s]
# Iteration 50 fit: [12.4 s]: Recall = 0.2049, Jaccard score = 0.1810, loss = 0.3552, eval: [6.8 s]
# Iteration 51 fit: [12.4 s]: Recall = 0.2062, Jaccard score = 0.1823, loss = 0.3540, eval: [6.8 s]
# Iteration 52 fit: [12.3 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3534, eval: [6.8 s]
# Iteration 53 fit: [12.4 s]: Recall = 0.2044, Jaccard score = 0.1804, loss = 0.3528, eval: [6.8 s]
# Iteration 54 fit: [12.6 s]: Recall = 0.2070, Jaccard score = 0.1831, loss = 0.3511, eval: [6.9 s]
# Iteration 55 fit: [12.5 s]: Recall = 0.2062, Jaccard score = 0.1824, loss = 0.3507, eval: [6.8 s]
# Iteration 56 fit: [12.2 s]: Recall = 0.2049, Jaccard score = 0.1810, loss = 0.3503, eval: [6.9 s]
# Iteration 57 fit: [12.5 s]: Recall = 0.2067, Jaccard score = 0.1829, loss = 0.3495, eval: [6.8 s]
# Iteration 58 fit: [12.1 s]: Recall = 0.2080, Jaccard score = 0.1842, loss = 0.3486, eval: [6.8 s]
# Iteration 59 fit: [12.2 s]: Recall = 0.2052, Jaccard score = 0.1813, loss = 0.3483, eval: [6.8 s]
# Iteration 60 fit: [12.5 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3469, eval: [7.0 s]
# Iteration 61 fit: [12.5 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3464, eval: [6.8 s]
# Iteration 62 fit: [12.3 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3460, eval: [6.8 s]
# Iteration 63 fit: [12.2 s]: Recall = 0.2080, Jaccard score = 0.1843, loss = 0.3450, eval: [6.9 s]
# Iteration 64 fit: [12.3 s]: Recall = 0.2094, Jaccard score = 0.1857, loss = 0.3440, eval: [6.8 s]
# Iteration 65 fit: [12.5 s]: Recall = 0.2066, Jaccard score = 0.1828, loss = 0.3441, eval: [6.8 s]
# Iteration 66 fit: [12.4 s]: Recall = 0.2095, Jaccard score = 0.1858, loss = 0.3431, eval: [6.8 s]
# Iteration 67 fit: [12.1 s]: Recall = 0.2066, Jaccard score = 0.1827, loss = 0.3419, eval: [6.9 s]
# Iteration 68 fit: [12.5 s]: Recall = 0.2078, Jaccard score = 0.1840, loss = 0.3417, eval: [6.9 s]
# Iteration 69 fit: [12.2 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3416, eval: [6.8 s]
# Iteration 70 fit: [12.4 s]: Recall = 0.2073, Jaccard score = 0.1835, loss = 0.3406, eval: [6.8 s]
# Iteration 71 fit: [12.5 s]: Recall = 0.2078, Jaccard score = 0.1840, loss = 0.3397, eval: [6.8 s]
# Iteration 72 fit: [12.2 s]: Recall = 0.2089, Jaccard score = 0.1852, loss = 0.3394, eval: [6.8 s]
# Iteration 73 fit: [12.4 s]: Recall = 0.2091, Jaccard score = 0.1854, loss = 0.3386, eval: [6.8 s]
# Iteration 74 fit: [12.4 s]: Recall = 0.2089, Jaccard score = 0.1852, loss = 0.3384, eval: [6.8 s]
# Iteration 75 fit: [12.5 s]: Recall = 0.2081, Jaccard score = 0.1843, loss = 0.3373, eval: [6.8 s]
# Iteration 76 fit: [12.5 s]: Recall = 0.2096, Jaccard score = 0.1859, loss = 0.3369, eval: [6.9 s]
# Iteration 77 fit: [12.4 s]: Recall = 0.2068, Jaccard score = 0.1830, loss = 0.3363, eval: [6.8 s]
# Iteration 78 fit: [12.4 s]: Recall = 0.2074, Jaccard score = 0.1836, loss = 0.3351, eval: [6.8 s]
# Iteration 79 fit: [12.2 s]: Recall = 0.2076, Jaccard score = 0.1838, loss = 0.3348, eval: [6.9 s]
# Iteration 80 fit: [12.5 s]: Recall = 0.2102, Jaccard score = 0.1865, loss = 0.3344, eval: [6.8 s]
# Iteration 81 fit: [12.5 s]: Recall = 0.2106, Jaccard score = 0.1870, loss = 0.3339, eval: [6.9 s]
# Iteration 82 fit: [12.4 s]: Recall = 0.2067, Jaccard score = 0.1829, loss = 0.3336, eval: [6.9 s]
# Iteration 83 fit: [12.3 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3326, eval: [6.8 s]
# Iteration 84 fit: [12.5 s]: Recall = 0.2093, Jaccard score = 0.1856, loss = 0.3326, eval: [6.7 s]
# Iteration 85 fit: [12.5 s]: Recall = 0.2079, Jaccard score = 0.1841, loss = 0.3322, eval: [6.8 s]
# Iteration 86 fit: [12.4 s]: Recall = 0.2085, Jaccard score = 0.1847, loss = 0.3307, eval: [6.9 s]
# Iteration 87 fit: [12.5 s]: Recall = 0.2070, Jaccard score = 0.1831, loss = 0.3316, eval: [6.8 s]
# Iteration 88 fit: [12.3 s]: Recall = 0.2083, Jaccard score = 0.1846, loss = 0.3304, eval: [6.9 s]
# Iteration 89 fit: [12.4 s]: Recall = 0.2068, Jaccard score = 0.1830, loss = 0.3299, eval: [6.8 s]
# Iteration 90 fit: [12.5 s]: Recall = 0.2068, Jaccard score = 0.1829, loss = 0.3285, eval: [6.8 s]
# Iteration 91 fit: [12.4 s]: Recall = 0.2093, Jaccard score = 0.1856, loss = 0.3283, eval: [6.8 s]
# Iteration 92 fit: [12.2 s]: Recall = 0.2068, Jaccard score = 0.1830, loss = 0.3283, eval: [6.9 s]
# Iteration 93 fit: [12.5 s]: Recall = 0.2081, Jaccard score = 0.1843, loss = 0.3274, eval: [6.9 s]
# Iteration 94 fit: [12.5 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3271, eval: [6.9 s]
# Iteration 95 fit: [12.5 s]: Recall = 0.2086, Jaccard score = 0.1849, loss = 0.3262, eval: [6.8 s]
# Iteration 96 fit: [12.1 s]: Recall = 0.2084, Jaccard score = 0.1847, loss = 0.3255, eval: [6.9 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1565607938.h5
--weights_path: Pretrain/_MLP_8_[512,128]_1565607938.h5
# Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 256)          256256      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 512)          0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          65664       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 834,049
# Trainable params: 834,049
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0230, Jaccard score = 0.0175
# Iteration 0 fit: [12.0 s]: Recall = 0.1434, Jaccard score = 0.1201, loss = 0.4496, eval: [6.6 s]
# Iteration 1 fit: [11.7 s]: Recall = 0.1604, Jaccard score = 0.1363, loss = 0.4158, eval: [6.8 s]
# Iteration 2 fit: [11.7 s]: Recall = 0.1747, Jaccard score = 0.1503, loss = 0.4036, eval: [6.8 s]
# Iteration 3 fit: [11.7 s]: Recall = 0.1835, Jaccard score = 0.1591, loss = 0.3926, eval: [6.7 s]
# Iteration 4 fit: [11.7 s]: Recall = 0.1883, Jaccard score = 0.1639, loss = 0.3840, eval: [6.8 s]
# Iteration 5 fit: [11.7 s]: Recall = 0.1928, Jaccard score = 0.1685, loss = 0.3765, eval: [6.8 s]
# Iteration 6 fit: [11.7 s]: Recall = 0.1946, Jaccard score = 0.1703, loss = 0.3694, eval: [6.8 s]
# Iteration 7 fit: [11.7 s]: Recall = 0.1971, Jaccard score = 0.1729, loss = 0.3631, eval: [6.7 s]
# Iteration 8 fit: [11.7 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3577, eval: [6.8 s]
# Iteration 9 fit: [11.7 s]: Recall = 0.2012, Jaccard score = 0.1771, loss = 0.3524, eval: [6.8 s]
# Iteration 10 fit: [11.7 s]: Recall = 0.2004, Jaccard score = 0.1763, loss = 0.3479, eval: [6.8 s]
# Iteration 11 fit: [11.7 s]: Recall = 0.2030, Jaccard score = 0.1790, loss = 0.3438, eval: [6.8 s]
# Iteration 12 fit: [11.7 s]: Recall = 0.2023, Jaccard score = 0.1782, loss = 0.3390, eval: [6.7 s]
# Iteration 13 fit: [11.7 s]: Recall = 0.2027, Jaccard score = 0.1787, loss = 0.3356, eval: [6.8 s]
# Iteration 14 fit: [11.7 s]: Recall = 0.2034, Jaccard score = 0.1795, loss = 0.3317, eval: [6.8 s]
# Iteration 15 fit: [11.7 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3285, eval: [6.7 s]
# Iteration 16 fit: [11.7 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3251, eval: [6.7 s]
# Iteration 17 fit: [11.7 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3222, eval: [6.7 s]
# Iteration 18 fit: [11.7 s]: Recall = 0.2047, Jaccard score = 0.1808, loss = 0.3182, eval: [6.8 s]
# Iteration 19 fit: [11.7 s]: Recall = 0.2054, Jaccard score = 0.1815, loss = 0.3160, eval: [6.6 s]
# Iteration 20 fit: [11.7 s]: Recall = 0.2064, Jaccard score = 0.1825, loss = 0.3125, eval: [6.8 s]
# Iteration 21 fit: [11.9 s]: Recall = 0.2069, Jaccard score = 0.1831, loss = 0.3099, eval: [6.8 s]
# Iteration 22 fit: [12.0 s]: Recall = 0.2064, Jaccard score = 0.1826, loss = 0.3077, eval: [6.7 s]
# Iteration 23 fit: [12.1 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.3045, eval: [6.7 s]
# Iteration 24 fit: [11.7 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.3012, eval: [6.7 s]
# Iteration 25 fit: [11.7 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.2995, eval: [6.8 s]
# Iteration 26 fit: [12.0 s]: Recall = 0.2060, Jaccard score = 0.1821, loss = 0.2966, eval: [6.9 s]
# Iteration 27 fit: [11.7 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.2937, eval: [6.6 s]
# Iteration 28 fit: [11.7 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.2913, eval: [6.7 s]
# Iteration 29 fit: [11.7 s]: Recall = 0.2049, Jaccard score = 0.1810, loss = 0.2891, eval: [6.7 s]
# Iteration 30 fit: [12.2 s]: Recall = 0.2046, Jaccard score = 0.1806, loss = 0.2865, eval: [6.7 s]
# Iteration 31 fit: [11.8 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.2837, eval: [6.8 s]
# Iteration 32 fit: [11.7 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.2816, eval: [6.7 s]
# Iteration 33 fit: [11.8 s]: Recall = 0.2052, Jaccard score = 0.1813, loss = 0.2787, eval: [6.8 s]
# Iteration 34 fit: [11.7 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.2766, eval: [6.6 s]
# Iteration 35 fit: [11.7 s]: Recall = 0.2030, Jaccard score = 0.1790, loss = 0.2744, eval: [6.7 s]
# Iteration 36 fit: [11.7 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.2728, eval: [6.9 s]
# Iteration 37 fit: [12.2 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.2709, eval: [6.7 s]
# Iteration 38 fit: [11.7 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.2686, eval: [6.8 s]
# Iteration 39 fit: [12.1 s]: Recall = 0.2020, Jaccard score = 0.1780, loss = 0.2661, eval: [6.7 s]
# Iteration 40 fit: [11.7 s]: Recall = 0.2012, Jaccard score = 0.1771, loss = 0.2636, eval: [6.7 s]
# Iteration 41 fit: [11.8 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.2618, eval: [6.9 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1565608751.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1565608751.h5
# Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1536)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          196736      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 2,245,889
# Trainable params: 2,245,889
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0258, Jaccard score = 0.0197
# Iteration 0 fit: [15.6 s]: Recall = 0.1561, Jaccard score = 0.1322, loss = 0.4350, eval: [7.0 s]
# Iteration 1 fit: [15.2 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.4034, eval: [7.1 s]
# Iteration 2 fit: [15.2 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3848, eval: [7.1 s]
# Iteration 3 fit: [15.6 s]: Recall = 0.1985, Jaccard score = 0.1743, loss = 0.3712, eval: [7.0 s]
# Iteration 4 fit: [15.2 s]: Recall = 0.2020, Jaccard score = 0.1779, loss = 0.3598, eval: [7.1 s]
# Iteration 5 fit: [15.2 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3509, eval: [7.1 s]
# Iteration 6 fit: [15.2 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3425, eval: [7.0 s]
# Iteration 7 fit: [15.2 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.3352, eval: [7.0 s]
# Iteration 8 fit: [15.2 s]: Recall = 0.2052, Jaccard score = 0.1813, loss = 0.3282, eval: [7.0 s]
# Iteration 9 fit: [15.2 s]: Recall = 0.2052, Jaccard score = 0.1813, loss = 0.3220, eval: [7.0 s]
# Iteration 10 fit: [15.1 s]: Recall = 0.2076, Jaccard score = 0.1838, loss = 0.3154, eval: [7.0 s]
# Iteration 11 fit: [15.2 s]: Recall = 0.2074, Jaccard score = 0.1836, loss = 0.3093, eval: [7.0 s]
# Iteration 12 fit: [15.2 s]: Recall = 0.2084, Jaccard score = 0.1846, loss = 0.3035, eval: [7.1 s]
# Iteration 13 fit: [15.2 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.2980, eval: [7.0 s]
# Iteration 14 fit: [15.6 s]: Recall = 0.2064, Jaccard score = 0.1825, loss = 0.2925, eval: [7.0 s]
# Iteration 15 fit: [15.2 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.2871, eval: [7.1 s]
# Iteration 16 fit: [15.2 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.2813, eval: [6.9 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,64]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[128,64]_1565609160.h5
--weights_path: Pretrain/_MLP_8_[128,64]_1565609160.h5
# Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1088)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 64)           69696       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 64)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            65          activation_1[0][0]               
# ==================================================================================================
# Total params: 1,222,785
# Trainable params: 1,222,785
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0380, Jaccard score = 0.0293
# Iteration 0 fit: [13.7 s]: Recall = 0.1376, Jaccard score = 0.1148, loss = 0.4845, eval: [8.6 s]
# Iteration 1 fit: [13.7 s]: Recall = 0.1500, Jaccard score = 0.1264, loss = 0.4423, eval: [6.9 s]
# Iteration 2 fit: [12.9 s]: Recall = 0.1572, Jaccard score = 0.1332, loss = 0.4224, eval: [7.0 s]
# Iteration 3 fit: [12.9 s]: Recall = 0.1661, Jaccard score = 0.1419, loss = 0.4115, eval: [7.1 s]
# Iteration 4 fit: [12.9 s]: Recall = 0.1702, Jaccard score = 0.1458, loss = 0.4035, eval: [7.0 s]
# Iteration 5 fit: [12.9 s]: Recall = 0.1743, Jaccard score = 0.1499, loss = 0.3970, eval: [7.1 s]
# Iteration 6 fit: [12.9 s]: Recall = 0.1764, Jaccard score = 0.1520, loss = 0.3909, eval: [7.0 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,64]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[128,64]_1565609334.h5
--weights_path: Pretrain/_MLP_8_[128,64]_1565609334.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 64)           64064       user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 128)          0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 64)           8256        concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 64)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            65          activation_1[0][0]               
# ==================================================================================================
# Total params: 200,385
# Trainable params: 200,385
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0272, Jaccard score = 0.0208
# Iteration 0 fit: [10.9 s]: Recall = 0.1341, Jaccard score = 0.1114, loss = 0.4931, eval: [6.6 s]
# Iteration 1 fit: [10.6 s]: Recall = 0.1433, Jaccard score = 0.1201, loss = 0.4443, eval: [6.7 s]
# Iteration 2 fit: [10.6 s]: Recall = 0.1510, Jaccard score = 0.1273, loss = 0.4258, eval: [6.8 s]
# Iteration 3 fit: [11.0 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.4169, eval: [6.7 s]
# Iteration 4 fit: [10.5 s]: Recall = 0.1646, Jaccard score = 0.1403, loss = 0.4112, eval: [6.7 s]
# Iteration 5 fit: [10.6 s]: Recall = 0.1650, Jaccard score = 0.1408, loss = 0.4064, eval: [6.8 s]
# Iteration 6 fit: [10.6 s]: Recall = 0.1669, Jaccard score = 0.1426, loss = 0.4023, eval: [6.8 s]
# Iteration 7 fit: [10.6 s]: Recall = 0.1727, Jaccard score = 0.1483, loss = 0.3987, eval: [6.8 s]
# Iteration 8 fit: [10.6 s]: Recall = 0.1756, Jaccard score = 0.1512, loss = 0.3955, eval: [6.8 s]
# Iteration 9 fit: [10.6 s]: Recall = 0.1778, Jaccard score = 0.1534, loss = 0.3922, eval: [6.8 s]
# Iteration 10 fit: [10.6 s]: Recall = 0.1810, Jaccard score = 0.1566, loss = 0.3891, eval: [6.8 s]
# Iteration 11 fit: [10.6 s]: Recall = 0.1821, Jaccard score = 0.1577, loss = 0.3860, eval: [6.7 s]
# Iteration 12 fit: [10.6 s]: Recall = 0.1878, Jaccard score = 0.1634, loss = 0.3835, eval: [6.7 s]
# Iteration 13 fit: [10.6 s]: Recall = 0.1835, Jaccard score = 0.1591, loss = 0.3807, eval: [6.8 s]
# Iteration 14 fit: [10.5 s]: Recall = 0.1869, Jaccard score = 0.1625, loss = 0.3785, eval: [6.8 s]
# Iteration 15 fit: [10.5 s]: Recall = 0.1873, Jaccard score = 0.1629, loss = 0.3759, eval: [6.8 s]
# Iteration 16 fit: [10.6 s]: Recall = 0.1890, Jaccard score = 0.1646, loss = 0.3737, eval: [6.7 s]
# Iteration 17 fit: [10.6 s]: Recall = 0.1878, Jaccard score = 0.1634, loss = 0.3711, eval: [6.8 s]
# Iteration 18 fit: [10.5 s]: Recall = 0.1897, Jaccard score = 0.1654, loss = 0.3691, eval: [6.9 s]
# Iteration 19 fit: [10.5 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.3678, eval: [6.7 s]
# Iteration 20 fit: [10.6 s]: Recall = 0.1914, Jaccard score = 0.1670, loss = 0.3651, eval: [6.8 s]
# Iteration 21 fit: [10.6 s]: Recall = 0.1923, Jaccard score = 0.1680, loss = 0.3632, eval: [6.8 s]
# Iteration 22 fit: [10.5 s]: Recall = 0.1918, Jaccard score = 0.1674, loss = 0.3616, eval: [6.8 s]
# Iteration 23 fit: [10.6 s]: Recall = 0.1934, Jaccard score = 0.1691, loss = 0.3595, eval: [6.8 s]
# Iteration 24 fit: [10.6 s]: Recall = 0.1944, Jaccard score = 0.1702, loss = 0.3580, eval: [6.8 s]
# Iteration 25 fit: [10.6 s]: Recall = 0.1939, Jaccard score = 0.1697, loss = 0.3560, eval: [6.8 s]
# Iteration 26 fit: [10.6 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3544, eval: [6.8 s]
# Iteration 27 fit: [10.6 s]: Recall = 0.1947, Jaccard score = 0.1705, loss = 0.3530, eval: [6.8 s]
# Iteration 28 fit: [10.6 s]: Recall = 0.1940, Jaccard score = 0.1697, loss = 0.3516, eval: [6.8 s]
# Iteration 29 fit: [10.6 s]: Recall = 0.1950, Jaccard score = 0.1707, loss = 0.3502, eval: [6.8 s]
# Iteration 30 fit: [10.5 s]: Recall = 0.1926, Jaccard score = 0.1683, loss = 0.3484, eval: [6.8 s]
# Iteration 31 fit: [10.6 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3466, eval: [6.8 s]
# Iteration 32 fit: [10.5 s]: Recall = 0.1952, Jaccard score = 0.1710, loss = 0.3454, eval: [6.6 s]
# Iteration 33 fit: [10.6 s]: Recall = 0.1935, Jaccard score = 0.1692, loss = 0.3448, eval: [6.7 s]
# Iteration 34 fit: [10.6 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3430, eval: [6.7 s]
# Iteration 35 fit: [10.6 s]: Recall = 0.1939, Jaccard score = 0.1696, loss = 0.3415, eval: [6.8 s]
# Iteration 36 fit: [10.6 s]: Recall = 0.1960, Jaccard score = 0.1718, loss = 0.3407, eval: [6.7 s]
# Iteration 37 fit: [10.6 s]: Recall = 0.1976, Jaccard score = 0.1734, loss = 0.3398, eval: [6.6 s]
# Iteration 38 fit: [10.6 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3385, eval: [6.8 s]
# Iteration 39 fit: [10.6 s]: Recall = 0.1960, Jaccard score = 0.1717, loss = 0.3371, eval: [6.7 s]
# Iteration 40 fit: [10.6 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3359, eval: [6.8 s]
# Iteration 41 fit: [10.6 s]: Recall = 0.1953, Jaccard score = 0.1710, loss = 0.3352, eval: [6.8 s]
# Iteration 42 fit: [10.6 s]: Recall = 0.1957, Jaccard score = 0.1715, loss = 0.3337, eval: [6.6 s]
# Iteration 43 fit: [10.6 s]: Recall = 0.1954, Jaccard score = 0.1712, loss = 0.3326, eval: [6.9 s]
# Iteration 44 fit: [10.6 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3321, eval: [6.7 s]
# Iteration 45 fit: [10.6 s]: Recall = 0.1980, Jaccard score = 0.1739, loss = 0.3310, eval: [6.8 s]
# Iteration 46 fit: [10.6 s]: Recall = 0.1946, Jaccard score = 0.1703, loss = 0.3297, eval: [6.8 s]
# Iteration 47 fit: [10.6 s]: Recall = 0.1976, Jaccard score = 0.1734, loss = 0.3289, eval: [6.8 s]
# Iteration 48 fit: [10.6 s]: Recall = 0.1984, Jaccard score = 0.1742, loss = 0.3281, eval: [6.8 s]
# Iteration 49 fit: [10.6 s]: Recall = 0.1960, Jaccard score = 0.1718, loss = 0.3272, eval: [6.8 s]
# Iteration 50 fit: [10.5 s]: Recall = 0.1957, Jaccard score = 0.1715, loss = 0.3262, eval: [6.8 s]
# Iteration 51 fit: [10.6 s]: Recall = 0.1935, Jaccard score = 0.1692, loss = 0.3257, eval: [6.8 s]
# Iteration 52 fit: [10.6 s]: Recall = 0.1929, Jaccard score = 0.1686, loss = 0.3244, eval: [6.7 s]
# Iteration 53 fit: [11.0 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3237, eval: [6.8 s]
# Iteration 54 fit: [10.6 s]: Recall = 0.1952, Jaccard score = 0.1710, loss = 0.3230, eval: [6.8 s]
# Iteration 55 fit: [10.6 s]: Recall = 0.1957, Jaccard score = 0.1714, loss = 0.3223, eval: [6.7 s]
# Iteration 56 fit: [10.6 s]: Recall = 0.1948, Jaccard score = 0.1705, loss = 0.3212, eval: [6.7 s]
# Iteration 57 fit: [10.7 s]: Recall = 0.1968, Jaccard score = 0.1726, loss = 0.3209, eval: [6.8 s]
# Iteration 58 fit: [10.6 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3190, eval: [6.8 s]
# Iteration 59 fit: [10.6 s]: Recall = 0.1928, Jaccard score = 0.1685, loss = 0.3196, eval: [6.8 s]
# Iteration 60 fit: [10.9 s]: Recall = 0.1955, Jaccard score = 0.1712, loss = 0.3182, eval: [6.8 s]
# Iteration 61 fit: [10.8 s]: Recall = 0.1951, Jaccard score = 0.1708, loss = 0.3173, eval: [6.9 s]
# Iteration 62 fit: [10.7 s]: Recall = 0.1977, Jaccard score = 0.1735, loss = 0.3172, eval: [6.9 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,64]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[128,64]_1565610447.h5
--weights_path: Pretrain/_MLP_8_[128,64]_1565610447.h5
# Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 128)          128128      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 192)          0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 64)           12352       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 64)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            65          activation_1[0][0]               
# ==================================================================================================
# Total params: 268,545
# Trainable params: 268,545
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0209, Jaccard score = 0.0159
# Iteration 0 fit: [11.4 s]: Recall = 0.1321, Jaccard score = 0.1096, loss = 0.4918, eval: [6.7 s]
# Iteration 1 fit: [10.9 s]: Recall = 0.1456, Jaccard score = 0.1222, loss = 0.4428, eval: [6.6 s]
# Iteration 2 fit: [10.6 s]: Recall = 0.1536, Jaccard score = 0.1298, loss = 0.4246, eval: [6.7 s]
# Iteration 3 fit: [10.6 s]: Recall = 0.1582, Jaccard score = 0.1342, loss = 0.4154, eval: [6.6 s]
# Iteration 4 fit: [10.5 s]: Recall = 0.1651, Jaccard score = 0.1409, loss = 0.4096, eval: [6.7 s]
# Iteration 5 fit: [11.3 s]: Recall = 0.1675, Jaccard score = 0.1432, loss = 0.4038, eval: [6.6 s]
# Iteration 6 fit: [10.5 s]: Recall = 0.1679, Jaccard score = 0.1436, loss = 0.3997, eval: [6.7 s]
# Iteration 7 fit: [10.6 s]: Recall = 0.1751, Jaccard score = 0.1507, loss = 0.3956, eval: [6.7 s]
# Iteration 8 fit: [10.6 s]: Recall = 0.1760, Jaccard score = 0.1516, loss = 0.3916, eval: [6.7 s]
# Iteration 9 fit: [10.6 s]: Recall = 0.1782, Jaccard score = 0.1537, loss = 0.3887, eval: [6.6 s]
# Iteration 10 fit: [10.5 s]: Recall = 0.1821, Jaccard score = 0.1577, loss = 0.3851, eval: [6.7 s]
# Iteration 11 fit: [10.6 s]: Recall = 0.1831, Jaccard score = 0.1587, loss = 0.3818, eval: [6.6 s]
# Iteration 12 fit: [10.6 s]: Recall = 0.1853, Jaccard score = 0.1609, loss = 0.3785, eval: [6.7 s]
# Iteration 13 fit: [10.6 s]: Recall = 0.1877, Jaccard score = 0.1633, loss = 0.3757, eval: [6.7 s]
# Iteration 14 fit: [10.5 s]: Recall = 0.1876, Jaccard score = 0.1632, loss = 0.3731, eval: [6.7 s]
# Iteration 15 fit: [10.6 s]: Recall = 0.1918, Jaccard score = 0.1675, loss = 0.3706, eval: [6.7 s]
# Iteration 16 fit: [10.8 s]: Recall = 0.1897, Jaccard score = 0.1654, loss = 0.3674, eval: [6.7 s]
# Iteration 17 fit: [10.9 s]: Recall = 0.1919, Jaccard score = 0.1675, loss = 0.3648, eval: [6.6 s]
# Iteration 18 fit: [10.8 s]: Recall = 0.1915, Jaccard score = 0.1671, loss = 0.3627, eval: [6.9 s]
# Iteration 19 fit: [10.6 s]: Recall = 0.1916, Jaccard score = 0.1672, loss = 0.3602, eval: [6.7 s]
# Iteration 20 fit: [10.9 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3579, eval: [6.6 s]
# Iteration 21 fit: [10.9 s]: Recall = 0.1925, Jaccard score = 0.1682, loss = 0.3559, eval: [6.7 s]
# Iteration 22 fit: [10.6 s]: Recall = 0.1947, Jaccard score = 0.1705, loss = 0.3533, eval: [6.6 s]
# Iteration 23 fit: [10.9 s]: Recall = 0.1948, Jaccard score = 0.1706, loss = 0.3519, eval: [6.6 s]
# Iteration 24 fit: [10.8 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.3492, eval: [6.8 s]
# Iteration 25 fit: [11.0 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3474, eval: [6.7 s]
# Iteration 26 fit: [10.7 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3455, eval: [6.6 s]
# Iteration 27 fit: [11.0 s]: Recall = 0.1944, Jaccard score = 0.1702, loss = 0.3437, eval: [6.6 s]
# Iteration 28 fit: [11.0 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3417, eval: [6.6 s]
# Iteration 29 fit: [10.9 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3399, eval: [6.6 s]
# Iteration 30 fit: [10.9 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3376, eval: [6.6 s]
# Iteration 31 fit: [11.1 s]: Recall = 0.1945, Jaccard score = 0.1702, loss = 0.3364, eval: [6.6 s]
# Iteration 32 fit: [10.9 s]: Recall = 0.1915, Jaccard score = 0.1672, loss = 0.3344, eval: [6.6 s]
# Iteration 33 fit: [10.7 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3332, eval: [6.7 s]
# Iteration 34 fit: [10.9 s]: Recall = 0.1965, Jaccard score = 0.1722, loss = 0.3313, eval: [6.7 s]
# Iteration 35 fit: [10.8 s]: Recall = 0.1948, Jaccard score = 0.1706, loss = 0.3298, eval: [6.8 s]
# Iteration 36 fit: [10.9 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3284, eval: [6.5 s]
# Iteration 37 fit: [10.9 s]: Recall = 0.1964, Jaccard score = 0.1722, loss = 0.3274, eval: [6.6 s]
# Iteration 38 fit: [11.0 s]: Recall = 0.1963, Jaccard score = 0.1721, loss = 0.3252, eval: [6.6 s]
# Iteration 39 fit: [10.9 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3242, eval: [6.6 s]
# Iteration 40 fit: [10.9 s]: Recall = 0.1950, Jaccard score = 0.1707, loss = 0.3231, eval: [6.7 s]
# Iteration 41 fit: [10.9 s]: Recall = 0.1934, Jaccard score = 0.1691, loss = 0.3210, eval: [6.6 s]
# Iteration 42 fit: [10.9 s]: Recall = 0.1944, Jaccard score = 0.1701, loss = 0.3194, eval: [6.7 s]
# Iteration 43 fit: [10.7 s]: Recall = 0.1952, Jaccard score = 0.1710, loss = 0.3184, eval: [6.7 s]
# Iteration 44 fit: [11.4 s]: Recall = 0.1915, Jaccard score = 0.1671, loss = 0.3170, eval: [6.7 s]
# Iteration 45 fit: [10.9 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3155, eval: [6.6 s]
# Iteration 46 fit: [11.0 s]: Recall = 0.1943, Jaccard score = 0.1700, loss = 0.3145, eval: [6.6 s]
# Iteration 47 fit: [11.0 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3133, eval: [6.6 s]
# Iteration 48 fit: [10.7 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3120, eval: [6.6 s]
# Iteration 49 fit: [10.8 s]: Recall = 0.1924, Jaccard score = 0.1681, loss = 0.3109, eval: [6.6 s]
# Iteration 50 fit: [10.9 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3094, eval: [6.6 s]
# Iteration 51 fit: [10.6 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3083, eval: [6.7 s]
# Iteration 52 fit: [10.8 s]: Recall = 0.1919, Jaccard score = 0.1675, loss = 0.3080, eval: [6.7 s]
# Iteration 53 fit: [11.0 s]: Recall = 0.1952, Jaccard score = 0.1710, loss = 0.3063, eval: [6.6 s]
# Iteration 54 fit: [10.8 s]: Recall = 0.1918, Jaccard score = 0.1675, loss = 0.3049, eval: [6.6 s]
# Iteration 55 fit: [10.9 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.3042, eval: [6.7 s]
# Iteration 56 fit: [10.7 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3034, eval: [6.6 s]
# Iteration 57 fit: [10.9 s]: Recall = 0.1934, Jaccard score = 0.1691, loss = 0.3015, eval: [6.7 s]
# Iteration 58 fit: [10.5 s]: Recall = 0.1951, Jaccard score = 0.1709, loss = 0.3011, eval: [6.7 s]
# Iteration 59 fit: [10.8 s]: Recall = 0.1944, Jaccard score = 0.1701, loss = 0.2995, eval: [6.8 s]
# Iteration 60 fit: [10.7 s]: Recall = 0.1936, Jaccard score = 0.1693, loss = 0.2990, eval: [6.7 s]
# Iteration 61 fit: [10.9 s]: Recall = 0.1927, Jaccard score = 0.1684, loss = 0.2976, eval: [6.6 s]
# Iteration 62 fit: [10.7 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.2966, eval: [6.6 s]
# Iteration 63 fit: [10.6 s]: Recall = 0.1911, Jaccard score = 0.1668, loss = 0.2960, eval: [6.6 s]
# Iteration 64 fit: [10.9 s]: Recall = 0.1906, Jaccard score = 0.1663, loss = 0.2949, eval: [6.6 s]
# Iteration 65 fit: [10.9 s]: Recall = 0.1952, Jaccard score = 0.1709, loss = 0.2939, eval: [6.7 s]
# Iteration 66 fit: [11.0 s]: Recall = 0.1914, Jaccard score = 0.1671, loss = 0.2928, eval: [6.7 s]
# Iteration 67 fit: [11.0 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.2920, eval: [6.7 s]
# Iteration 68 fit: [10.6 s]: Recall = 0.1888, Jaccard score = 0.1644, loss = 0.2915, eval: [6.6 s]
# Iteration 69 fit: [11.1 s]: Recall = 0.1889, Jaccard score = 0.1645, loss = 0.2906, eval: [6.8 s]
# End. Best Iteration 34:  Recall = 0.1965, Jaccard score = 0.1722. 
# The best NeuMF model has been saved to Pretrain/_MLP_8_[128,64]_1565610447.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,64]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[128,64]_1565611738.h5
--weights_path: Pretrain/_MLP_8_[128,64]_1565611738.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 256)          256256      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 320)          0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 64)           20544       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 64)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            65          activation_1[0][0]               
# ==================================================================================================
# Total params: 404,865
# Trainable params: 404,865
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0257, Jaccard score = 0.0196
# Iteration 0 fit: [11.4 s]: Recall = 0.1360, Jaccard score = 0.1132, loss = 0.4881, eval: [6.7 s]
# Iteration 1 fit: [11.1 s]: Recall = 0.1447, Jaccard score = 0.1214, loss = 0.4437, eval: [6.7 s]
# Iteration 2 fit: [11.0 s]: Recall = 0.1529, Jaccard score = 0.1291, loss = 0.4241, eval: [6.8 s]
# Iteration 3 fit: [11.1 s]: Recall = 0.1626, Jaccard score = 0.1385, loss = 0.4146, eval: [6.7 s]
# Iteration 4 fit: [11.2 s]: Recall = 0.1663, Jaccard score = 0.1420, loss = 0.4075, eval: [6.7 s]
# Iteration 5 fit: [11.1 s]: Recall = 0.1698, Jaccard score = 0.1454, loss = 0.4019, eval: [6.8 s]
# Iteration 6 fit: [11.1 s]: Recall = 0.1733, Jaccard score = 0.1489, loss = 0.3968, eval: [6.7 s]
# Iteration 7 fit: [11.0 s]: Recall = 0.1757, Jaccard score = 0.1513, loss = 0.3926, eval: [6.6 s]
# Iteration 8 fit: [11.0 s]: Recall = 0.1819, Jaccard score = 0.1575, loss = 0.3880, eval: [6.7 s]
# Iteration 9 fit: [11.0 s]: Recall = 0.1810, Jaccard score = 0.1566, loss = 0.3839, eval: [6.7 s]
# Iteration 10 fit: [11.0 s]: Recall = 0.1842, Jaccard score = 0.1598, loss = 0.3806, eval: [6.7 s]
# Iteration 11 fit: [11.1 s]: Recall = 0.1851, Jaccard score = 0.1607, loss = 0.3768, eval: [6.7 s]
# Iteration 12 fit: [11.1 s]: Recall = 0.1861, Jaccard score = 0.1617, loss = 0.3734, eval: [6.7 s]
# Iteration 13 fit: [11.1 s]: Recall = 0.1877, Jaccard score = 0.1633, loss = 0.3701, eval: [6.7 s]
# Iteration 14 fit: [11.5 s]: Recall = 0.1908, Jaccard score = 0.1664, loss = 0.3669, eval: [6.8 s]
# Iteration 15 fit: [11.1 s]: Recall = 0.1901, Jaccard score = 0.1658, loss = 0.3639, eval: [6.6 s]
# Iteration 16 fit: [11.2 s]: Recall = 0.1928, Jaccard score = 0.1685, loss = 0.3607, eval: [6.7 s]
# Iteration 17 fit: [11.1 s]: Recall = 0.1929, Jaccard score = 0.1686, loss = 0.3575, eval: [6.8 s]
# Iteration 18 fit: [11.1 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3548, eval: [6.8 s]
# Iteration 19 fit: [11.2 s]: Recall = 0.1918, Jaccard score = 0.1675, loss = 0.3524, eval: [6.7 s]
# Iteration 20 fit: [11.1 s]: Recall = 0.1944, Jaccard score = 0.1702, loss = 0.3495, eval: [6.8 s]
# Iteration 21 fit: [11.2 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3467, eval: [6.7 s]
# Iteration 22 fit: [11.1 s]: Recall = 0.1921, Jaccard score = 0.1678, loss = 0.3441, eval: [6.6 s]
# Iteration 23 fit: [11.2 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.3414, eval: [6.8 s]
# Iteration 24 fit: [11.0 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3389, eval: [6.7 s]
# Iteration 25 fit: [11.1 s]: Recall = 0.1923, Jaccard score = 0.1680, loss = 0.3361, eval: [6.7 s]
# Iteration 26 fit: [11.0 s]: Recall = 0.1947, Jaccard score = 0.1705, loss = 0.3341, eval: [6.7 s]
# Iteration 27 fit: [11.1 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3319, eval: [6.6 s]
# Iteration 28 fit: [11.1 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3294, eval: [6.7 s]
# Iteration 29 fit: [11.2 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3274, eval: [6.8 s]
# Iteration 30 fit: [11.0 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3247, eval: [6.7 s]
# Iteration 31 fit: [11.1 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3224, eval: [6.8 s]
# Iteration 32 fit: [11.1 s]: Recall = 0.1960, Jaccard score = 0.1718, loss = 0.3206, eval: [6.7 s]
# Iteration 33 fit: [11.2 s]: Recall = 0.1944, Jaccard score = 0.1702, loss = 0.3185, eval: [6.8 s]
# Iteration 34 fit: [11.1 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3163, eval: [6.7 s]
# Iteration 35 fit: [11.2 s]: Recall = 0.1964, Jaccard score = 0.1722, loss = 0.3145, eval: [6.7 s]
# Iteration 36 fit: [11.2 s]: Recall = 0.1943, Jaccard score = 0.1700, loss = 0.3124, eval: [6.7 s]
# Iteration 37 fit: [11.1 s]: Recall = 0.1960, Jaccard score = 0.1718, loss = 0.3101, eval: [6.8 s]
# Iteration 38 fit: [11.0 s]: Recall = 0.1954, Jaccard score = 0.1712, loss = 0.3083, eval: [6.7 s]
# Iteration 39 fit: [11.1 s]: Recall = 0.1939, Jaccard score = 0.1696, loss = 0.3064, eval: [6.7 s]
# Iteration 40 fit: [11.0 s]: Recall = 0.1935, Jaccard score = 0.1692, loss = 0.3050, eval: [6.7 s]
# Iteration 41 fit: [11.2 s]: Recall = 0.1924, Jaccard score = 0.1681, loss = 0.3028, eval: [6.8 s]
# Iteration 42 fit: [11.1 s]: Recall = 0.1931, Jaccard score = 0.1688, loss = 0.3011, eval: [6.8 s]
# Iteration 43 fit: [11.2 s]: Recall = 0.1944, Jaccard score = 0.1701, loss = 0.2991, eval: [6.9 s]
# Iteration 44 fit: [11.0 s]: Recall = 0.1906, Jaccard score = 0.1663, loss = 0.2976, eval: [6.7 s]
# Iteration 45 fit: [11.1 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.2955, eval: [6.7 s]
# Iteration 46 fit: [11.0 s]: Recall = 0.1898, Jaccard score = 0.1655, loss = 0.2941, eval: [6.7 s]
# Iteration 47 fit: [11.2 s]: Recall = 0.1932, Jaccard score = 0.1689, loss = 0.2923, eval: [6.7 s]
# Iteration 48 fit: [11.1 s]: Recall = 0.1906, Jaccard score = 0.1663, loss = 0.2904, eval: [6.7 s]
# Iteration 49 fit: [11.2 s]: Recall = 0.1888, Jaccard score = 0.1644, loss = 0.2889, eval: [6.8 s]
# Iteration 50 fit: [11.1 s]: Recall = 0.1894, Jaccard score = 0.1651, loss = 0.2876, eval: [6.7 s]
# Iteration 51 fit: [11.1 s]: Recall = 0.1903, Jaccard score = 0.1659, loss = 0.2859, eval: [6.7 s]
# Iteration 52 fit: [11.0 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.2843, eval: [6.7 s]
# Iteration 53 fit: [11.1 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.2828, eval: [6.8 s]
# Iteration 54 fit: [11.0 s]: Recall = 0.1880, Jaccard score = 0.1636, loss = 0.2810, eval: [6.7 s]
# Iteration 55 fit: [11.1 s]: Recall = 0.1909, Jaccard score = 0.1666, loss = 0.2793, eval: [6.7 s]
# Iteration 56 fit: [11.0 s]: Recall = 0.1883, Jaccard score = 0.1639, loss = 0.2778, eval: [6.8 s]
# Iteration 57 fit: [11.2 s]: Recall = 0.1916, Jaccard score = 0.1672, loss = 0.2763, eval: [6.7 s]
# Iteration 58 fit: [11.2 s]: Recall = 0.1871, Jaccard score = 0.1627, loss = 0.2751, eval: [6.7 s]
# Iteration 59 fit: [11.2 s]: Recall = 0.1875, Jaccard score = 0.1631, loss = 0.2736, eval: [6.7 s]
# Iteration 60 fit: [11.2 s]: Recall = 0.1882, Jaccard score = 0.1638, loss = 0.2725, eval: [6.6 s]
# Iteration 61 fit: [11.1 s]: Recall = 0.1882, Jaccard score = 0.1638, loss = 0.2713, eval: [6.8 s]
# Iteration 62 fit: [11.1 s]: Recall = 0.1870, Jaccard score = 0.1626, loss = 0.2701, eval: [6.7 s]
# Iteration 63 fit: [11.1 s]: Recall = 0.1876, Jaccard score = 0.1632, loss = 0.2686, eval: [6.8 s]
# Iteration 64 fit: [11.1 s]: Recall = 0.1856, Jaccard score = 0.1612, loss = 0.2672, eval: [6.7 s]
# Iteration 65 fit: [11.1 s]: Recall = 0.1879, Jaccard score = 0.1635, loss = 0.2660, eval: [6.7 s]
# Iteration 66 fit: [11.0 s]: Recall = 0.1871, Jaccard score = 0.1627, loss = 0.2642, eval: [6.6 s]
# Iteration 67 fit: [11.1 s]: Recall = 0.1869, Jaccard score = 0.1625, loss = 0.2638, eval: [6.8 s]
# Iteration 68 fit: [11.0 s]: Recall = 0.1842, Jaccard score = 0.1598, loss = 0.2619, eval: [6.7 s]
# Iteration 69 fit: [11.2 s]: Recall = 0.1863, Jaccard score = 0.1619, loss = 0.2610, eval: [6.8 s]
# Iteration 70 fit: [11.1 s]: Recall = 0.1861, Jaccard score = 0.1617, loss = 0.2591, eval: [6.6 s]
# End. Best Iteration 35:  Recall = 0.1964, Jaccard score = 0.1722. 
# The best NeuMF model has been saved to Pretrain/_MLP_8_[128,64]_1565611738.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,64]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[128,64]_1565613631.h5
--weights_path: Pretrain/_MLP_8_[128,64]_1565613631.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 256)          256256      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 320)          0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 64)           20544       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 64)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            65          activation_1[0][0]               
# ==================================================================================================
# Total params: 404,865
# Trainable params: 404,865
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0267, Jaccard score = 0.0204
# Iteration 0 fit: [11.4 s]: Recall = 0.1037, Jaccard score = 0.0840, loss = 0.4923, eval: [6.9 s]
# Iteration 1 fit: [11.1 s]: Recall = 0.1301, Jaccard score = 0.1078, loss = 0.4615, eval: [6.9 s]
# Iteration 2 fit: [11.0 s]: Recall = 0.1426, Jaccard score = 0.1194, loss = 0.4408, eval: [7.0 s]
# Iteration 3 fit: [11.1 s]: Recall = 0.1491, Jaccard score = 0.1255, loss = 0.4283, eval: [7.0 s]
# Iteration 4 fit: [11.1 s]: Recall = 0.1516, Jaccard score = 0.1279, loss = 0.4201, eval: [7.0 s]
# Iteration 5 fit: [11.1 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.4151, eval: [7.0 s]
# Iteration 6 fit: [11.0 s]: Recall = 0.1605, Jaccard score = 0.1364, loss = 0.4108, eval: [7.1 s]
# Iteration 7 fit: [12.0 s]: Recall = 0.1614, Jaccard score = 0.1372, loss = 0.4069, eval: [6.9 s]
# Iteration 8 fit: [11.0 s]: Recall = 0.1660, Jaccard score = 0.1418, loss = 0.4041, eval: [7.0 s]
# Iteration 9 fit: [11.0 s]: Recall = 0.1668, Jaccard score = 0.1425, loss = 0.4015, eval: [7.0 s]
# Iteration 10 fit: [11.0 s]: Recall = 0.1710, Jaccard score = 0.1466, loss = 0.3983, eval: [6.9 s]
# Iteration 11 fit: [11.0 s]: Recall = 0.1709, Jaccard score = 0.1466, loss = 0.3955, eval: [6.9 s]
# Iteration 12 fit: [11.0 s]: Recall = 0.1748, Jaccard score = 0.1504, loss = 0.3929, eval: [6.9 s]
# Iteration 13 fit: [11.0 s]: Recall = 0.1784, Jaccard score = 0.1540, loss = 0.3900, eval: [6.9 s]
# Iteration 14 fit: [11.1 s]: Recall = 0.1810, Jaccard score = 0.1566, loss = 0.3871, eval: [6.9 s]
# Iteration 15 fit: [11.0 s]: Recall = 0.1810, Jaccard score = 0.1565, loss = 0.3849, eval: [7.0 s]
# Iteration 16 fit: [11.0 s]: Recall = 0.1811, Jaccard score = 0.1566, loss = 0.3818, eval: [7.0 s]
# Iteration 17 fit: [11.1 s]: Recall = 0.1832, Jaccard score = 0.1587, loss = 0.3796, eval: [7.0 s]
# Iteration 18 fit: [11.0 s]: Recall = 0.1858, Jaccard score = 0.1614, loss = 0.3772, eval: [7.0 s]
# Iteration 19 fit: [11.0 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3749, eval: [6.9 s]
# Iteration 20 fit: [11.0 s]: Recall = 0.1895, Jaccard score = 0.1651, loss = 0.3721, eval: [6.9 s]
# Iteration 21 fit: [11.1 s]: Recall = 0.1883, Jaccard score = 0.1639, loss = 0.3696, eval: [6.9 s]
# Iteration 22 fit: [11.0 s]: Recall = 0.1898, Jaccard score = 0.1654, loss = 0.3677, eval: [7.0 s]
# Iteration 23 fit: [11.1 s]: Recall = 0.1916, Jaccard score = 0.1672, loss = 0.3659, eval: [6.9 s]
# Iteration 24 fit: [11.1 s]: Recall = 0.1904, Jaccard score = 0.1660, loss = 0.3635, eval: [7.0 s]
# Iteration 25 fit: [11.0 s]: Recall = 0.1908, Jaccard score = 0.1664, loss = 0.3620, eval: [7.0 s]
# Iteration 26 fit: [11.1 s]: Recall = 0.1941, Jaccard score = 0.1698, loss = 0.3597, eval: [7.0 s]
# Iteration 27 fit: [11.1 s]: Recall = 0.1928, Jaccard score = 0.1685, loss = 0.3577, eval: [6.9 s]
# Iteration 28 fit: [11.0 s]: Recall = 0.1909, Jaccard score = 0.1665, loss = 0.3569, eval: [7.0 s]
# Iteration 29 fit: [11.0 s]: Recall = 0.1920, Jaccard score = 0.1677, loss = 0.3547, eval: [7.0 s]
# Iteration 30 fit: [11.0 s]: Recall = 0.1924, Jaccard score = 0.1681, loss = 0.3528, eval: [7.0 s]
# Iteration 31 fit: [11.1 s]: Recall = 0.1935, Jaccard score = 0.1692, loss = 0.3512, eval: [7.0 s]
# Iteration 32 fit: [11.0 s]: Recall = 0.1918, Jaccard score = 0.1675, loss = 0.3496, eval: [7.0 s]
# Iteration 33 fit: [11.1 s]: Recall = 0.1941, Jaccard score = 0.1698, loss = 0.3480, eval: [6.9 s]
# Iteration 34 fit: [11.1 s]: Recall = 0.1957, Jaccard score = 0.1715, loss = 0.3469, eval: [7.0 s]
# Iteration 35 fit: [11.0 s]: Recall = 0.1927, Jaccard score = 0.1683, loss = 0.3454, eval: [7.0 s]
# Iteration 36 fit: [11.1 s]: Recall = 0.1918, Jaccard score = 0.1674, loss = 0.3439, eval: [7.0 s]
# Iteration 37 fit: [11.1 s]: Recall = 0.1939, Jaccard score = 0.1696, loss = 0.3423, eval: [7.0 s]
# Iteration 38 fit: [11.0 s]: Recall = 0.1945, Jaccard score = 0.1702, loss = 0.3407, eval: [7.0 s]
# Iteration 39 fit: [11.0 s]: Recall = 0.1946, Jaccard score = 0.1703, loss = 0.3396, eval: [6.9 s]
# Iteration 40 fit: [11.0 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3388, eval: [6.9 s]
# Iteration 41 fit: [11.0 s]: Recall = 0.1946, Jaccard score = 0.1703, loss = 0.3374, eval: [6.9 s]
# Iteration 42 fit: [11.0 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3366, eval: [7.1 s]
# Iteration 43 fit: [11.1 s]: Recall = 0.1951, Jaccard score = 0.1708, loss = 0.3352, eval: [6.9 s]
# Iteration 44 fit: [11.1 s]: Recall = 0.1929, Jaccard score = 0.1686, loss = 0.3342, eval: [7.0 s]
# Iteration 45 fit: [11.0 s]: Recall = 0.1962, Jaccard score = 0.1720, loss = 0.3332, eval: [6.9 s]
# Iteration 46 fit: [11.2 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3316, eval: [7.0 s]
# Iteration 47 fit: [11.2 s]: Recall = 0.1965, Jaccard score = 0.1722, loss = 0.3306, eval: [7.0 s]
# Iteration 48 fit: [11.1 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3293, eval: [7.0 s]
# Iteration 49 fit: [11.1 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3287, eval: [7.0 s]
# Iteration 50 fit: [11.0 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3274, eval: [7.0 s]
# Iteration 51 fit: [11.1 s]: Recall = 0.1966, Jaccard score = 0.1724, loss = 0.3261, eval: [6.9 s]
# Iteration 52 fit: [11.0 s]: Recall = 0.1945, Jaccard score = 0.1702, loss = 0.3257, eval: [6.9 s]
# Iteration 53 fit: [11.1 s]: Recall = 0.1961, Jaccard score = 0.1718, loss = 0.3240, eval: [7.0 s]
# Iteration 54 fit: [11.0 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3237, eval: [6.9 s]
# Iteration 55 fit: [11.1 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3225, eval: [7.0 s]
# Iteration 56 fit: [11.1 s]: Recall = 0.1961, Jaccard score = 0.1718, loss = 0.3217, eval: [6.9 s]
# Iteration 57 fit: [11.1 s]: Recall = 0.1961, Jaccard score = 0.1718, loss = 0.3207, eval: [7.0 s]
# Iteration 58 fit: [11.0 s]: Recall = 0.1959, Jaccard score = 0.1716, loss = 0.3202, eval: [6.9 s]
# Iteration 59 fit: [11.1 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3194, eval: [7.0 s]
# Iteration 60 fit: [11.0 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3182, eval: [6.9 s]
# Iteration 61 fit: [11.1 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3178, eval: [6.9 s]
# Iteration 62 fit: [11.0 s]: Recall = 0.1941, Jaccard score = 0.1698, loss = 0.3170, eval: [7.0 s]
# Iteration 63 fit: [11.9 s]: Recall = 0.1968, Jaccard score = 0.1725, loss = 0.3160, eval: [6.9 s]
# Iteration 64 fit: [11.1 s]: Recall = 0.1946, Jaccard score = 0.1703, loss = 0.3148, eval: [7.0 s]
# Iteration 65 fit: [11.0 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3145, eval: [7.0 s]
# Iteration 66 fit: [11.0 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3136, eval: [7.0 s]
# Iteration 67 fit: [11.4 s]: Recall = 0.1952, Jaccard score = 0.1710, loss = 0.3126, eval: [7.1 s]
# Iteration 68 fit: [11.1 s]: Recall = 0.1929, Jaccard score = 0.1686, loss = 0.3123, eval: [7.0 s]
# Iteration 69 fit: [11.0 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3112, eval: [7.0 s]
# Iteration 70 fit: [11.0 s]: Recall = 0.1943, Jaccard score = 0.1700, loss = 0.3109, eval: [7.1 s]
# Iteration 71 fit: [11.0 s]: Recall = 0.1953, Jaccard score = 0.1710, loss = 0.3099, eval: [7.0 s]
# Iteration 72 fit: [11.0 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3091, eval: [6.9 s]
# Iteration 73 fit: [11.1 s]: Recall = 0.1936, Jaccard score = 0.1693, loss = 0.3081, eval: [6.9 s]
# Iteration 74 fit: [11.1 s]: Recall = 0.1968, Jaccard score = 0.1725, loss = 0.3076, eval: [6.9 s]
# Iteration 75 fit: [11.0 s]: Recall = 0.1963, Jaccard score = 0.1721, loss = 0.3069, eval: [6.9 s]
# Iteration 76 fit: [11.1 s]: Recall = 0.1941, Jaccard score = 0.1698, loss = 0.3068, eval: [6.9 s]
# Iteration 77 fit: [11.1 s]: Recall = 0.1964, Jaccard score = 0.1721, loss = 0.3060, eval: [6.9 s]
# Iteration 78 fit: [11.0 s]: Recall = 0.1959, Jaccard score = 0.1717, loss = 0.3056, eval: [6.9 s]
# Iteration 79 fit: [11.1 s]: Recall = 0.1919, Jaccard score = 0.1676, loss = 0.3039, eval: [7.0 s]
# Iteration 80 fit: [11.0 s]: Recall = 0.1956, Jaccard score = 0.1714, loss = 0.3033, eval: [7.1 s]
# Iteration 81 fit: [11.1 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3029, eval: [7.1 s]
# Iteration 82 fit: [11.1 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3025, eval: [7.0 s]
# Iteration 83 fit: [13.8 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3022, eval: [7.0 s]
# Iteration 84 fit: [11.1 s]: Recall = 0.1960, Jaccard score = 0.1718, loss = 0.3013, eval: [7.1 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[64,32]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[64,32]_1565615200.h5
--weights_path: Pretrain/_MLP_8_[64,32]_1565615200.h5
# Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 32)        64000       item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 32)           32032       user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 32)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 64)           0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 32)           2080        concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 32)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            33          activation_1[0][0]               
# ==================================================================================================
# Total params: 98,145
# Trainable params: 98,145
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0246, Jaccard score = 0.0187
# Iteration 0 fit: [11.4 s]: Recall = 0.0769, Jaccard score = 0.0610, loss = 0.5086, eval: [6.8 s]
# Iteration 1 fit: [11.2 s]: Recall = 0.1032, Jaccard score = 0.0836, loss = 0.4801, eval: [6.9 s]
# Iteration 2 fit: [11.2 s]: Recall = 0.1243, Jaccard score = 0.1025, loss = 0.4627, eval: [6.8 s]
# Iteration 3 fit: [11.3 s]: Recall = 0.1332, Jaccard score = 0.1106, loss = 0.4476, eval: [6.9 s]
# Iteration 4 fit: [11.5 s]: Recall = 0.1396, Jaccard score = 0.1165, loss = 0.4372, eval: [6.8 s]
# Iteration 5 fit: [11.1 s]: Recall = 0.1407, Jaccard score = 0.1176, loss = 0.4298, eval: [6.8 s]
# Iteration 6 fit: [11.2 s]: Recall = 0.1432, Jaccard score = 0.1200, loss = 0.4241, eval: [6.9 s]
# Iteration 7 fit: [11.8 s]: Recall = 0.1464, Jaccard score = 0.1230, loss = 0.4202, eval: [6.9 s]
# Iteration 8 fit: [11.3 s]: Recall = 0.1499, Jaccard score = 0.1263, loss = 0.4168, eval: [6.8 s]
# Iteration 9 fit: [11.2 s]: Recall = 0.1515, Jaccard score = 0.1278, loss = 0.4146, eval: [6.8 s]
# Iteration 10 fit: [11.3 s]: Recall = 0.1528, Jaccard score = 0.1290, loss = 0.4130, eval: [6.9 s]
# Iteration 11 fit: [11.2 s]: Recall = 0.1553, Jaccard score = 0.1315, loss = 0.4109, eval: [6.7 s]
# Iteration 12 fit: [11.3 s]: Recall = 0.1543, Jaccard score = 0.1305, loss = 0.4094, eval: [6.9 s]
# Iteration 13 fit: [11.5 s]: Recall = 0.1602, Jaccard score = 0.1361, loss = 0.4074, eval: [7.0 s]
# Iteration 14 fit: [11.5 s]: Recall = 0.1590, Jaccard score = 0.1350, loss = 0.4054, eval: [6.9 s]
# Iteration 15 fit: [11.2 s]: Recall = 0.1601, Jaccard score = 0.1360, loss = 0.4042, eval: [6.9 s]
# Iteration 16 fit: [11.1 s]: Recall = 0.1624, Jaccard score = 0.1383, loss = 0.4026, eval: [6.9 s]
# Iteration 17 fit: [11.3 s]: Recall = 0.1646, Jaccard score = 0.1404, loss = 0.4010, eval: [6.8 s]
# Iteration 18 fit: [11.2 s]: Recall = 0.1635, Jaccard score = 0.1393, loss = 0.3997, eval: [6.7 s]
# Iteration 19 fit: [11.2 s]: Recall = 0.1662, Jaccard score = 0.1419, loss = 0.3977, eval: [6.9 s]
# Iteration 20 fit: [11.2 s]: Recall = 0.1683, Jaccard score = 0.1440, loss = 0.3968, eval: [6.9 s]
# Iteration 21 fit: [11.4 s]: Recall = 0.1703, Jaccard score = 0.1460, loss = 0.3950, eval: [6.9 s]
# Iteration 22 fit: [11.2 s]: Recall = 0.1717, Jaccard score = 0.1473, loss = 0.3938, eval: [6.9 s]
# Iteration 23 fit: [11.3 s]: Recall = 0.1730, Jaccard score = 0.1487, loss = 0.3920, eval: [6.9 s]
# Iteration 24 fit: [11.2 s]: Recall = 0.1751, Jaccard score = 0.1507, loss = 0.3906, eval: [6.7 s]
# Iteration 25 fit: [11.2 s]: Recall = 0.1766, Jaccard score = 0.1522, loss = 0.3893, eval: [6.9 s]
# Iteration 26 fit: [11.3 s]: Recall = 0.1766, Jaccard score = 0.1522, loss = 0.3879, eval: [6.8 s]
# Iteration 27 fit: [11.3 s]: Recall = 0.1774, Jaccard score = 0.1530, loss = 0.3859, eval: [6.9 s]
# Iteration 28 fit: [11.2 s]: Recall = 0.1787, Jaccard score = 0.1543, loss = 0.3849, eval: [6.9 s]
# Iteration 29 fit: [11.2 s]: Recall = 0.1809, Jaccard score = 0.1564, loss = 0.3832, eval: [6.9 s]
# Iteration 30 fit: [11.3 s]: Recall = 0.1841, Jaccard score = 0.1597, loss = 0.3824, eval: [6.8 s]
# Iteration 31 fit: [11.2 s]: Recall = 0.1834, Jaccard score = 0.1589, loss = 0.3813, eval: [6.9 s]
# Iteration 32 fit: [12.2 s]: Recall = 0.1828, Jaccard score = 0.1584, loss = 0.3798, eval: [6.8 s]
# Iteration 33 fit: [11.3 s]: Recall = 0.1821, Jaccard score = 0.1577, loss = 0.3786, eval: [7.0 s]
# Iteration 34 fit: [11.3 s]: Recall = 0.1827, Jaccard score = 0.1583, loss = 0.3765, eval: [6.8 s]
# Iteration 35 fit: [11.2 s]: Recall = 0.1828, Jaccard score = 0.1583, loss = 0.3759, eval: [6.7 s]
# Iteration 36 fit: [11.2 s]: Recall = 0.1830, Jaccard score = 0.1586, loss = 0.3746, eval: [6.9 s]
# Iteration 37 fit: [11.4 s]: Recall = 0.1837, Jaccard score = 0.1593, loss = 0.3736, eval: [6.9 s]
# Iteration 38 fit: [11.3 s]: Recall = 0.1846, Jaccard score = 0.1601, loss = 0.3723, eval: [6.9 s]
# Iteration 39 fit: [11.2 s]: Recall = 0.1839, Jaccard score = 0.1595, loss = 0.3713, eval: [6.9 s]
# Iteration 40 fit: [11.4 s]: Recall = 0.1853, Jaccard score = 0.1609, loss = 0.3707, eval: [6.9 s]
# Iteration 41 fit: [11.2 s]: Recall = 0.1870, Jaccard score = 0.1626, loss = 0.3695, eval: [6.8 s]
# Iteration 42 fit: [11.3 s]: Recall = 0.1855, Jaccard score = 0.1610, loss = 0.3690, eval: [7.0 s]
# Iteration 43 fit: [11.3 s]: Recall = 0.1860, Jaccard score = 0.1616, loss = 0.3678, eval: [6.9 s]
# Iteration 44 fit: [11.2 s]: Recall = 0.1860, Jaccard score = 0.1616, loss = 0.3665, eval: [6.9 s]
# Iteration 45 fit: [11.1 s]: Recall = 0.1875, Jaccard score = 0.1631, loss = 0.3656, eval: [6.8 s]
# Iteration 46 fit: [11.2 s]: Recall = 0.1889, Jaccard score = 0.1645, loss = 0.3649, eval: [6.8 s]
# Iteration 47 fit: [11.2 s]: Recall = 0.1868, Jaccard score = 0.1624, loss = 0.3641, eval: [6.9 s]
# Iteration 48 fit: [11.2 s]: Recall = 0.1889, Jaccard score = 0.1646, loss = 0.3632, eval: [6.7 s]
# Iteration 49 fit: [11.2 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3628, eval: [6.9 s]
# Iteration 50 fit: [11.4 s]: Recall = 0.1865, Jaccard score = 0.1621, loss = 0.3620, eval: [6.8 s]
# Iteration 51 fit: [11.2 s]: Recall = 0.1871, Jaccard score = 0.1627, loss = 0.3606, eval: [6.8 s]
# Iteration 52 fit: [11.2 s]: Recall = 0.1889, Jaccard score = 0.1645, loss = 0.3596, eval: [6.8 s]
# Iteration 53 fit: [11.2 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3595, eval: [6.9 s]
# Iteration 54 fit: [11.2 s]: Recall = 0.1880, Jaccard score = 0.1636, loss = 0.3588, eval: [6.8 s]
# Iteration 55 fit: [11.2 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3578, eval: [6.9 s]
# Iteration 56 fit: [11.3 s]: Recall = 0.1864, Jaccard score = 0.1619, loss = 0.3570, eval: [6.9 s]
# Iteration 57 fit: [11.4 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3563, eval: [6.7 s]
# Iteration 58 fit: [11.2 s]: Recall = 0.1878, Jaccard score = 0.1634, loss = 0.3559, eval: [6.7 s]
# Iteration 59 fit: [11.3 s]: Recall = 0.1898, Jaccard score = 0.1655, loss = 0.3553, eval: [6.8 s]
# Iteration 60 fit: [11.2 s]: Recall = 0.1904, Jaccard score = 0.1660, loss = 0.3549, eval: [6.9 s]
# Iteration 61 fit: [11.3 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3542, eval: [6.8 s]
# Iteration 62 fit: [11.1 s]: Recall = 0.1922, Jaccard score = 0.1679, loss = 0.3537, eval: [6.9 s]
# Iteration 63 fit: [11.3 s]: Recall = 0.1941, Jaccard score = 0.1698, loss = 0.3525, eval: [6.9 s]
# Iteration 64 fit: [11.2 s]: Recall = 0.1888, Jaccard score = 0.1644, loss = 0.3520, eval: [6.8 s]
# Iteration 65 fit: [11.2 s]: Recall = 0.1894, Jaccard score = 0.1651, loss = 0.3517, eval: [6.7 s]
# Iteration 66 fit: [11.2 s]: Recall = 0.1921, Jaccard score = 0.1678, loss = 0.3509, eval: [6.9 s]
# Iteration 67 fit: [11.4 s]: Recall = 0.1897, Jaccard score = 0.1653, loss = 0.3507, eval: [6.7 s]
# Iteration 68 fit: [11.2 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3502, eval: [6.9 s]
# Iteration 69 fit: [11.3 s]: Recall = 0.1913, Jaccard score = 0.1670, loss = 0.3494, eval: [6.8 s]
# Iteration 70 fit: [11.3 s]: Recall = 0.1914, Jaccard score = 0.1670, loss = 0.3490, eval: [6.8 s]
# Iteration 71 fit: [11.2 s]: Recall = 0.1911, Jaccard score = 0.1668, loss = 0.3481, eval: [6.9 s]
# Iteration 72 fit: [11.2 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3478, eval: [6.7 s]
# Iteration 73 fit: [11.3 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3476, eval: [6.9 s]
# Iteration 74 fit: [11.1 s]: Recall = 0.1921, Jaccard score = 0.1678, loss = 0.3470, eval: [6.7 s]
# Iteration 75 fit: [11.2 s]: Recall = 0.1914, Jaccard score = 0.1670, loss = 0.3466, eval: [6.9 s]
# Iteration 76 fit: [11.3 s]: Recall = 0.1911, Jaccard score = 0.1668, loss = 0.3456, eval: [6.8 s]
# Iteration 77 fit: [11.3 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3455, eval: [6.9 s]
# Iteration 78 fit: [11.1 s]: Recall = 0.1911, Jaccard score = 0.1668, loss = 0.3450, eval: [6.9 s]
# Iteration 79 fit: [11.2 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3449, eval: [6.9 s]
# Iteration 80 fit: [11.2 s]: Recall = 0.1909, Jaccard score = 0.1665, loss = 0.3445, eval: [6.9 s]
# Iteration 81 fit: [11.3 s]: Recall = 0.1902, Jaccard score = 0.1659, loss = 0.3436, eval: [6.7 s]
# Iteration 82 fit: [11.3 s]: Recall = 0.1927, Jaccard score = 0.1683, loss = 0.3435, eval: [6.9 s]
# Iteration 83 fit: [11.3 s]: Recall = 0.1927, Jaccard score = 0.1684, loss = 0.3430, eval: [6.9 s]
# Iteration 84 fit: [11.2 s]: Recall = 0.1923, Jaccard score = 0.1679, loss = 0.3422, eval: [6.8 s]
# Iteration 85 fit: [11.2 s]: Recall = 0.1915, Jaccard score = 0.1672, loss = 0.3419, eval: [6.9 s]
# Iteration 86 fit: [11.2 s]: Recall = 0.1918, Jaccard score = 0.1675, loss = 0.3410, eval: [6.9 s]
# Iteration 87 fit: [11.2 s]: Recall = 0.1925, Jaccard score = 0.1682, loss = 0.3405, eval: [6.9 s]
# Iteration 88 fit: [11.2 s]: Recall = 0.1913, Jaccard score = 0.1670, loss = 0.3406, eval: [6.9 s]
# Iteration 89 fit: [11.2 s]: Recall = 0.1889, Jaccard score = 0.1646, loss = 0.3406, eval: [6.7 s]
# Iteration 90 fit: [11.3 s]: Recall = 0.1903, Jaccard score = 0.1660, loss = 0.3401, eval: [6.8 s]
# Iteration 91 fit: [12.5 s]: Recall = 0.1904, Jaccard score = 0.1660, loss = 0.3397, eval: [6.8 s]
# Iteration 92 fit: [11.3 s]: Recall = 0.1909, Jaccard score = 0.1666, loss = 0.3395, eval: [6.7 s]
# Iteration 93 fit: [11.4 s]: Recall = 0.1923, Jaccard score = 0.1680, loss = 0.3383, eval: [6.9 s]
# Iteration 94 fit: [11.2 s]: Recall = 0.1916, Jaccard score = 0.1672, loss = 0.3384, eval: [6.7 s]
# Iteration 95 fit: [12.1 s]: Recall = 0.1899, Jaccard score = 0.1655, loss = 0.3382, eval: [6.9 s]
# Iteration 96 fit: [11.3 s]: Recall = 0.1936, Jaccard score = 0.1693, loss = 0.3381, eval: [6.9 s]
# Iteration 97 fit: [11.2 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3373, eval: [6.9 s]
# Iteration 98 fit: [10.9 s]: Recall = 0.1898, Jaccard score = 0.1655, loss = 0.3372, eval: [6.9 s]
# End. Best Iteration 63:  Recall = 0.1941, Jaccard score = 0.1698. 
# The best NeuMF model has been saved to Pretrain/_MLP_8_[64,32]_1565615200.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565617615.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565617615.h5
# Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 16)        32000       item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 16)           16016       user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 16)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 32)           0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 16)           528         concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 16)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            17          activation_1[0][0]               
# ==================================================================================================
# Total params: 48,561
# Trainable params: 48,561
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0314, Jaccard score = 0.0241
# Iteration 0 fit: [11.1 s]: Recall = 0.0421, Jaccard score = 0.0325, loss = 0.5180, eval: [6.9 s]
# Iteration 1 fit: [10.8 s]: Recall = 0.0719, Jaccard score = 0.0568, loss = 0.4935, eval: [6.9 s]
# Iteration 2 fit: [10.8 s]: Recall = 0.0941, Jaccard score = 0.0757, loss = 0.4824, eval: [6.9 s]
# Iteration 3 fit: [10.8 s]: Recall = 0.1161, Jaccard score = 0.0951, loss = 0.4696, eval: [6.9 s]
# Iteration 4 fit: [10.8 s]: Recall = 0.1244, Jaccard score = 0.1026, loss = 0.4580, eval: [6.9 s]
# Iteration 5 fit: [10.8 s]: Recall = 0.1298, Jaccard score = 0.1075, loss = 0.4483, eval: [6.9 s]
# Iteration 6 fit: [10.8 s]: Recall = 0.1326, Jaccard score = 0.1101, loss = 0.4407, eval: [6.9 s]
# Iteration 7 fit: [10.8 s]: Recall = 0.1378, Jaccard score = 0.1149, loss = 0.4346, eval: [6.9 s]
# Iteration 8 fit: [10.8 s]: Recall = 0.1414, Jaccard score = 0.1182, loss = 0.4301, eval: [6.9 s]
# Iteration 9 fit: [11.6 s]: Recall = 0.1434, Jaccard score = 0.1201, loss = 0.4264, eval: [6.9 s]
# Iteration 10 fit: [10.8 s]: Recall = 0.1405, Jaccard score = 0.1174, loss = 0.4237, eval: [6.8 s]
# Iteration 11 fit: [10.8 s]: Recall = 0.1420, Jaccard score = 0.1188, loss = 0.4213, eval: [6.9 s]
# Iteration 12 fit: [10.8 s]: Recall = 0.1439, Jaccard score = 0.1206, loss = 0.4192, eval: [6.9 s]
# Iteration 13 fit: [10.8 s]: Recall = 0.1466, Jaccard score = 0.1232, loss = 0.4173, eval: [6.9 s]
# Iteration 14 fit: [10.8 s]: Recall = 0.1467, Jaccard score = 0.1233, loss = 0.4163, eval: [6.9 s]
# Iteration 15 fit: [10.8 s]: Recall = 0.1489, Jaccard score = 0.1254, loss = 0.4155, eval: [6.9 s]
# Iteration 16 fit: [10.8 s]: Recall = 0.1471, Jaccard score = 0.1236, loss = 0.4141, eval: [7.0 s]
# Iteration 17 fit: [10.8 s]: Recall = 0.1484, Jaccard score = 0.1248, loss = 0.4128, eval: [6.9 s]
# Iteration 18 fit: [10.8 s]: Recall = 0.1466, Jaccard score = 0.1231, loss = 0.4126, eval: [6.9 s]
# Iteration 19 fit: [10.8 s]: Recall = 0.1504, Jaccard score = 0.1267, loss = 0.4113, eval: [6.8 s]
# Iteration 20 fit: [10.8 s]: Recall = 0.1488, Jaccard score = 0.1252, loss = 0.4106, eval: [6.9 s]
# Iteration 21 fit: [10.8 s]: Recall = 0.1497, Jaccard score = 0.1260, loss = 0.4095, eval: [6.9 s]
# Iteration 22 fit: [10.8 s]: Recall = 0.1500, Jaccard score = 0.1264, loss = 0.4090, eval: [6.9 s]
# Iteration 23 fit: [10.8 s]: Recall = 0.1511, Jaccard score = 0.1274, loss = 0.4080, eval: [6.9 s]
# Iteration 24 fit: [10.8 s]: Recall = 0.1520, Jaccard score = 0.1282, loss = 0.4076, eval: [6.8 s]
# Iteration 25 fit: [10.8 s]: Recall = 0.1553, Jaccard score = 0.1314, loss = 0.4066, eval: [6.9 s]
# Iteration 26 fit: [10.8 s]: Recall = 0.1536, Jaccard score = 0.1298, loss = 0.4061, eval: [6.9 s]
# Iteration 27 fit: [10.8 s]: Recall = 0.1515, Jaccard score = 0.1278, loss = 0.4054, eval: [6.9 s]
# Iteration 28 fit: [10.8 s]: Recall = 0.1552, Jaccard score = 0.1313, loss = 0.4049, eval: [6.8 s]
# Iteration 29 fit: [10.8 s]: Recall = 0.1564, Jaccard score = 0.1325, loss = 0.4038, eval: [6.9 s]
# Iteration 30 fit: [10.8 s]: Recall = 0.1546, Jaccard score = 0.1308, loss = 0.4031, eval: [6.9 s]
# Iteration 31 fit: [10.8 s]: Recall = 0.1569, Jaccard score = 0.1330, loss = 0.4027, eval: [6.9 s]
# Iteration 32 fit: [10.8 s]: Recall = 0.1559, Jaccard score = 0.1319, loss = 0.4017, eval: [6.9 s]
# Iteration 33 fit: [10.8 s]: Recall = 0.1575, Jaccard score = 0.1336, loss = 0.4010, eval: [6.9 s]
# Iteration 34 fit: [10.8 s]: Recall = 0.1591, Jaccard score = 0.1351, loss = 0.4006, eval: [6.9 s]
# Iteration 35 fit: [10.8 s]: Recall = 0.1560, Jaccard score = 0.1321, loss = 0.3995, eval: [7.0 s]
# Iteration 36 fit: [10.8 s]: Recall = 0.1564, Jaccard score = 0.1324, loss = 0.3990, eval: [6.9 s]
# Iteration 37 fit: [10.8 s]: Recall = 0.1612, Jaccard score = 0.1371, loss = 0.3986, eval: [6.9 s]
# Iteration 38 fit: [10.8 s]: Recall = 0.1578, Jaccard score = 0.1338, loss = 0.3976, eval: [6.9 s]
# Iteration 39 fit: [10.8 s]: Recall = 0.1611, Jaccard score = 0.1370, loss = 0.3972, eval: [6.9 s]
# Iteration 40 fit: [10.8 s]: Recall = 0.1636, Jaccard score = 0.1394, loss = 0.3968, eval: [6.8 s]
# Iteration 41 fit: [10.8 s]: Recall = 0.1625, Jaccard score = 0.1383, loss = 0.3957, eval: [6.9 s]
# Iteration 42 fit: [10.8 s]: Recall = 0.1606, Jaccard score = 0.1365, loss = 0.3948, eval: [6.8 s]
# Iteration 43 fit: [10.8 s]: Recall = 0.1637, Jaccard score = 0.1395, loss = 0.3947, eval: [6.9 s]
# Iteration 44 fit: [10.8 s]: Recall = 0.1637, Jaccard score = 0.1395, loss = 0.3944, eval: [6.9 s]
# Iteration 45 fit: [10.8 s]: Recall = 0.1632, Jaccard score = 0.1390, loss = 0.3934, eval: [6.7 s]
# Iteration 46 fit: [10.8 s]: Recall = 0.1643, Jaccard score = 0.1401, loss = 0.3926, eval: [6.8 s]
# Iteration 47 fit: [10.8 s]: Recall = 0.1633, Jaccard score = 0.1391, loss = 0.3918, eval: [6.9 s]
# Iteration 48 fit: [10.8 s]: Recall = 0.1633, Jaccard score = 0.1391, loss = 0.3913, eval: [6.8 s]
# Iteration 49 fit: [10.8 s]: Recall = 0.1652, Jaccard score = 0.1410, loss = 0.3910, eval: [6.9 s]
# Iteration 50 fit: [11.5 s]: Recall = 0.1624, Jaccard score = 0.1383, loss = 0.3904, eval: [7.0 s]
# Iteration 51 fit: [11.4 s]: Recall = 0.1642, Jaccard score = 0.1400, loss = 0.3897, eval: [6.9 s]
# Iteration 52 fit: [10.8 s]: Recall = 0.1670, Jaccard score = 0.1428, loss = 0.3892, eval: [6.9 s]
# Iteration 53 fit: [10.8 s]: Recall = 0.1670, Jaccard score = 0.1428, loss = 0.3884, eval: [6.9 s]
# Iteration 54 fit: [10.8 s]: Recall = 0.1648, Jaccard score = 0.1406, loss = 0.3881, eval: [6.8 s]
# Iteration 55 fit: [10.8 s]: Recall = 0.1662, Jaccard score = 0.1420, loss = 0.3874, eval: [6.9 s]
# Iteration 56 fit: [10.8 s]: Recall = 0.1683, Jaccard score = 0.1440, loss = 0.3866, eval: [6.7 s]
# Iteration 57 fit: [11.2 s]: Recall = 0.1662, Jaccard score = 0.1419, loss = 0.3864, eval: [8.7 s]
# Iteration 58 fit: [11.7 s]: Recall = 0.1683, Jaccard score = 0.1440, loss = 0.3856, eval: [7.1 s]
# Iteration 59 fit: [13.4 s]: Recall = 0.1684, Jaccard score = 0.1441, loss = 0.3853, eval: [6.9 s]
# Iteration 60 fit: [10.8 s]: Recall = 0.1706, Jaccard score = 0.1462, loss = 0.3847, eval: [6.8 s]
# Iteration 61 fit: [10.8 s]: Recall = 0.1695, Jaccard score = 0.1452, loss = 0.3843, eval: [6.8 s]
# Iteration 62 fit: [10.8 s]: Recall = 0.1707, Jaccard score = 0.1463, loss = 0.3840, eval: [6.9 s]
# Iteration 63 fit: [10.8 s]: Recall = 0.1700, Jaccard score = 0.1457, loss = 0.3830, eval: [6.9 s]
# Iteration 64 fit: [10.8 s]: Recall = 0.1700, Jaccard score = 0.1457, loss = 0.3824, eval: [6.7 s]
# Iteration 65 fit: [10.8 s]: Recall = 0.1689, Jaccard score = 0.1446, loss = 0.3822, eval: [6.9 s]
# Iteration 66 fit: [10.8 s]: Recall = 0.1744, Jaccard score = 0.1500, loss = 0.3819, eval: [6.7 s]
# Iteration 67 fit: [10.8 s]: Recall = 0.1703, Jaccard score = 0.1460, loss = 0.3820, eval: [6.9 s]
# Iteration 68 fit: [10.8 s]: Recall = 0.1743, Jaccard score = 0.1499, loss = 0.3805, eval: [6.9 s]
# Iteration 69 fit: [10.8 s]: Recall = 0.1709, Jaccard score = 0.1466, loss = 0.3805, eval: [6.8 s]
# Iteration 70 fit: [10.8 s]: Recall = 0.1727, Jaccard score = 0.1483, loss = 0.3794, eval: [6.8 s]
# Iteration 71 fit: [11.2 s]: Recall = 0.1713, Jaccard score = 0.1469, loss = 0.3798, eval: [6.8 s]
# Iteration 72 fit: [10.8 s]: Recall = 0.1739, Jaccard score = 0.1495, loss = 0.3792, eval: [6.9 s]
# Iteration 73 fit: [10.8 s]: Recall = 0.1706, Jaccard score = 0.1463, loss = 0.3787, eval: [6.9 s]
# Iteration 74 fit: [10.8 s]: Recall = 0.1736, Jaccard score = 0.1492, loss = 0.3783, eval: [6.9 s]
# Iteration 75 fit: [10.8 s]: Recall = 0.1748, Jaccard score = 0.1504, loss = 0.3777, eval: [6.9 s]
# Iteration 76 fit: [10.8 s]: Recall = 0.1737, Jaccard score = 0.1493, loss = 0.3770, eval: [6.9 s]
# Iteration 77 fit: [10.8 s]: Recall = 0.1735, Jaccard score = 0.1492, loss = 0.3772, eval: [6.9 s]
# Iteration 78 fit: [10.8 s]: Recall = 0.1748, Jaccard score = 0.1504, loss = 0.3767, eval: [6.9 s]
# Iteration 79 fit: [10.8 s]: Recall = 0.1741, Jaccard score = 0.1497, loss = 0.3767, eval: [6.9 s]
# Iteration 80 fit: [10.8 s]: Recall = 0.1741, Jaccard score = 0.1497, loss = 0.3757, eval: [6.9 s]
# Iteration 81 fit: [10.8 s]: Recall = 0.1732, Jaccard score = 0.1488, loss = 0.3754, eval: [6.8 s]
# Iteration 82 fit: [10.8 s]: Recall = 0.1748, Jaccard score = 0.1504, loss = 0.3753, eval: [6.9 s]
# Iteration 83 fit: [10.8 s]: Recall = 0.1760, Jaccard score = 0.1516, loss = 0.3747, eval: [6.9 s]
# Iteration 84 fit: [10.8 s]: Recall = 0.1759, Jaccard score = 0.1514, loss = 0.3745, eval: [6.9 s]
# Iteration 85 fit: [10.8 s]: Recall = 0.1746, Jaccard score = 0.1502, loss = 0.3738, eval: [6.8 s]
# Iteration 86 fit: [10.8 s]: Recall = 0.1770, Jaccard score = 0.1525, loss = 0.3742, eval: [6.9 s]
# Iteration 87 fit: [10.8 s]: Recall = 0.1762, Jaccard score = 0.1518, loss = 0.3737, eval: [6.9 s]
# Iteration 88 fit: [10.8 s]: Recall = 0.1747, Jaccard score = 0.1503, loss = 0.3732, eval: [6.9 s]
# Iteration 89 fit: [10.8 s]: Recall = 0.1750, Jaccard score = 0.1506, loss = 0.3728, eval: [6.9 s]
# Iteration 90 fit: [10.8 s]: Recall = 0.1757, Jaccard score = 0.1513, loss = 0.3728, eval: [6.9 s]
# Iteration 91 fit: [10.8 s]: Recall = 0.1751, Jaccard score = 0.1507, loss = 0.3717, eval: [6.9 s]
# Iteration 92 fit: [10.8 s]: Recall = 0.1760, Jaccard score = 0.1516, loss = 0.3716, eval: [6.9 s]
# Iteration 93 fit: [10.8 s]: Recall = 0.1770, Jaccard score = 0.1525, loss = 0.3713, eval: [6.9 s]
# Iteration 94 fit: [10.8 s]: Recall = 0.1756, Jaccard score = 0.1512, loss = 0.3711, eval: [6.9 s]
# Iteration 95 fit: [10.8 s]: Recall = 0.1761, Jaccard score = 0.1517, loss = 0.3708, eval: [6.9 s]
# Iteration 96 fit: [10.8 s]: Recall = 0.1770, Jaccard score = 0.1526, loss = 0.3703, eval: [7.0 s]
# Iteration 97 fit: [10.8 s]: Recall = 0.1776, Jaccard score = 0.1532, loss = 0.3702, eval: [6.8 s]
# Iteration 98 fit: [10.8 s]: Recall = 0.1761, Jaccard score = 0.1517, loss = 0.3691, eval: [6.9 s]
# Iteration 99 fit: [10.8 s]: Recall = 0.1756, Jaccard score = 0.1512, loss = 0.3695, eval: [6.9 s]
# Iteration 100 fit: [10.8 s]: Recall = 0.1788, Jaccard score = 0.1543, loss = 0.3690, eval: [6.9 s]
# Iteration 101 fit: [10.8 s]: Recall = 0.1796, Jaccard score = 0.1552, loss = 0.3694, eval: [6.9 s]
# Iteration 102 fit: [10.8 s]: Recall = 0.1792, Jaccard score = 0.1548, loss = 0.3687, eval: [6.9 s]
# Iteration 103 fit: [10.8 s]: Recall = 0.1761, Jaccard score = 0.1517, loss = 0.3684, eval: [6.9 s]
# Iteration 104 fit: [10.8 s]: Recall = 0.1783, Jaccard score = 0.1539, loss = 0.3680, eval: [6.9 s]
# Iteration 105 fit: [10.8 s]: Recall = 0.1796, Jaccard score = 0.1552, loss = 0.3678, eval: [6.8 s]
# Iteration 106 fit: [10.8 s]: Recall = 0.1789, Jaccard score = 0.1545, loss = 0.3675, eval: [6.9 s]
# Iteration 107 fit: [10.8 s]: Recall = 0.1788, Jaccard score = 0.1543, loss = 0.3676, eval: [6.8 s]
# Iteration 108 fit: [10.8 s]: Recall = 0.1789, Jaccard score = 0.1545, loss = 0.3669, eval: [6.9 s]
# Iteration 109 fit: [10.8 s]: Recall = 0.1807, Jaccard score = 0.1563, loss = 0.3663, eval: [6.9 s]
# Iteration 110 fit: [10.8 s]: Recall = 0.1788, Jaccard score = 0.1543, loss = 0.3659, eval: [6.9 s]
# Iteration 111 fit: [10.8 s]: Recall = 0.1759, Jaccard score = 0.1514, loss = 0.3659, eval: [6.9 s]
# Iteration 112 fit: [10.8 s]: Recall = 0.1771, Jaccard score = 0.1527, loss = 0.3659, eval: [6.9 s]
# Iteration 113 fit: [10.8 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.3659, eval: [6.9 s]
# Iteration 114 fit: [10.8 s]: Recall = 0.1780, Jaccard score = 0.1536, loss = 0.3653, eval: [6.9 s]
# Iteration 115 fit: [10.8 s]: Recall = 0.1788, Jaccard score = 0.1543, loss = 0.3650, eval: [6.9 s]
# Iteration 116 fit: [10.8 s]: Recall = 0.1810, Jaccard score = 0.1565, loss = 0.3646, eval: [6.8 s]
# Iteration 117 fit: [10.8 s]: Recall = 0.1780, Jaccard score = 0.1536, loss = 0.3645, eval: [6.9 s]
# Iteration 118 fit: [10.8 s]: Recall = 0.1793, Jaccard score = 0.1549, loss = 0.3642, eval: [6.9 s]
# Iteration 119 fit: [10.8 s]: Recall = 0.1815, Jaccard score = 0.1570, loss = 0.3637, eval: [6.9 s]
# Iteration 120 fit: [10.8 s]: Recall = 0.1810, Jaccard score = 0.1565, loss = 0.3641, eval: [6.8 s]
# Iteration 121 fit: [10.8 s]: Recall = 0.1805, Jaccard score = 0.1561, loss = 0.3640, eval: [6.9 s]
# Iteration 122 fit: [10.8 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.3633, eval: [7.0 s]
# Iteration 123 fit: [10.8 s]: Recall = 0.1809, Jaccard score = 0.1564, loss = 0.3632, eval: [6.9 s]
# Iteration 124 fit: [10.8 s]: Recall = 0.1819, Jaccard score = 0.1575, loss = 0.3630, eval: [6.8 s]
# Iteration 125 fit: [10.8 s]: Recall = 0.1800, Jaccard score = 0.1555, loss = 0.3626, eval: [7.0 s]
# Iteration 126 fit: [10.8 s]: Recall = 0.1786, Jaccard score = 0.1542, loss = 0.3622, eval: [6.8 s]
# Iteration 127 fit: [10.8 s]: Recall = 0.1791, Jaccard score = 0.1546, loss = 0.3622, eval: [6.9 s]
# Iteration 128 fit: [10.8 s]: Recall = 0.1778, Jaccard score = 0.1534, loss = 0.3617, eval: [6.7 s]
# Iteration 129 fit: [10.8 s]: Recall = 0.1829, Jaccard score = 0.1585, loss = 0.3619, eval: [6.9 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565689108.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565689108.h5
# Load data done [4.2 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565692887.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565692887.h5
# Load data done [4.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565693171.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565693171.h5
# Load data done [3.9 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565693352.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565693352.h5
# Load data done [4.3 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565693578.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565693578.h5
# Load data done [4.2 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565693630.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565693630.h5
# Load data done [4.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.


# Launched by terminal.


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565693752.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565693752.h5
# Load data done [4.4 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565693832.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565693832.h5
# Load data done [3.9 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565697283.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565697283.h5
# Load data done [3.9 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# airplane fuselage
# airplane wing
# almond tree
# amusement park
# aquatic bird
# armored vehicle
# art gallery
# assembly hall
# athletic game
# auto racing
# ball game
# bicycle seat
# bicycle wheel
# big cat
# bike pedal
# billiard room
# bird feeder
# bird of prey
# black background
# blackandwhite
# boat racing
# branchlet
# brass instrument
# breakfast table
# brick red
# bridal veil
# building complex
# building structure
# bumper car
# cable car
# canal boat
# cantilever bridge
# car bumper
# car engine
# car grille
# car hood
# car interior
# car mirror
# car part
# car rally
# car seat
# car tire
# car wheel
# cargo container
# carthorse
# cherry blossom
# cliff diving
# cliff dwelling
# clock tower
# comic book
# computer keyboard
# computer monitor
# computer screen
# concert band
# conference table
# contact sport
# container ship
# control panel
# country house
# court game
# crew boat
# cross-country skiing
# cruise ship
# dark red
# department store
# depth of field
# digital display
# dining room
# dining table
# dinner table
# display screen
# display window
# dome building
# door knocker
# draft horse
# dust storm
# electric locomotive
# farm machine
# farmer's market
# feather boa
# ferris wheel
# field game
# field hockey
# field house
# fighter jet
# figure skating
# fire truck
# flower cluster
# flying buttress
# football helmet
# formal wear
# four wheel drive
# freight car
# french window
# fuel injection
# full moon
# fur hat
# gable roof
# goal net
# golden retriever
# golf cart
# golf club
# gothic arch
# grainfield
# great hall
# grocery store
# group performance
# groupshot
# gym weights
# hand rail
# hang glider
# high jump
# horse cart
# horse ranch
# horseback riding
# hot air balloon
# hour hand
# ice hockey
# ice rink
# ice skating
# interior door
# jack-o-lantern
# jumbo jet
# jungle gym
# keyboard instrument
# kitchen ware
# lecture hall
# life jacket
# light painting
# meeting room
# military officer
# military vehicle
# minute hand
# mixed drink
# motor scooter
# mountain bike
# mountain peak
# mountain ridge
# neon light
# newel post
# nissen hut
# ocean floor
# ocean liner
# office furniture
# oil lamp
# onion dome
# open air market
# orange daisy
# organ instrument
# organ loft
# organic pattern
# outdoor sport
# palm tree
# park bench
# passenger ship
# pedestrian crossing
# percussion instrument
# photo border
# photomicrograph
# piano keyboard
# picture frame
# pink flower
# pointed arch
# portable computer
# potted plant
# power line
# race car
# radiogram
# railroad track
# reading lamp
# recreational vehicle
# red maple
# reddish brown
# rock climbing
# rock formation
# rock wall
# roller coaster
# roller skate
# roller skating
# roman arch
# room light
# rope bridge
# rose window
# rotor blade
# round arch
# row house
# rowing boat
# saddle horse
# sail boat
# salad bar
# school bus
# scuba diver
# scuba diving
# sea lion
# seat belt
# shelf stacks
# shipping container
# ski pole
# skin diving
# snack bar
# solar array
# solar cell
# speed skate
# spider web
# sport fight
# sports car
# stained glass
# star shape
# steam engine
# steel arch bridge
# steering wheel
# stemma
# stock car
# stone wall
# store shelf
# street sign
# stringed instrument
# study hall
# study room
# sumo wrestling
# sun parlor
# sunbath
# support column
# swimming pool
# swimming trunks
# team sport
# telephone booth
# telephone pole
# telephone wire
# trail bike
# urban decay
# vigil light
# volcanic crater
# water ski
# water skiing
# water sport
# wheel spoke
# white background
# whitewater rafting
# wind turbine
# window box
# window frame
# wine cellar
# wood fence
# wood laminate
# blackandwhite
# branchlet
# carthorse
# farmer's market
# grainfield
# groupshot
# jack-o-lantern
# photomicrograph
# radiogram
# stemma
# sunbath


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565699748.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565699748.h5
# Load data done [3.9 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565699819.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565699819.h5
# Load data done [4.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565700410.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565700410.h5
# Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565700486.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565700486.h5
# Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# embedding_1 (Embedding)         (None, 1000, 100)    100000      user_features[0][0]              
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 16)        32000       item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 100000)       0           embedding_1[0][0]                
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 16)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 100016)       0           flatten_3[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 16)           1600272     concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 16)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            17          activation_1[0][0]               
# ==================================================================================================
# Total params: 1,732,289
# Trainable params: 1,632,289
# Non-trainable params: 100,000
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0279, Jaccard score = 0.0213
# Iteration 0 fit: [30.7 s]: Recall = 0.0543, Jaccard score = 0.0424, loss = 0.5030, eval: [11.6 s]
# Iteration 1 fit: [30.9 s]: Recall = 0.0846, Jaccard score = 0.0676, loss = 0.4989, eval: [11.7 s]
# Iteration 2 fit: [31.4 s]: Recall = 0.1030, Jaccard score = 0.0835, loss = 0.4901, eval: [10.6 s]
# Iteration 3 fit: [30.6 s]: Recall = 0.1175, Jaccard score = 0.0963, loss = 0.4746, eval: [11.2 s]
# Iteration 4 fit: [32.3 s]: Recall = 0.1226, Jaccard score = 0.1010, loss = 0.4610, eval: [11.0 s]
# Iteration 5 fit: [31.6 s]: Recall = 0.1161, Jaccard score = 0.0951, loss = 0.4529, eval: [10.8 s]
# Iteration 6 fit: [31.4 s]: Recall = 0.1274, Jaccard score = 0.1053, loss = 0.4469, eval: [11.0 s]
# Iteration 7 fit: [31.7 s]: Recall = 0.1180, Jaccard score = 0.0968, loss = 0.4418, eval: [10.8 s]
# Iteration 8 fit: [32.0 s]: Recall = 0.1270, Jaccard score = 0.1049, loss = 0.4387, eval: [11.2 s]
# Iteration 9 fit: [31.9 s]: Recall = 0.1220, Jaccard score = 0.1004, loss = 0.4352, eval: [11.5 s]
# Iteration 10 fit: [32.1 s]: Recall = 0.1238, Jaccard score = 0.1020, loss = 0.4323, eval: [10.9 s]
# Iteration 11 fit: [32.5 s]: Recall = 0.1321, Jaccard score = 0.1097, loss = 0.4300, eval: [12.1 s]
# Iteration 12 fit: [30.7 s]: Recall = 0.1171, Jaccard score = 0.0960, loss = 0.4289, eval: [11.4 s]
# Iteration 13 fit: [31.9 s]: Recall = 0.1276, Jaccard score = 0.1055, loss = 0.4276, eval: [11.3 s]
# Iteration 14 fit: [32.0 s]: Recall = 0.1282, Jaccard score = 0.1060, loss = 0.4267, eval: [11.1 s]
# Iteration 15 fit: [29.5 s]: Recall = 0.1262, Jaccard score = 0.1043, loss = 0.4252, eval: [10.8 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565701214.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565701214.h5
# Load data done [4.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565709766.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565709766.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565777031.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565777031.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565785286.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565785286.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565785345.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565785345.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565785361.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565785361.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565786201.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565786201.h5
# Load data done [8.1 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565786219.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565786219.h5
# Load data done [8.3 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# embedding_1 (Embedding)         (None, 1000, 100)    100000      user_features[0][0]              
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 16)        32000       item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 100000)       0           embedding_1[0][0]                
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 16)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 100016)       0           flatten_3[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 16)           1600272     concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 16)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            17          activation_1[0][0]               
# ==================================================================================================
# Total params: 1,732,289
# Trainable params: 1,632,289
# Non-trainable params: 100,000
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565786278.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565786278.h5
# Load data done [8.9 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565786489.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565786489.h5
# Load data done [8.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_features (InputLayer)      (None, 77)           0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# embedding_1 (Embedding)         (None, 77, 100)      100000      user_features[0][0]              
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 16)        32000       item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 7700)         0           embedding_1[0][0]                
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 16)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 7716)         0           flatten_3[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 16)           123472      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 16)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            17          activation_1[0][0]               
# ==================================================================================================
# Total params: 255,489
# Trainable params: 155,489
# Non-trainable params: 100,000
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0278, Jaccard score = 0.0212


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565786595.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565786595.h5
# Load data done [4.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_features (InputLayer)      (None, 77)           0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# embedding_1 (Embedding)         (None, 77, 100)      100000      user_features[0][0]              
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 16)        32000       item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_3 (Flatten)             (None, 7700)         0           embedding_1[0][0]                
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 16)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 7716)         0           flatten_3[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 16)           123472      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 16)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            17          activation_1[0][0]               
# ==================================================================================================
# Total params: 255,489
# Trainable params: 155,489
# Non-trainable params: 100,000
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0300, Jaccard score = 0.0230
# Iteration 0 fit: [10.3 s]: Recall = 0.0554, Jaccard score = 0.0432, loss = 0.4994, eval: [10.2 s]
# Iteration 1 fit: [7.0 s]: Recall = 0.0797, Jaccard score = 0.0634, loss = 0.4898, eval: [10.1 s]
# Iteration 2 fit: [7.0 s]: Recall = 0.1013, Jaccard score = 0.0820, loss = 0.4777, eval: [10.1 s]
# Iteration 3 fit: [7.1 s]: Recall = 0.1137, Jaccard score = 0.0929, loss = 0.4666, eval: [10.1 s]
# Iteration 4 fit: [7.0 s]: Recall = 0.1210, Jaccard score = 0.0995, loss = 0.4572, eval: [10.1 s]
# Iteration 5 fit: [7.0 s]: Recall = 0.1241, Jaccard score = 0.1023, loss = 0.4493, eval: [10.2 s]
# Iteration 6 fit: [7.0 s]: Recall = 0.1298, Jaccard score = 0.1075, loss = 0.4433, eval: [10.2 s]
# Iteration 7 fit: [7.0 s]: Recall = 0.1281, Jaccard score = 0.1060, loss = 0.4380, eval: [10.2 s]
# Iteration 8 fit: [7.1 s]: Recall = 0.1198, Jaccard score = 0.0984, loss = 0.4342, eval: [10.1 s]
# Iteration 9 fit: [7.0 s]: Recall = 0.1301, Jaccard score = 0.1078, loss = 0.4314, eval: [10.1 s]
# Iteration 10 fit: [7.0 s]: Recall = 0.1309, Jaccard score = 0.1085, loss = 0.4294, eval: [10.1 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565787115.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565787115.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565787141.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565787141.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565787198.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565787198.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565787619.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565787619.h5
# Load data done [12.4 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 77)           0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 16)        32000       item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 1024)         79872       user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 16)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1040)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 16)           16656       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 16)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            17          activation_1[0][0]               
# ==================================================================================================
# Total params: 128,545
# Trainable params: 128,545
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,16]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[32,16]_1565787966.h5
--weights_path: Pretrain/_MLP_8_[32,16]_1565787966.h5
# Load data done [13.3 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 100)          0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 16)        32000       item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 1024)         103424      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 16)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1040)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 16)           16656       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 16)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            17          activation_1[0][0]               
# ==================================================================================================
# Total params: 152,097
# Trainable params: 152,097
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0254, Jaccard score = 0.0194
# Iteration 0 fit: [8.4 s]: Recall = 0.0406, Jaccard score = 0.0313, loss = 0.5189, eval: [9.6 s]
# Iteration 1 fit: [7.5 s]: Recall = 0.0649, Jaccard score = 0.0510, loss = 0.4996, eval: [9.6 s]
# Iteration 2 fit: [7.5 s]: Recall = 0.0971, Jaccard score = 0.0783, loss = 0.4876, eval: [9.5 s]
# Iteration 3 fit: [7.5 s]: Recall = 0.1173, Jaccard score = 0.0961, loss = 0.4751, eval: [9.5 s]
# Iteration 4 fit: [7.5 s]: Recall = 0.1225, Jaccard score = 0.1009, loss = 0.4652, eval: [9.5 s]
# Iteration 5 fit: [7.5 s]: Recall = 0.1268, Jaccard score = 0.1048, loss = 0.4566, eval: [9.5 s]
# Iteration 6 fit: [7.5 s]: Recall = 0.1264, Jaccard score = 0.1044, loss = 0.4498, eval: [9.5 s]
# Iteration 7 fit: [7.5 s]: Recall = 0.1237, Jaccard score = 0.1019, loss = 0.4440, eval: [9.5 s]
# Iteration 8 fit: [7.6 s]: Recall = 0.1259, Jaccard score = 0.1040, loss = 0.4391, eval: [9.7 s]
# Iteration 9 fit: [7.5 s]: Recall = 0.1254, Jaccard score = 0.1035, loss = 0.4351, eval: [9.5 s]
# Iteration 10 fit: [7.5 s]: Recall = 0.1293, Jaccard score = 0.1071, loss = 0.4323, eval: [9.5 s]
# Iteration 11 fit: [7.5 s]: Recall = 0.1284, Jaccard score = 0.1062, loss = 0.4293, eval: [9.9 s]
# Iteration 12 fit: [7.6 s]: Recall = 0.1331, Jaccard score = 0.1105, loss = 0.4277, eval: [9.6 s]
# Iteration 13 fit: [7.6 s]: Recall = 0.1275, Jaccard score = 0.1054, loss = 0.4264, eval: [9.6 s]
# Iteration 14 fit: [7.6 s]: Recall = 0.1327, Jaccard score = 0.1102, loss = 0.4251, eval: [9.6 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[256,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[256,128]_1565788257.h5
--weights_path: Pretrain/_MLP_8_[256,128]_1565788257.h5
# Load data done [12.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 100)          0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 128)       256000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 1024)         103424      user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 128)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1152)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          147584      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 507,137
# Trainable params: 507,137
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0290, Jaccard score = 0.0222
# Iteration 0 fit: [8.7 s]: Recall = 0.1244, Jaccard score = 0.1026, loss = 0.4936, eval: [9.5 s]
# Iteration 1 fit: [7.8 s]: Recall = 0.1376, Jaccard score = 0.1148, loss = 0.4550, eval: [9.5 s]
# Iteration 2 fit: [7.9 s]: Recall = 0.1440, Jaccard score = 0.1207, loss = 0.4370, eval: [9.5 s]
# Iteration 3 fit: [7.9 s]: Recall = 0.1502, Jaccard score = 0.1265, loss = 0.4276, eval: [9.5 s]
# Iteration 4 fit: [7.9 s]: Recall = 0.1588, Jaccard score = 0.1348, loss = 0.4212, eval: [9.5 s]
# Iteration 5 fit: [7.9 s]: Recall = 0.1601, Jaccard score = 0.1360, loss = 0.4163, eval: [9.5 s]
# Iteration 6 fit: [7.9 s]: Recall = 0.1673, Jaccard score = 0.1430, loss = 0.4116, eval: [9.5 s]
# Iteration 7 fit: [7.9 s]: Recall = 0.1700, Jaccard score = 0.1456, loss = 0.4078, eval: [9.5 s]
# Iteration 8 fit: [7.9 s]: Recall = 0.1745, Jaccard score = 0.1501, loss = 0.4039, eval: [9.5 s]
# Iteration 9 fit: [7.9 s]: Recall = 0.1789, Jaccard score = 0.1545, loss = 0.4002, eval: [9.5 s]
# Iteration 10 fit: [7.9 s]: Recall = 0.1788, Jaccard score = 0.1544, loss = 0.3965, eval: [9.5 s]
# Iteration 11 fit: [7.9 s]: Recall = 0.1810, Jaccard score = 0.1566, loss = 0.3935, eval: [9.5 s]
# Iteration 12 fit: [7.9 s]: Recall = 0.1817, Jaccard score = 0.1573, loss = 0.3901, eval: [9.5 s]
# Iteration 13 fit: [7.8 s]: Recall = 0.1881, Jaccard score = 0.1637, loss = 0.3871, eval: [9.5 s]
# Iteration 14 fit: [7.8 s]: Recall = 0.1877, Jaccard score = 0.1633, loss = 0.3837, eval: [9.5 s]
# Iteration 15 fit: [7.8 s]: Recall = 0.1891, Jaccard score = 0.1647, loss = 0.3811, eval: [9.5 s]
# Iteration 16 fit: [7.9 s]: Recall = 0.1905, Jaccard score = 0.1661, loss = 0.3792, eval: [9.9 s]
# Iteration 17 fit: [7.9 s]: Recall = 0.1893, Jaccard score = 0.1650, loss = 0.3764, eval: [9.6 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[256,128]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[256,128]_1565788611.h5
--weights_path: Pretrain/_MLP_8_[256,128]_1565788611.h5
# Load data done [13.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 100)          0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 128)       256000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 256)          25856       user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 128)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 384)          0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          49280       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 331,265
# Trainable params: 331,265
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0290, Jaccard score = 0.0222
# Iteration 0 fit: [8.3 s]: Recall = 0.1192, Jaccard score = 0.0979, loss = 0.5016, eval: [9.5 s]
# Iteration 1 fit: [7.5 s]: Recall = 0.1524, Jaccard score = 0.1286, loss = 0.4543, eval: [9.5 s]
# Iteration 2 fit: [7.5 s]: Recall = 0.1607, Jaccard score = 0.1366, loss = 0.4301, eval: [9.5 s]
# Iteration 3 fit: [7.5 s]: Recall = 0.1682, Jaccard score = 0.1439, loss = 0.4173, eval: [9.5 s]
# Iteration 4 fit: [7.5 s]: Recall = 0.1738, Jaccard score = 0.1494, loss = 0.4088, eval: [9.5 s]
# Iteration 5 fit: [7.4 s]: Recall = 0.1766, Jaccard score = 0.1522, loss = 0.4026, eval: [9.5 s]
# Iteration 6 fit: [7.5 s]: Recall = 0.1775, Jaccard score = 0.1531, loss = 0.3979, eval: [9.5 s]
# Iteration 7 fit: [7.4 s]: Recall = 0.1841, Jaccard score = 0.1597, loss = 0.3931, eval: [9.5 s]
# Iteration 8 fit: [7.5 s]: Recall = 0.1842, Jaccard score = 0.1598, loss = 0.3897, eval: [9.5 s]
# Iteration 9 fit: [7.4 s]: Recall = 0.1856, Jaccard score = 0.1612, loss = 0.3857, eval: [9.5 s]
# Iteration 10 fit: [7.5 s]: Recall = 0.1891, Jaccard score = 0.1647, loss = 0.3819, eval: [9.5 s]
# Iteration 11 fit: [7.4 s]: Recall = 0.1886, Jaccard score = 0.1642, loss = 0.3790, eval: [9.5 s]
# Iteration 12 fit: [7.5 s]: Recall = 0.1948, Jaccard score = 0.1706, loss = 0.3766, eval: [9.5 s]
# Iteration 13 fit: [7.5 s]: Recall = 0.1935, Jaccard score = 0.1692, loss = 0.3735, eval: [9.7 s]
# Iteration 14 fit: [7.5 s]: Recall = 0.1932, Jaccard score = 0.1689, loss = 0.3709, eval: [9.6 s]
# Iteration 15 fit: [7.5 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3688, eval: [9.7 s]
# Iteration 16 fit: [7.5 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3657, eval: [9.7 s]
# Iteration 17 fit: [7.5 s]: Recall = 0.1975, Jaccard score = 0.1733, loss = 0.3644, eval: [9.6 s]
# Iteration 18 fit: [7.6 s]: Recall = 0.1960, Jaccard score = 0.1718, loss = 0.3623, eval: [9.5 s]
# Iteration 19 fit: [7.4 s]: Recall = 0.1972, Jaccard score = 0.1730, loss = 0.3605, eval: [9.5 s]
# Iteration 20 fit: [7.6 s]: Recall = 0.1987, Jaccard score = 0.1746, loss = 0.3587, eval: [9.5 s]
# Iteration 21 fit: [7.4 s]: Recall = 0.1961, Jaccard score = 0.1719, loss = 0.3574, eval: [9.6 s]
# Iteration 22 fit: [7.7 s]: Recall = 0.1984, Jaccard score = 0.1742, loss = 0.3561, eval: [9.7 s]
# Iteration 23 fit: [7.5 s]: Recall = 0.2024, Jaccard score = 0.1783, loss = 0.3545, eval: [9.6 s]
# Iteration 24 fit: [7.5 s]: Recall = 0.1988, Jaccard score = 0.1747, loss = 0.3531, eval: [9.6 s]
# Iteration 25 fit: [7.5 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3517, eval: [9.6 s]
# Iteration 26 fit: [7.5 s]: Recall = 0.2002, Jaccard score = 0.1761, loss = 0.3509, eval: [9.5 s]
# Iteration 27 fit: [7.5 s]: Recall = 0.2006, Jaccard score = 0.1765, loss = 0.3494, eval: [9.5 s]
# Iteration 28 fit: [7.5 s]: Recall = 0.2015, Jaccard score = 0.1775, loss = 0.3480, eval: [9.5 s]
# Iteration 29 fit: [7.5 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3473, eval: [9.9 s]
# Iteration 30 fit: [7.5 s]: Recall = 0.2014, Jaccard score = 0.1774, loss = 0.3464, eval: [9.5 s]
# Iteration 31 fit: [7.5 s]: Recall = 0.2029, Jaccard score = 0.1789, loss = 0.3456, eval: [9.5 s]
# Iteration 32 fit: [7.5 s]: Recall = 0.2004, Jaccard score = 0.1763, loss = 0.3438, eval: [9.5 s]
# Iteration 33 fit: [7.4 s]: Recall = 0.2028, Jaccard score = 0.1788, loss = 0.3437, eval: [9.5 s]
# Iteration 34 fit: [7.5 s]: Recall = 0.2005, Jaccard score = 0.1764, loss = 0.3420, eval: [9.5 s]
# Iteration 35 fit: [7.4 s]: Recall = 0.2015, Jaccard score = 0.1775, loss = 0.3414, eval: [9.5 s]
# Iteration 36 fit: [7.4 s]: Recall = 0.2011, Jaccard score = 0.1770, loss = 0.3402, eval: [9.5 s]
# Iteration 37 fit: [7.4 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3397, eval: [9.5 s]
# Iteration 38 fit: [7.4 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3392, eval: [9.5 s]
# Iteration 39 fit: [7.4 s]: Recall = 0.2035, Jaccard score = 0.1795, loss = 0.3383, eval: [9.5 s]
# Iteration 40 fit: [7.4 s]: Recall = 0.2012, Jaccard score = 0.1772, loss = 0.3376, eval: [9.5 s]
# Iteration 41 fit: [7.5 s]: Recall = 0.2028, Jaccard score = 0.1788, loss = 0.3364, eval: [9.6 s]
# Iteration 42 fit: [7.5 s]: Recall = 0.2029, Jaccard score = 0.1789, loss = 0.3361, eval: [9.5 s]
# Iteration 43 fit: [7.5 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.3356, eval: [9.5 s]
# Iteration 44 fit: [7.5 s]: Recall = 0.2025, Jaccard score = 0.1785, loss = 0.3350, eval: [9.5 s]
# Iteration 45 fit: [7.5 s]: Recall = 0.2028, Jaccard score = 0.1788, loss = 0.3341, eval: [9.5 s]
# Iteration 46 fit: [7.4 s]: Recall = 0.2039, Jaccard score = 0.1799, loss = 0.3335, eval: [9.6 s]
# Iteration 47 fit: [9.1 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3325, eval: [10.8 s]
# Iteration 48 fit: [7.5 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3327, eval: [9.5 s]
# Iteration 49 fit: [7.5 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3317, eval: [9.5 s]
# Iteration 50 fit: [7.4 s]: Recall = 0.2038, Jaccard score = 0.1798, loss = 0.3311, eval: [9.5 s]
# Iteration 51 fit: [7.4 s]: Recall = 0.2034, Jaccard score = 0.1794, loss = 0.3308, eval: [9.6 s]
# Iteration 52 fit: [7.5 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3304, eval: [9.4 s]
# Iteration 53 fit: [7.4 s]: Recall = 0.2029, Jaccard score = 0.1789, loss = 0.3293, eval: [9.5 s]
# Iteration 54 fit: [7.4 s]: Recall = 0.2025, Jaccard score = 0.1785, loss = 0.3287, eval: [9.5 s]
# Iteration 55 fit: [7.5 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.3284, eval: [9.5 s]
# Iteration 56 fit: [7.4 s]: Recall = 0.2054, Jaccard score = 0.1815, loss = 0.3278, eval: [9.5 s]
# Iteration 57 fit: [7.4 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3273, eval: [9.5 s]
# Iteration 58 fit: [7.4 s]: Recall = 0.2028, Jaccard score = 0.1788, loss = 0.3267, eval: [9.5 s]
# Iteration 59 fit: [7.4 s]: Recall = 0.2044, Jaccard score = 0.1804, loss = 0.3264, eval: [9.5 s]
# Iteration 60 fit: [7.5 s]: Recall = 0.2027, Jaccard score = 0.1786, loss = 0.3253, eval: [9.5 s]
# Iteration 61 fit: [7.4 s]: Recall = 0.2023, Jaccard score = 0.1782, loss = 0.3248, eval: [9.5 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,96]_1565789748.h5
--weights_path: Pretrain/_MLP_8_[512,96]_1565789748.h5
# Load data done [12.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 100)          0                                            
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 356)          0           user_features[0][0]              
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 96)           34272       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 96)           0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            97          activation_1[0][0]               
# ==================================================================================================
# Total params: 546,369
# Trainable params: 546,369
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0264, Jaccard score = 0.0201
# Iteration 0 fit: [8.4 s]: Recall = 0.1530, Jaccard score = 0.1292, loss = 0.4856, eval: [9.5 s]
# Iteration 1 fit: [7.7 s]: Recall = 0.1695, Jaccard score = 0.1452, loss = 0.4299, eval: [9.5 s]
# Iteration 2 fit: [7.7 s]: Recall = 0.1765, Jaccard score = 0.1520, loss = 0.4110, eval: [9.6 s]
# Iteration 3 fit: [7.7 s]: Recall = 0.1823, Jaccard score = 0.1578, loss = 0.4007, eval: [9.5 s]
# Iteration 4 fit: [7.7 s]: Recall = 0.1866, Jaccard score = 0.1622, loss = 0.3933, eval: [9.5 s]
# Iteration 5 fit: [7.7 s]: Recall = 0.1897, Jaccard score = 0.1653, loss = 0.3874, eval: [9.6 s]
# Iteration 6 fit: [7.7 s]: Recall = 0.1911, Jaccard score = 0.1667, loss = 0.3828, eval: [9.6 s]
# Iteration 7 fit: [7.7 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3784, eval: [9.5 s]
# Iteration 8 fit: [7.7 s]: Recall = 0.1945, Jaccard score = 0.1702, loss = 0.3744, eval: [9.5 s]
# Iteration 9 fit: [7.7 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3711, eval: [9.5 s]
# Iteration 10 fit: [7.7 s]: Recall = 0.1961, Jaccard score = 0.1719, loss = 0.3682, eval: [9.5 s]
# Iteration 11 fit: [7.7 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3653, eval: [9.5 s]
# Iteration 12 fit: [7.7 s]: Recall = 0.1968, Jaccard score = 0.1726, loss = 0.3628, eval: [9.5 s]
# Iteration 13 fit: [7.8 s]: Recall = 0.1968, Jaccard score = 0.1726, loss = 0.3605, eval: [9.5 s]
# Iteration 14 fit: [7.7 s]: Recall = 0.1996, Jaccard score = 0.1754, loss = 0.3582, eval: [9.5 s]
# Iteration 15 fit: [7.7 s]: Recall = 0.1996, Jaccard score = 0.1754, loss = 0.3566, eval: [9.5 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,256]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,256]_1565790064.h5
--weights_path: Pretrain/_MLP_8_[512,256]_1565790064.h5
# Load data done [12.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 100)          0                                            
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 356)          0           user_features[0][0]              
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 256)          91392       concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 256)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            257         activation_1[0][0]               
# ==================================================================================================
# Total params: 603,649
# Trainable params: 603,649
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0242, Jaccard score = 0.0184
# Iteration 0 fit: [8.5 s]: Recall = 0.1561, Jaccard score = 0.1322, loss = 0.4722, eval: [9.5 s]
# Iteration 1 fit: [7.7 s]: Recall = 0.1718, Jaccard score = 0.1474, loss = 0.4195, eval: [9.5 s]
# Iteration 2 fit: [7.9 s]: Recall = 0.1784, Jaccard score = 0.1539, loss = 0.4028, eval: [9.5 s]
# Iteration 3 fit: [7.7 s]: Recall = 0.1868, Jaccard score = 0.1623, loss = 0.3925, eval: [9.5 s]
# Iteration 4 fit: [7.7 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3852, eval: [9.5 s]
# Iteration 5 fit: [7.8 s]: Recall = 0.1920, Jaccard score = 0.1677, loss = 0.3792, eval: [9.5 s]
# Iteration 6 fit: [7.7 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3740, eval: [9.5 s]
# Iteration 7 fit: [7.7 s]: Recall = 0.1978, Jaccard score = 0.1736, loss = 0.3690, eval: [9.5 s]
# Iteration 8 fit: [7.7 s]: Recall = 0.1967, Jaccard score = 0.1725, loss = 0.3654, eval: [9.5 s]
# Iteration 9 fit: [7.7 s]: Recall = 0.1988, Jaccard score = 0.1747, loss = 0.3618, eval: [9.5 s]
# Iteration 10 fit: [8.3 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3585, eval: [11.7 s]
# Iteration 11 fit: [7.7 s]: Recall = 0.1998, Jaccard score = 0.1757, loss = 0.3556, eval: [9.5 s]
# Iteration 12 fit: [7.7 s]: Recall = 0.2011, Jaccard score = 0.1770, loss = 0.3531, eval: [9.4 s]
# Iteration 13 fit: [7.7 s]: Recall = 0.2052, Jaccard score = 0.1813, loss = 0.3505, eval: [9.4 s]
# Iteration 14 fit: [7.7 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3481, eval: [9.4 s]
# Iteration 15 fit: [7.7 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3459, eval: [9.4 s]
# Iteration 16 fit: [7.8 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3440, eval: [9.4 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,256]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,256]_1565790434.h5
--weights_path: Pretrain/_MLP_8_[512,256]_1565790434.h5
# Load data done [9.3 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #   
# =================================================================
# item_input (InputLayer)      (None, 1)                 0         
# _________________________________________________________________
# item_embedding (Embedding)   (None, 1, 256)            512000    
# _________________________________________________________________
# flatten_2 (Flatten)          (None, 256)               0         
# _________________________________________________________________
# layer1 (Dense)               (None, 256)               65792     
# _________________________________________________________________
# activation_1 (Activation)    (None, 256)               0         
# _________________________________________________________________
# prediction (Dense)           (None, 1)                 257       
# =================================================================
# Total params: 578,049
# Trainable params: 578,049
# Non-trainable params: 0
# _________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0305, Jaccard score = 0.0233
# Iteration 0 fit: [7.0 s]: Recall = 0.1385, Jaccard score = 0.1156, loss = 0.4430, eval: [5.8 s]
# Iteration 1 fit: [6.8 s]: Recall = 0.1365, Jaccard score = 0.1137, loss = 0.4219, eval: [5.9 s]
# Iteration 2 fit: [6.7 s]: Recall = 0.1362, Jaccard score = 0.1134, loss = 0.4209, eval: [5.9 s]
# Iteration 3 fit: [6.6 s]: Recall = 0.1382, Jaccard score = 0.1153, loss = 0.4207, eval: [5.9 s]
# Iteration 4 fit: [6.6 s]: Recall = 0.1359, Jaccard score = 0.1131, loss = 0.4209, eval: [5.9 s]
# Iteration 5 fit: [6.6 s]: Recall = 0.1354, Jaccard score = 0.1127, loss = 0.4204, eval: [5.9 s]
# Iteration 6 fit: [6.6 s]: Recall = 0.1348, Jaccard score = 0.1122, loss = 0.4201, eval: [5.8 s]
# Iteration 7 fit: [6.6 s]: Recall = 0.1352, Jaccard score = 0.1125, loss = 0.4201, eval: [5.8 s]
# Iteration 8 fit: [6.6 s]: Recall = 0.1378, Jaccard score = 0.1149, loss = 0.4200, eval: [5.8 s]
# Iteration 9 fit: [6.6 s]: Recall = 0.1352, Jaccard score = 0.1125, loss = 0.4203, eval: [5.8 s]
# Iteration 10 fit: [6.6 s]: Recall = 0.1381, Jaccard score = 0.1152, loss = 0.4199, eval: [5.8 s]
# Iteration 11 fit: [6.6 s]: Recall = 0.1404, Jaccard score = 0.1173, loss = 0.4201, eval: [5.9 s]
# Iteration 12 fit: [6.6 s]: Recall = 0.1391, Jaccard score = 0.1161, loss = 0.4201, eval: [5.8 s]
# Iteration 13 fit: [6.6 s]: Recall = 0.1361, Jaccard score = 0.1134, loss = 0.4201, eval: [5.8 s]
# Iteration 14 fit: [6.6 s]: Recall = 0.1388, Jaccard score = 0.1158, loss = 0.4198, eval: [5.8 s]
# Iteration 15 fit: [6.6 s]: Recall = 0.1383, Jaccard score = 0.1154, loss = 0.4198, eval: [5.8 s]
# Iteration 16 fit: [6.6 s]: Recall = 0.1369, Jaccard score = 0.1140, loss = 0.4198, eval: [5.9 s]
# Iteration 17 fit: [6.6 s]: Recall = 0.1401, Jaccard score = 0.1170, loss = 0.4200, eval: [5.8 s]
# Iteration 18 fit: [6.6 s]: Recall = 0.1374, Jaccard score = 0.1145, loss = 0.4194, eval: [5.8 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,256]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,256]_1565790851.h5
--weights_path: Pretrain/_MLP_8_[512,256]_1565790851.h5


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,256]', learner='adam', lr=0.0001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[512,256]_1565790863.h5
--weights_path: Pretrain/_MLP_8_[512,256]_1565790863.h5
# Load data done [10.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 100)          0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 512)          51712       user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 768)          0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 256)          196864      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 256)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            257         activation_1[0][0]               
# ==================================================================================================
# Total params: 760,833
# Trainable params: 760,833
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0263, Jaccard score = 0.0201
# Iteration 0 fit: [7.8 s]: Recall = 0.1611, Jaccard score = 0.1370, loss = 0.4702, eval: [5.8 s]
# Iteration 1 fit: [7.4 s]: Recall = 0.1724, Jaccard score = 0.1480, loss = 0.4224, eval: [5.8 s]
# Iteration 2 fit: [7.3 s]: Recall = 0.1833, Jaccard score = 0.1589, loss = 0.4033, eval: [5.8 s]
# Iteration 3 fit: [7.3 s]: Recall = 0.1905, Jaccard score = 0.1661, loss = 0.3914, eval: [5.8 s]
# Iteration 4 fit: [7.3 s]: Recall = 0.1889, Jaccard score = 0.1646, loss = 0.3826, eval: [5.8 s]
# Iteration 5 fit: [7.3 s]: Recall = 0.1928, Jaccard score = 0.1685, loss = 0.3754, eval: [5.8 s]
# Iteration 6 fit: [7.3 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3679, eval: [5.8 s]
# Iteration 7 fit: [7.3 s]: Recall = 0.1980, Jaccard score = 0.1739, loss = 0.3620, eval: [5.8 s]
# Iteration 8 fit: [7.3 s]: Recall = 0.1993, Jaccard score = 0.1751, loss = 0.3564, eval: [5.8 s]
# Iteration 9 fit: [7.3 s]: Recall = 0.2005, Jaccard score = 0.1764, loss = 0.3511, eval: [5.8 s]
# Iteration 10 fit: [7.3 s]: Recall = 0.2016, Jaccard score = 0.1775, loss = 0.3468, eval: [5.8 s]
# Iteration 11 fit: [7.3 s]: Recall = 0.2044, Jaccard score = 0.1804, loss = 0.3424, eval: [5.8 s]
# Iteration 12 fit: [7.3 s]: Recall = 0.2043, Jaccard score = 0.1803, loss = 0.3383, eval: [5.8 s]
# Iteration 13 fit: [7.3 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3346, eval: [5.8 s]
# Iteration 14 fit: [7.3 s]: Recall = 0.2041, Jaccard score = 0.1801, loss = 0.3303, eval: [5.8 s]
# Iteration 15 fit: [7.3 s]: Recall = 0.2046, Jaccard score = 0.1806, loss = 0.3274, eval: [5.8 s]
# Iteration 16 fit: [7.3 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3237, eval: [5.8 s]
# Iteration 17 fit: [7.3 s]: Recall = 0.2054, Jaccard score = 0.1815, loss = 0.3206, eval: [5.9 s]
# Iteration 18 fit: [7.3 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.3173, eval: [5.8 s]
# Iteration 19 fit: [7.3 s]: Recall = 0.2043, Jaccard score = 0.1803, loss = 0.3136, eval: [5.8 s]
# Iteration 20 fit: [7.3 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3113, eval: [5.8 s]
# Iteration 21 fit: [7.3 s]: Recall = 0.2039, Jaccard score = 0.1800, loss = 0.3078, eval: [5.8 s]
# Iteration 22 fit: [7.3 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.3053, eval: [5.8 s]
# Iteration 23 fit: [7.4 s]: Recall = 0.2046, Jaccard score = 0.1806, loss = 0.3026, eval: [5.8 s]
# Iteration 24 fit: [7.3 s]: Recall = 0.2035, Jaccard score = 0.1795, loss = 0.2993, eval: [5.8 s]
# Iteration 25 fit: [7.3 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.2971, eval: [5.8 s]
# Iteration 26 fit: [7.3 s]: Recall = 0.2039, Jaccard score = 0.1800, loss = 0.2949, eval: [5.8 s]
# Iteration 27 fit: [7.3 s]: Recall = 0.2011, Jaccard score = 0.1771, loss = 0.2918, eval: [5.8 s]
# Iteration 28 fit: [7.3 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.2899, eval: [5.8 s]
