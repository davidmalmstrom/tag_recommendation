--nn_model: MLP
--is_tag: "1"
--eval_recall: "1"
--topk: "3"
--big_tag: "0"
--epochs: "300"
--layers: "[1024,128]"
--reg_layers: "[0,0]"
--early_stopping: "35"
--test_dataset: "1"
--percentage: "0.0"
--dataset_name_prepend: "cold_0.0_"

# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[64,64]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[64,64]_1563978066.h5
# --weights_path: Pretrain/_MLP_8_[64,64]_1563978066.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0287, Jaccard score = 0.0219
# # Iteration 0 fit: [11.5 s]: Recall = 0.1593, Jaccard score = 0.1352, loss = 0.4435, eval: [6.6 s]
# # Iteration 1 fit: [11.2 s]: Recall = 0.1755, Jaccard score = 0.1511, loss = 0.4030, eval: [6.5 s]
# # Iteration 2 fit: [11.2 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.3880, eval: [6.6 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.3740, eval: [6.6 s]
# # Iteration 4 fit: [11.1 s]: Recall = 0.1879, Jaccard score = 0.1635, loss = 0.3624, eval: [6.5 s]
# # Iteration 5 fit: [11.2 s]: Recall = 0.1883, Jaccard score = 0.1639, loss = 0.3506, eval: [6.6 s]
# # Iteration 6 fit: [11.1 s]: Recall = 0.1873, Jaccard score = 0.1629, loss = 0.3403, eval: [6.5 s]
# # Iteration 7 fit: [11.1 s]: Recall = 0.1868, Jaccard score = 0.1624, loss = 0.3296, eval: [6.6 s]
# # Iteration 8 fit: [11.8 s]: Recall = 0.1833, Jaccard score = 0.1589, loss = 0.3201, eval: [6.6 s]
# # Iteration 9 fit: [11.1 s]: Recall = 0.1783, Jaccard score = 0.1539, loss = 0.3105, eval: [6.5 s]
# # Iteration 10 fit: [11.3 s]: Recall = 0.1751, Jaccard score = 0.1507, loss = 0.3022, eval: [6.5 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[16,300]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[16,300]_1563978295.h5
# --weights_path: Pretrain/_MLP_8_[16,300]_1563978295.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0238, Jaccard score = 0.0181
# # Iteration 0 fit: [11.3 s]: Recall = 0.1468, Jaccard score = 0.1233, loss = 0.4618, eval: [6.5 s]
# # Iteration 1 fit: [10.9 s]: Recall = 0.1610, Jaccard score = 0.1369, loss = 0.4169, eval: [6.5 s]
# # Iteration 2 fit: [11.6 s]: Recall = 0.1725, Jaccard score = 0.1482, loss = 0.4040, eval: [6.7 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1755, Jaccard score = 0.1511, loss = 0.3947, eval: [6.6 s]
# # Iteration 4 fit: [10.9 s]: Recall = 0.1813, Jaccard score = 0.1569, loss = 0.3851, eval: [6.6 s]
# # Iteration 5 fit: [11.1 s]: Recall = 0.1867, Jaccard score = 0.1623, loss = 0.3758, eval: [6.6 s]
# # Iteration 6 fit: [11.0 s]: Recall = 0.1855, Jaccard score = 0.1610, loss = 0.3670, eval: [6.6 s]
# # Iteration 7 fit: [11.1 s]: Recall = 0.1859, Jaccard score = 0.1614, loss = 0.3585, eval: [6.6 s]
# # Iteration 8 fit: [11.1 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3504, eval: [6.5 s]
# # Iteration 9 fit: [11.1 s]: Recall = 0.1851, Jaccard score = 0.1607, loss = 0.3424, eval: [6.7 s]
# # Iteration 10 fit: [11.0 s]: Recall = 0.1862, Jaccard score = 0.1618, loss = 0.3346, eval: [6.7 s]
# # Iteration 11 fit: [11.0 s]: Recall = 0.1829, Jaccard score = 0.1584, loss = 0.3287, eval: [6.7 s]
# # Iteration 12 fit: [11.1 s]: Recall = 0.1827, Jaccard score = 0.1583, loss = 0.3214, eval: [6.7 s]
# # Iteration 13 fit: [11.6 s]: Recall = 0.1820, Jaccard score = 0.1575, loss = 0.3152, eval: [6.5 s]
# # Iteration 14 fit: [11.0 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.3083, eval: [6.7 s]
# # Iteration 15 fit: [11.1 s]: Recall = 0.1780, Jaccard score = 0.1536, loss = 0.3030, eval: [6.5 s]
# # Iteration 16 fit: [11.1 s]: Recall = 0.1776, Jaccard score = 0.1532, loss = 0.2980, eval: [6.6 s]
# # Iteration 17 fit: [11.1 s]: Recall = 0.1729, Jaccard score = 0.1485, loss = 0.2920, eval: [6.5 s]
# # Iteration 18 fit: [11.1 s]: Recall = 0.1742, Jaccard score = 0.1498, loss = 0.2868, eval: [6.8 s]
# # Iteration 19 fit: [12.2 s]: Recall = 0.1718, Jaccard score = 0.1474, loss = 0.2822, eval: [6.5 s]
# # Iteration 20 fit: [11.2 s]: Recall = 0.1674, Jaccard score = 0.1431, loss = 0.2767, eval: [6.6 s]
# # Iteration 21 fit: [11.0 s]: Recall = 0.1696, Jaccard score = 0.1453, loss = 0.2732, eval: [6.7 s]
# # Model test performed 
# # Recall score: 0.055224867724867725     Jaccard score: 0.04329789992221934

# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[16,200]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[16,200]_1563978794.h5
# --weights_path: Pretrain/_MLP_8_[16,200]_1563978794.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0271, Jaccard score = 0.0207
# # Iteration 0 fit: [10.8 s]: Recall = 0.1406, Jaccard score = 0.1175, loss = 0.4647, eval: [6.7 s]
# # Iteration 1 fit: [11.0 s]: Recall = 0.1601, Jaccard score = 0.1360, loss = 0.4172, eval: [6.7 s]
# # Iteration 2 fit: [10.5 s]: Recall = 0.1699, Jaccard score = 0.1456, loss = 0.4052, eval: [6.6 s]
# # Iteration 3 fit: [10.7 s]: Recall = 0.1747, Jaccard score = 0.1503, loss = 0.3955, eval: [6.6 s]
# # Iteration 4 fit: [10.7 s]: Recall = 0.1829, Jaccard score = 0.1584, loss = 0.3858, eval: [6.7 s]
# # Iteration 5 fit: [10.5 s]: Recall = 0.1860, Jaccard score = 0.1616, loss = 0.3773, eval: [6.7 s]
# # Iteration 6 fit: [10.5 s]: Recall = 0.1860, Jaccard score = 0.1616, loss = 0.3687, eval: [6.6 s]
# # Iteration 7 fit: [10.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3609, eval: [6.7 s]
# # Iteration 8 fit: [10.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3533, eval: [6.7 s]
# # Iteration 9 fit: [10.5 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.3458, eval: [6.5 s]
# # Iteration 10 fit: [10.7 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3387, eval: [6.5 s]
# # Iteration 11 fit: [10.5 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3321, eval: [6.6 s]
# # Iteration 12 fit: [10.6 s]: Recall = 0.1863, Jaccard score = 0.1619, loss = 0.3260, eval: [6.7 s]
# # Iteration 13 fit: [10.7 s]: Recall = 0.1868, Jaccard score = 0.1624, loss = 0.3201, eval: [6.6 s]
# # Iteration 14 fit: [10.5 s]: Recall = 0.1820, Jaccard score = 0.1575, loss = 0.3151, eval: [6.6 s]
# # Iteration 15 fit: [10.3 s]: Recall = 0.1839, Jaccard score = 0.1595, loss = 0.3098, eval: [6.7 s]
# # Iteration 16 fit: [11.2 s]: Recall = 0.1830, Jaccard score = 0.1586, loss = 0.3040, eval: [6.5 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[32,200]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[32,200]_1563979110.h5
# --weights_path: Pretrain/_MLP_8_[32,200]_1563979110.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0299, Jaccard score = 0.0229
# # Iteration 0 fit: [12.1 s]: Recall = 0.1593, Jaccard score = 0.1353, loss = 0.4492, eval: [6.7 s]
# # Iteration 1 fit: [11.1 s]: Recall = 0.1708, Jaccard score = 0.1464, loss = 0.4073, eval: [6.7 s]
# # Iteration 2 fit: [11.1 s]: Recall = 0.1833, Jaccard score = 0.1588, loss = 0.3931, eval: [6.7 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3807, eval: [6.7 s]
# # Iteration 4 fit: [11.1 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3688, eval: [6.7 s]
# # Iteration 5 fit: [11.1 s]: Recall = 0.1889, Jaccard score = 0.1646, loss = 0.3583, eval: [6.5 s]
# # Iteration 6 fit: [11.2 s]: Recall = 0.1918, Jaccard score = 0.1674, loss = 0.3471, eval: [6.6 s]
# # Iteration 7 fit: [11.1 s]: Recall = 0.1909, Jaccard score = 0.1666, loss = 0.3372, eval: [6.7 s]
# # Iteration 8 fit: [11.1 s]: Recall = 0.1907, Jaccard score = 0.1664, loss = 0.3283, eval: [6.7 s]
# # Iteration 9 fit: [11.1 s]: Recall = 0.1909, Jaccard score = 0.1666, loss = 0.3185, eval: [6.7 s]
# # Iteration 10 fit: [11.1 s]: Recall = 0.1892, Jaccard score = 0.1648, loss = 0.3101, eval: [6.7 s]
# # Iteration 11 fit: [11.2 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.3019, eval: [6.7 s]
# # Iteration 12 fit: [11.2 s]: Recall = 0.1823, Jaccard score = 0.1578, loss = 0.2942, eval: [6.7 s]
# # Iteration 13 fit: [11.1 s]: Recall = 0.1797, Jaccard score = 0.1552, loss = 0.2864, eval: [6.7 s]
# # Iteration 14 fit: [11.2 s]: Recall = 0.1789, Jaccard score = 0.1545, loss = 0.2788, eval: [6.7 s]
# # Iteration 15 fit: [11.1 s]: Recall = 0.1761, Jaccard score = 0.1517, loss = 0.2720, eval: [6.7 s]
# # Iteration 16 fit: [11.1 s]: Recall = 0.1753, Jaccard score = 0.1509, loss = 0.2657, eval: [6.7 s]
# # Iteration 17 fit: [11.1 s]: Recall = 0.1679, Jaccard score = 0.1436, loss = 0.2589, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1,1024]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[1,1024]_1563979483.h5
# --weights_path: Pretrain/_MLP_8_[1,1024]_1563979483.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'ValueError'>: The shape of the input to "Flatten" is not fully defined (got (1, 0). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,1024]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,1024]_1563979516.h5
# --weights_path: Pretrain/_MLP_8_[4,1024]_1563979516.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 2)         40000       user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 2)            0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 2)         4000        item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1002)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 2)            0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1004)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 1024)         1029120     concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            1025        layer1[0][0]                     
# # ==================================================================================================
# # Total params: 1,074,145
# # Trainable params: 1,074,145
# # Non-trainable params: 0
# # __________________________________________________________________________________________________


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,1024]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,1024]_1563979535.h5
# --weights_path: Pretrain/_MLP_8_[4,1024]_1563979535.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0265, Jaccard score = 0.0202
# # Iteration 0 fit: [12.6 s]: Recall = 0.1217, Jaccard score = 0.1001, loss = 0.4847, eval: [6.7 s]
# # Iteration 1 fit: [12.6 s]: Recall = 0.1442, Jaccard score = 0.1209, loss = 0.4350, eval: [6.7 s]
# # Iteration 2 fit: [12.5 s]: Recall = 0.1496, Jaccard score = 0.1259, loss = 0.4204, eval: [6.8 s]
# # Iteration 3 fit: [12.5 s]: Recall = 0.1525, Jaccard score = 0.1288, loss = 0.4152, eval: [6.7 s]
# # Iteration 4 fit: [12.5 s]: Recall = 0.1544, Jaccard score = 0.1306, loss = 0.4117, eval: [6.9 s]
# # Iteration 5 fit: [12.7 s]: Recall = 0.1567, Jaccard score = 0.1327, loss = 0.4083, eval: [6.9 s]
# # Iteration 6 fit: [12.6 s]: Recall = 0.1551, Jaccard score = 0.1312, loss = 0.4055, eval: [6.9 s]
# # Iteration 7 fit: [12.6 s]: Recall = 0.1581, Jaccard score = 0.1341, loss = 0.4029, eval: [6.9 s]
# # Iteration 8 fit: [12.5 s]: Recall = 0.1575, Jaccard score = 0.1336, loss = 0.3997, eval: [6.8 s]
# # Iteration 9 fit: [12.6 s]: Recall = 0.1569, Jaccard score = 0.1330, loss = 0.3965, eval: [6.8 s]
# # Iteration 10 fit: [12.6 s]: Recall = 0.1558, Jaccard score = 0.1319, loss = 0.3935, eval: [6.8 s]
# # Iteration 11 fit: [12.5 s]: Recall = 0.1606, Jaccard score = 0.1365, loss = 0.3904, eval: [6.7 s]
# # Iteration 12 fit: [12.5 s]: Recall = 0.1589, Jaccard score = 0.1349, loss = 0.3879, eval: [6.9 s]
# # Iteration 13 fit: [12.6 s]: Recall = 0.1596, Jaccard score = 0.1356, loss = 0.3852, eval: [6.7 s]
# # Iteration 14 fit: [12.6 s]: Recall = 0.1599, Jaccard score = 0.1358, loss = 0.3823, eval: [6.7 s]
# # Iteration 15 fit: [12.5 s]: Recall = 0.1569, Jaccard score = 0.1329, loss = 0.3794, eval: [6.9 s]
# # Iteration 16 fit: [12.5 s]: Recall = 0.1591, Jaccard score = 0.1350, loss = 0.3770, eval: [6.7 s]
# # Iteration 17 fit: [12.6 s]: Recall = 0.1555, Jaccard score = 0.1316, loss = 0.3739, eval: [6.9 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,512,512]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,512,512]_1563979921.h5
# --weights_path: Pretrain/_MLP_8_[4,512,512]_1563979921.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'AssertionError'>: 


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,512,512]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,512,512]_1563979934.h5
# --weights_path: Pretrain/_MLP_8_[4,512,512]_1563979934.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0244, Jaccard score = 0.0186
# # Iteration 0 fit: [13.0 s]: Recall = 0.1319, Jaccard score = 0.1094, loss = 0.4769, eval: [6.8 s]
# # Iteration 1 fit: [12.3 s]: Recall = 0.1438, Jaccard score = 0.1205, loss = 0.4295, eval: [6.8 s]
# # Iteration 2 fit: [12.9 s]: Recall = 0.1523, Jaccard score = 0.1286, loss = 0.4166, eval: [6.8 s]
# # Iteration 3 fit: [12.3 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.4102, eval: [6.8 s]
# # Iteration 4 fit: [12.3 s]: Recall = 0.1584, Jaccard score = 0.1344, loss = 0.4043, eval: [6.8 s]
# # Iteration 5 fit: [12.3 s]: Recall = 0.1595, Jaccard score = 0.1354, loss = 0.3988, eval: [6.8 s]
# # Iteration 6 fit: [12.6 s]: Recall = 0.1604, Jaccard score = 0.1363, loss = 0.3926, eval: [6.9 s]
# # Iteration 7 fit: [12.4 s]: Recall = 0.1589, Jaccard score = 0.1349, loss = 0.3862, eval: [6.8 s]
# # Iteration 8 fit: [12.3 s]: Recall = 0.1626, Jaccard score = 0.1385, loss = 0.3800, eval: [6.8 s]
# # Iteration 9 fit: [12.3 s]: Recall = 0.1630, Jaccard score = 0.1388, loss = 0.3733, eval: [6.8 s]
# # Iteration 10 fit: [12.3 s]: Recall = 0.1620, Jaccard score = 0.1378, loss = 0.3678, eval: [6.7 s]
# # Iteration 11 fit: [12.3 s]: Recall = 0.1632, Jaccard score = 0.1390, loss = 0.3621, eval: [6.8 s]
# # Iteration 12 fit: [12.3 s]: Recall = 0.1648, Jaccard score = 0.1406, loss = 0.3566, eval: [6.8 s]
# # Iteration 13 fit: [12.6 s]: Recall = 0.1634, Jaccard score = 0.1393, loss = 0.3512, eval: [6.8 s]
# # Iteration 14 fit: [12.3 s]: Recall = 0.1600, Jaccard score = 0.1359, loss = 0.3463, eval: [6.8 s]
# # Iteration 15 fit: [12.4 s]: Recall = 0.1571, Jaccard score = 0.1332, loss = 0.3413, eval: [6.8 s]
# # Iteration 16 fit: [12.3 s]: Recall = 0.1611, Jaccard score = 0.1370, loss = 0.3370, eval: [6.8 s]
# # Iteration 17 fit: [12.3 s]: Recall = 0.1615, Jaccard score = 0.1373, loss = 0.3323, eval: [6.7 s]
# # Iteration 18 fit: [12.3 s]: Recall = 0.1592, Jaccard score = 0.1352, loss = 0.3282, eval: [6.8 s]
# # Iteration 19 fit: [12.3 s]: Recall = 0.1546, Jaccard score = 0.1308, loss = 0.3239, eval: [6.8 s]
# # Iteration 20 fit: [12.3 s]: Recall = 0.1573, Jaccard score = 0.1333, loss = 0.3202, eval: [6.7 s]
# # Iteration 21 fit: [12.3 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.3160, eval: [6.7 s]
# # Iteration 22 fit: [12.3 s]: Recall = 0.1534, Jaccard score = 0.1296, loss = 0.3117, eval: [6.7 s]
# # Iteration 23 fit: [12.2 s]: Recall = 0.1543, Jaccard score = 0.1304, loss = 0.3094, eval: [6.8 s]
# # Iteration 24 fit: [12.3 s]: Recall = 0.1528, Jaccard score = 0.1290, loss = 0.3056, eval: [6.8 s]
# # Iteration 25 fit: [12.3 s]: Recall = 0.1541, Jaccard score = 0.1302, loss = 0.3016, eval: [6.8 s]
# # Iteration 26 fit: [12.3 s]: Recall = 0.1502, Jaccard score = 0.1265, loss = 0.2994, eval: [6.8 s]
# # Iteration 27 fit: [12.3 s]: Recall = 0.1506, Jaccard score = 0.1269, loss = 0.2969, eval: [6.7 s]
# # Iteration 28 fit: [12.3 s]: Recall = 0.1496, Jaccard score = 0.1259, loss = 0.2932, eval: [6.8 s]
# # Iteration 29 fit: [12.3 s]: Recall = 0.1516, Jaccard score = 0.1279, loss = 0.2909, eval: [6.8 s]
# # Iteration 30 fit: [12.3 s]: Recall = 0.1465, Jaccard score = 0.1230, loss = 0.2873, eval: [6.8 s]
# # Iteration 31 fit: [12.3 s]: Recall = 0.1478, Jaccard score = 0.1242, loss = 0.2858, eval: [6.8 s]
# # Iteration 32 fit: [12.2 s]: Recall = 0.1489, Jaccard score = 0.1254, loss = 0.2831, eval: [6.8 s]
# # Iteration 33 fit: [12.3 s]: Recall = 0.1451, Jaccard score = 0.1217, loss = 0.2811, eval: [6.8 s]
# # Iteration 34 fit: [12.3 s]: Recall = 0.1474, Jaccard score = 0.1239, loss = 0.2785, eval: [6.8 s]
# # Iteration 35 fit: [12.3 s]: Recall = 0.1467, Jaccard score = 0.1233, loss = 0.2763, eval: [6.8 s]
# # Iteration 36 fit: [12.3 s]: Recall = 0.1426, Jaccard score = 0.1194, loss = 0.2740, eval: [6.8 s]
# # Iteration 37 fit: [12.3 s]: Recall = 0.1413, Jaccard score = 0.1182, loss = 0.2722, eval: [6.8 s]
# # Iteration 38 fit: [12.3 s]: Recall = 0.1450, Jaccard score = 0.1216, loss = 0.2701, eval: [6.8 s]
# # Iteration 39 fit: [12.3 s]: Recall = 0.1415, Jaccard score = 0.1184, loss = 0.2680, eval: [6.8 s]
# # Iteration 40 fit: [12.3 s]: Recall = 0.1379, Jaccard score = 0.1150, loss = 0.2657, eval: [6.7 s]
# # Iteration 41 fit: [12.3 s]: Recall = 0.1437, Jaccard score = 0.1204, loss = 0.2651, eval: [6.8 s]
# # Iteration 42 fit: [12.3 s]: Recall = 0.1421, Jaccard score = 0.1189, loss = 0.2637, eval: [6.7 s]
# # Iteration 43 fit: [12.3 s]: Recall = 0.1396, Jaccard score = 0.1165, loss = 0.2612, eval: [6.7 s]
# # Iteration 44 fit: [12.2 s]: Recall = 0.1385, Jaccard score = 0.1155, loss = 0.2595, eval: [6.8 s]
# # Iteration 45 fit: [12.3 s]: Recall = 0.1369, Jaccard score = 0.1141, loss = 0.2574, eval: [6.8 s]
# # Iteration 46 fit: [12.4 s]: Recall = 0.1403, Jaccard score = 0.1173, loss = 0.2567, eval: [6.8 s]
# # Iteration 47 fit: [12.3 s]: Recall = 0.1378, Jaccard score = 0.1149, loss = 0.2550, eval: [6.8 s]
# # End. Best Iteration 12:  Recall = 0.1648, Jaccard score = 0.1406. 
# # The best NeuMF model has been saved to Pretrain/_MLP_8_[4,512,512]_1563979934.h5


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,128,128,128]_1563995964.h5
# --weights_path: Pretrain/_MLP_8_[4,128,128,128]_1563995964.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'AssertionError'>: 


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,128,128,128]_1563995977.h5
# --weights_path: Pretrain/_MLP_8_[4,128,128,128]_1563995977.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0272, Jaccard score = 0.0208
# # Iteration 0 fit: [11.7 s]: Recall = 0.1220, Jaccard score = 0.1004, loss = 0.4743, eval: [6.7 s]
# # Iteration 1 fit: [11.4 s]: Recall = 0.1376, Jaccard score = 0.1148, loss = 0.4303, eval: [6.7 s]
# # Iteration 2 fit: [11.4 s]: Recall = 0.1471, Jaccard score = 0.1236, loss = 0.4173, eval: [6.9 s]
# # Iteration 3 fit: [11.4 s]: Recall = 0.1516, Jaccard score = 0.1279, loss = 0.4108, eval: [6.9 s]
# # Iteration 4 fit: [11.5 s]: Recall = 0.1543, Jaccard score = 0.1305, loss = 0.4057, eval: [6.8 s]
# # Iteration 5 fit: [11.4 s]: Recall = 0.1568, Jaccard score = 0.1329, loss = 0.4009, eval: [6.9 s]
# # Iteration 6 fit: [11.5 s]: Recall = 0.1606, Jaccard score = 0.1365, loss = 0.3959, eval: [6.8 s]
# # Iteration 7 fit: [11.5 s]: Recall = 0.1598, Jaccard score = 0.1358, loss = 0.3915, eval: [6.9 s]
# # Iteration 8 fit: [11.5 s]: Recall = 0.1603, Jaccard score = 0.1362, loss = 0.3874, eval: [6.8 s]
# # Iteration 9 fit: [11.5 s]: Recall = 0.1614, Jaccard score = 0.1372, loss = 0.3832, eval: [6.8 s]
# # Iteration 10 fit: [11.8 s]: Recall = 0.1618, Jaccard score = 0.1376, loss = 0.3777, eval: [6.9 s]
# # Iteration 11 fit: [11.6 s]: Recall = 0.1615, Jaccard score = 0.1374, loss = 0.3740, eval: [6.9 s]
# # Iteration 12 fit: [11.6 s]: Recall = 0.1608, Jaccard score = 0.1367, loss = 0.3699, eval: [6.9 s]
# # Iteration 13 fit: [11.5 s]: Recall = 0.1619, Jaccard score = 0.1377, loss = 0.3666, eval: [6.9 s]
# # Iteration 14 fit: [11.4 s]: Recall = 0.1650, Jaccard score = 0.1407, loss = 0.3625, eval: [6.9 s]
# # Iteration 15 fit: [11.6 s]: Recall = 0.1600, Jaccard score = 0.1359, loss = 0.3596, eval: [6.9 s]
# # Iteration 16 fit: [11.5 s]: Recall = 0.1616, Jaccard score = 0.1375, loss = 0.3561, eval: [6.9 s]
# # Iteration 17 fit: [11.4 s]: Recall = 0.1613, Jaccard score = 0.1372, loss = 0.3532, eval: [6.9 s]
# # Iteration 18 fit: [11.4 s]: Recall = 0.1614, Jaccard score = 0.1373, loss = 0.3501, eval: [6.7 s]
# # Iteration 19 fit: [11.6 s]: Recall = 0.1612, Jaccard score = 0.1371, loss = 0.3474, eval: [6.9 s]
# # Iteration 20 fit: [11.4 s]: Recall = 0.1592, Jaccard score = 0.1352, loss = 0.3448, eval: [6.8 s]
# # Iteration 21 fit: [11.4 s]: Recall = 0.1586, Jaccard score = 0.1346, loss = 0.3418, eval: [6.8 s]
# # Iteration 22 fit: [11.5 s]: Recall = 0.1600, Jaccard score = 0.1359, loss = 0.3394, eval: [6.8 s]
# # Iteration 23 fit: [11.4 s]: Recall = 0.1566, Jaccard score = 0.1326, loss = 0.3369, eval: [6.9 s]
# # Iteration 24 fit: [11.4 s]: Recall = 0.1563, Jaccard score = 0.1324, loss = 0.3353, eval: [6.9 s]
# # Iteration 25 fit: [11.4 s]: Recall = 0.1580, Jaccard score = 0.1340, loss = 0.3329, eval: [6.9 s]
# # Iteration 26 fit: [11.4 s]: Recall = 0.1556, Jaccard score = 0.1317, loss = 0.3307, eval: [6.8 s]
# # Iteration 27 fit: [11.4 s]: Recall = 0.1576, Jaccard score = 0.1337, loss = 0.3287, eval: [6.9 s]
# # Iteration 28 fit: [11.4 s]: Recall = 0.1606, Jaccard score = 0.1365, loss = 0.3267, eval: [6.9 s]
# # Iteration 29 fit: [11.6 s]: Recall = 0.1541, Jaccard score = 0.1302, loss = 0.3247, eval: [7.2 s]
# # Iteration 30 fit: [11.5 s]: Recall = 0.1547, Jaccard score = 0.1309, loss = 0.3228, eval: [6.9 s]
# # Iteration 31 fit: [11.4 s]: Recall = 0.1568, Jaccard score = 0.1328, loss = 0.3211, eval: [6.9 s]
# # Iteration 32 fit: [11.5 s]: Recall = 0.1527, Jaccard score = 0.1289, loss = 0.3193, eval: [6.7 s]
# # Iteration 33 fit: [11.4 s]: Recall = 0.1496, Jaccard score = 0.1260, loss = 0.3176, eval: [6.9 s]
# # Iteration 34 fit: [11.4 s]: Recall = 0.1521, Jaccard score = 0.1284, loss = 0.3160, eval: [6.8 s]
# # Iteration 35 fit: [11.5 s]: Recall = 0.1485, Jaccard score = 0.1250, loss = 0.3142, eval: [6.9 s]
# # Iteration 36 fit: [11.6 s]: Recall = 0.1496, Jaccard score = 0.1260, loss = 0.3131, eval: [7.0 s]
# # Iteration 37 fit: [11.5 s]: Recall = 0.1485, Jaccard score = 0.1250, loss = 0.3118, eval: [6.9 s]
# # Iteration 38 fit: [11.5 s]: Recall = 0.1533, Jaccard score = 0.1295, loss = 0.3099, eval: [7.0 s]
# # Iteration 39 fit: [12.8 s]: Recall = 0.1505, Jaccard score = 0.1268, loss = 0.3088, eval: [6.9 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[4,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[4,128,128,128]_1563996727.h5
# --weights_path: Pretrain/_MLP_8_[4,128,128,128]_1563996727.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # <class 'tensorflow.python.framework.errors_impl.InternalError'>: Blas GEMM launch failed : a.shape=(100, 1004), b.shape=(1004, 128), m=100, n=128, k=1004 	 [[{{node layer1/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:GPU:0"](concatenate_2/concat, layer1/kernel/read)]] 	 [[{{node prediction/Sigmoid/_115}} = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_85_prediction/Sigmoid", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()]]
# # Iteration 40 fit: [12.2 s]: Recall = 0.1527, Jaccard score = 0.1289, loss = 0.3077, eval: [7.0 s]
# # Iteration 41 fit: [11.5 s]: Recall = 0.1472, Jaccard score = 0.1237, loss = 0.3065, eval: [6.9 s]
# # Iteration 42 fit: [11.5 s]: Recall = 0.1448, Jaccard score = 0.1215, loss = 0.3050, eval: [6.9 s]
# # Iteration 43 fit: [11.6 s]: Recall = 0.1480, Jaccard score = 0.1245, loss = 0.3039, eval: [6.9 s]
# # Iteration 44 fit: [11.6 s]: Recall = 0.1489, Jaccard score = 0.1253, loss = 0.3021, eval: [6.9 s]
# # Iteration 45 fit: [11.4 s]: Recall = 0.1510, Jaccard score = 0.1273, loss = 0.3014, eval: [6.8 s]
# # Iteration 46 fit: [11.4 s]: Recall = 0.1516, Jaccard score = 0.1279, loss = 0.3002, eval: [6.9 s]
# # Iteration 47 fit: [11.4 s]: Recall = 0.1503, Jaccard score = 0.1266, loss = 0.2985, eval: [6.8 s]
# # Iteration 48 fit: [11.4 s]: Recall = 0.1469, Jaccard score = 0.1234, loss = 0.2979, eval: [7.0 s]
# # Iteration 49 fit: [11.4 s]: Recall = 0.1433, Jaccard score = 0.1201, loss = 0.2970, eval: [6.8 s]
# # End. Best Iteration 14:  Recall = 0.1650, Jaccard score = 0.1407. 
# # The best NeuMF model has been saved to Pretrain/_MLP_8_[4,128,128,128]_1563995977.h5


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[2,128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[2,128,128,128]_1563998004.h5
# --weights_path: Pretrain/_MLP_8_[2,128,128,128]_1563998004.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0261, Jaccard score = 0.0199
# # Iteration 0 fit: [11.9 s]: Recall = 0.1043, Jaccard score = 0.0846, loss = 0.4881, eval: [6.8 s]
# # Iteration 1 fit: [13.8 s]: Recall = 0.1324, Jaccard score = 0.1099, loss = 0.4443, eval: [8.9 s]
# # Iteration 2 fit: [11.5 s]: Recall = 0.1416, Jaccard score = 0.1185, loss = 0.4275, eval: [6.9 s]
# # Iteration 3 fit: [11.6 s]: Recall = 0.1438, Jaccard score = 0.1205, loss = 0.4201, eval: [6.9 s]
# # Iteration 4 fit: [11.5 s]: Recall = 0.1467, Jaccard score = 0.1232, loss = 0.4145, eval: [6.8 s]
# # Iteration 5 fit: [12.4 s]: Recall = 0.1446, Jaccard score = 0.1213, loss = 0.4101, eval: [6.8 s]
# # Iteration 6 fit: [11.5 s]: Recall = 0.1483, Jaccard score = 0.1248, loss = 0.4059, eval: [6.9 s]
# # Iteration 7 fit: [12.9 s]: Recall = 0.1490, Jaccard score = 0.1254, loss = 0.4027, eval: [8.8 s]
# # Iteration 8 fit: [12.1 s]: Recall = 0.1511, Jaccard score = 0.1274, loss = 0.3995, eval: [6.9 s]
# # Iteration 9 fit: [11.5 s]: Recall = 0.1466, Jaccard score = 0.1232, loss = 0.3955, eval: [6.8 s]
# # Iteration 10 fit: [12.1 s]: Recall = 0.1444, Jaccard score = 0.1211, loss = 0.3919, eval: [6.9 s]
# # Iteration 11 fit: [11.6 s]: Recall = 0.1493, Jaccard score = 0.1257, loss = 0.3882, eval: [6.9 s]
# # Iteration 12 fit: [11.5 s]: Recall = 0.1505, Jaccard score = 0.1268, loss = 0.3849, eval: [6.9 s]
# # Iteration 13 fit: [11.4 s]: Recall = 0.1460, Jaccard score = 0.1225, loss = 0.3823, eval: [7.0 s]
# # Iteration 14 fit: [11.6 s]: Recall = 0.1489, Jaccard score = 0.1254, loss = 0.3801, eval: [6.9 s]
# # Iteration 15 fit: [11.5 s]: Recall = 0.1478, Jaccard score = 0.1243, loss = 0.3774, eval: [6.9 s]
# # Iteration 16 fit: [11.5 s]: Recall = 0.1475, Jaccard score = 0.1240, loss = 0.3753, eval: [6.9 s]
# # Iteration 17 fit: [11.6 s]: Recall = 0.1479, Jaccard score = 0.1243, loss = 0.3734, eval: [6.9 s]
# # Iteration 18 fit: [11.4 s]: Recall = 0.1485, Jaccard score = 0.1249, loss = 0.3716, eval: [6.9 s]
# # Iteration 19 fit: [11.5 s]: Recall = 0.1480, Jaccard score = 0.1245, loss = 0.3698, eval: [6.8 s]
# # Iteration 20 fit: [11.5 s]: Recall = 0.1467, Jaccard score = 0.1232, loss = 0.3679, eval: [6.9 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1563999947.h5
# --weights_path: Pretrain/_MLP_8_[1024,128]_1563999947.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0269, Jaccard score = 0.0205
# # Iteration 0 fit: [35.9 s]: Recall = 0.1571, Jaccard score = 0.1331, loss = 0.4326, eval: [6.5 s]
# # Iteration 1 fit: [35.1 s]: Recall = 0.1789, Jaccard score = 0.1545, loss = 0.3912, eval: [6.7 s]
# # Iteration 2 fit: [35.2 s]: Recall = 0.1792, Jaccard score = 0.1547, loss = 0.3563, eval: [6.5 s]
# # Iteration 3 fit: [35.3 s]: Recall = 0.1767, Jaccard score = 0.1523, loss = 0.3220, eval: [6.6 s]
# # Iteration 4 fit: [35.2 s]: Recall = 0.1686, Jaccard score = 0.1443, loss = 0.2878, eval: [6.6 s]
# # Iteration 5 fit: [35.3 s]: Recall = 0.1652, Jaccard score = 0.1410, loss = 0.2548, eval: [6.7 s]
# # Iteration 6 fit: [35.3 s]: Recall = 0.1561, Jaccard score = 0.1322, loss = 0.2230, eval: [6.5 s]
# # Iteration 7 fit: [35.2 s]: Recall = 0.1465, Jaccard score = 0.1231, loss = 0.1946, eval: [6.6 s]
# # Iteration 8 fit: [35.3 s]: Recall = 0.1440, Jaccard score = 0.1207, loss = 0.1684, eval: [6.6 s]
# # Iteration 9 fit: [35.2 s]: Recall = 0.1415, Jaccard score = 0.1183, loss = 0.1476, eval: [6.5 s]
# # Iteration 10 fit: [35.2 s]: Recall = 0.1373, Jaccard score = 0.1144, loss = 0.1294, eval: [6.7 s]
# # Iteration 11 fit: [35.3 s]: Recall = 0.1301, Jaccard score = 0.1078, loss = 0.1138, eval: [8.5 s]
# # Iteration 12 fit: [35.8 s]: Recall = 0.1298, Jaccard score = 0.1075, loss = 0.1014, eval: [6.8 s]
# # Iteration 13 fit: [35.5 s]: Recall = 0.1271, Jaccard score = 0.1051, loss = 0.0910, eval: [6.6 s]
# # Iteration 14 fit: [35.3 s]: Recall = 0.1293, Jaccard score = 0.1070, loss = 0.0838, eval: [6.6 s]
# # Iteration 15 fit: [35.4 s]: Recall = 0.1317, Jaccard score = 0.1093, loss = 0.0760, eval: [7.1 s]
# # Iteration 16 fit: [36.0 s]: Recall = 0.1261, Jaccard score = 0.1042, loss = 0.0699, eval: [8.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564000714.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564000714.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'TypeError'>: The `BatchNormalization` layer does not accept positional arguments. Use keyword arguments instead.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564046630.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564046630.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0267, Jaccard score = 0.0204
# # Iteration 0 fit: [14.8 s]: Recall = 0.1668, Jaccard score = 0.1425, loss = 0.4372, eval: [7.2 s]
# # Iteration 1 fit: [14.2 s]: Recall = 0.1833, Jaccard score = 0.1588, loss = 0.3983, eval: [7.2 s]
# # Iteration 2 fit: [14.2 s]: Recall = 0.1901, Jaccard score = 0.1657, loss = 0.3796, eval: [7.3 s]
# # Iteration 3 fit: [14.2 s]: Recall = 0.1920, Jaccard score = 0.1677, loss = 0.3632, eval: [7.3 s]
# # Iteration 4 fit: [14.2 s]: Recall = 0.1923, Jaccard score = 0.1680, loss = 0.3473, eval: [7.3 s]
# # Iteration 5 fit: [14.3 s]: Recall = 0.1902, Jaccard score = 0.1658, loss = 0.3327, eval: [7.3 s]
# # Iteration 6 fit: [14.2 s]: Recall = 0.1866, Jaccard score = 0.1622, loss = 0.3162, eval: [7.3 s]
# # Iteration 7 fit: [14.2 s]: Recall = 0.1805, Jaccard score = 0.1560, loss = 0.3011, eval: [7.3 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564046841.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564046841.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0239, Jaccard score = 0.0182
# # Iteration 0 fit: [26.1 s]: Recall = 0.1619, Jaccard score = 0.1377, loss = 0.4327, eval: [7.2 s]
# # Iteration 1 fit: [24.4 s]: Recall = 0.1820, Jaccard score = 0.1576, loss = 0.3929, eval: [7.4 s]
# # Iteration 2 fit: [24.4 s]: Recall = 0.1875, Jaccard score = 0.1631, loss = 0.3648, eval: [7.3 s]
# # Iteration 3 fit: [24.4 s]: Recall = 0.1852, Jaccard score = 0.1608, loss = 0.3367, eval: [7.2 s]
# # Iteration 4 fit: [24.4 s]: Recall = 0.1799, Jaccard score = 0.1555, loss = 0.3087, eval: [7.2 s]
# # Iteration 5 fit: [24.5 s]: Recall = 0.1734, Jaccard score = 0.1490, loss = 0.2826, eval: [7.3 s]
# # Iteration 6 fit: [24.4 s]: Recall = 0.1679, Jaccard score = 0.1436, loss = 0.2587, eval: [7.2 s]
# # Iteration 7 fit: [24.5 s]: Recall = 0.1568, Jaccard score = 0.1329, loss = 0.2365, eval: [7.3 s]
# # Iteration 8 fit: [24.4 s]: Recall = 0.1530, Jaccard score = 0.1292, loss = 0.2151, eval: [7.2 s]
# # Iteration 9 fit: [24.4 s]: Recall = 0.1486, Jaccard score = 0.1250, loss = 0.1959, eval: [7.3 s]
# # Iteration 10 fit: [24.6 s]: Recall = 0.1439, Jaccard score = 0.1206, loss = 0.1782, eval: [7.4 s]
# # Iteration 11 fit: [24.4 s]: Recall = 0.1409, Jaccard score = 0.1177, loss = 0.1620, eval: [7.2 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564047326.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564047326.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0271, Jaccard score = 0.0207


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564048816.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564048816.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0253, Jaccard score = 0.0193
# # Iteration 0 fit: [23.8 s]: Recall = 0.1653, Jaccard score = 0.1411, loss = 0.4310, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564048880.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564048880.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0229, Jaccard score = 0.0174
# # Iteration 0 fit: [13.0 s]: Recall = 0.1693, Jaccard score = 0.1450, loss = 0.4352, eval: [6.6 s]
# # Iteration 1 fit: [12.6 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3941, eval: [6.7 s]
# # Iteration 2 fit: [12.8 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3728, eval: [6.6 s]
# # Iteration 3 fit: [12.6 s]: Recall = 0.1923, Jaccard score = 0.1679, loss = 0.3553, eval: [6.7 s]
# # Iteration 4 fit: [12.6 s]: Recall = 0.1955, Jaccard score = 0.1712, loss = 0.3388, eval: [6.7 s]
# # Iteration 5 fit: [12.6 s]: Recall = 0.1925, Jaccard score = 0.1682, loss = 0.3231, eval: [6.6 s]
# # Iteration 6 fit: [12.6 s]: Recall = 0.1891, Jaccard score = 0.1647, loss = 0.3066, eval: [6.5 s]
# # Iteration 7 fit: [12.8 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.2914, eval: [6.7 s]
# # Iteration 8 fit: [12.6 s]: Recall = 0.1807, Jaccard score = 0.1563, loss = 0.2774, eval: [7.8 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564049087.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564049087.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0275, Jaccard score = 0.0210
# # Iteration 0 fit: [14.8 s]: Recall = 0.1690, Jaccard score = 0.1447, loss = 0.4409, eval: [7.1 s]
# # Iteration 1 fit: [14.3 s]: Recall = 0.1844, Jaccard score = 0.1600, loss = 0.3964, eval: [7.3 s]
# # Iteration 2 fit: [15.7 s]: Recall = 0.1905, Jaccard score = 0.1661, loss = 0.3765, eval: [8.7 s]
# # Iteration 3 fit: [14.3 s]: Recall = 0.1929, Jaccard score = 0.1686, loss = 0.3611, eval: [7.1 s]
# # Iteration 4 fit: [14.3 s]: Recall = 0.1932, Jaccard score = 0.1689, loss = 0.3450, eval: [7.2 s]
# # Iteration 5 fit: [14.3 s]: Recall = 0.1880, Jaccard score = 0.1636, loss = 0.3310, eval: [7.1 s]
# # Iteration 6 fit: [14.3 s]: Recall = 0.1887, Jaccard score = 0.1643, loss = 0.3155, eval: [7.2 s]
# # Iteration 7 fit: [14.6 s]: Recall = 0.1843, Jaccard score = 0.1599, loss = 0.3002, eval: [7.2 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564049294.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564049294.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0266, Jaccard score = 0.0203
# # Iteration 0 fit: [14.5 s]: Recall = 0.1493, Jaccard score = 0.1257, loss = 0.4497, eval: [6.8 s]
# # Iteration 1 fit: [13.0 s]: Recall = 0.1665, Jaccard score = 0.1423, loss = 0.4164, eval: [6.9 s]
# # Iteration 2 fit: [13.0 s]: Recall = 0.1809, Jaccard score = 0.1565, loss = 0.4038, eval: [6.8 s]
# # Iteration 3 fit: [13.1 s]: Recall = 0.1841, Jaccard score = 0.1597, loss = 0.3909, eval: [6.7 s]
# # Iteration 4 fit: [13.0 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3802, eval: [6.7 s]
# # Iteration 5 fit: [13.1 s]: Recall = 0.1915, Jaccard score = 0.1672, loss = 0.3690, eval: [6.8 s]
# # Iteration 6 fit: [13.0 s]: Recall = 0.1913, Jaccard score = 0.1670, loss = 0.3581, eval: [6.8 s]
# # Iteration 7 fit: [13.0 s]: Recall = 0.1919, Jaccard score = 0.1675, loss = 0.3486, eval: [6.7 s]
# # Iteration 8 fit: [13.0 s]: Recall = 0.1890, Jaccard score = 0.1646, loss = 0.3393, eval: [6.8 s]
# # Iteration 9 fit: [13.0 s]: Recall = 0.1889, Jaccard score = 0.1646, loss = 0.3311, eval: [6.8 s]
# # Iteration 10 fit: [12.9 s]: Recall = 0.1871, Jaccard score = 0.1627, loss = 0.3236, eval: [6.8 s]
# # Iteration 11 fit: [13.0 s]: Recall = 0.1879, Jaccard score = 0.1635, loss = 0.3170, eval: [6.9 s]
# # Iteration 12 fit: [12.9 s]: Recall = 0.1834, Jaccard score = 0.1589, loss = 0.3109, eval: [6.7 s]
# # Iteration 13 fit: [13.0 s]: Recall = 0.1837, Jaccard score = 0.1592, loss = 0.3041, eval: [6.8 s]
# # Iteration 14 fit: [13.0 s]: Recall = 0.1814, Jaccard score = 0.1569, loss = 0.2991, eval: [6.7 s]
# # Iteration 15 fit: [13.0 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.2937, eval: [6.7 s]
# # Iteration 16 fit: [12.9 s]: Recall = 0.1787, Jaccard score = 0.1542, loss = 0.2896, eval: [6.7 s]
# # Iteration 17 fit: [13.0 s]: Recall = 0.1749, Jaccard score = 0.1505, loss = 0.2845, eval: [6.8 s]
# # Iteration 18 fit: [12.9 s]: Recall = 0.1745, Jaccard score = 0.1501, loss = 0.2792, eval: [6.8 s]
# # Iteration 19 fit: [12.9 s]: Recall = 0.1739, Jaccard score = 0.1495, loss = 0.2754, eval: [6.7 s]
# # Iteration 20 fit: [13.0 s]: Recall = 0.1728, Jaccard score = 0.1484, loss = 0.2719, eval: [6.7 s]
# # Iteration 21 fit: [13.0 s]: Recall = 0.1690, Jaccard score = 0.1447, loss = 0.2681, eval: [6.8 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564057538.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564057538.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0281, Jaccard score = 0.0215
# # Iteration 0 fit: [11.8 s]: Recall = 0.1589, Jaccard score = 0.1349, loss = 0.4470, eval: [6.6 s]
# # Iteration 1 fit: [11.7 s]: Recall = 0.1727, Jaccard score = 0.1483, loss = 0.4133, eval: [6.7 s]
# # Iteration 2 fit: [11.3 s]: Recall = 0.1841, Jaccard score = 0.1597, loss = 0.3998, eval: [6.7 s]
# # Iteration 3 fit: [11.4 s]: Recall = 0.1869, Jaccard score = 0.1625, loss = 0.3892, eval: [6.7 s]
# # Iteration 4 fit: [11.4 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3795, eval: [6.7 s]
# # Iteration 5 fit: [12.4 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3714, eval: [8.5 s]
# # Iteration 6 fit: [12.9 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3636, eval: [6.6 s]
# # Iteration 7 fit: [11.4 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3569, eval: [6.7 s]
# # Iteration 8 fit: [11.9 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3495, eval: [6.6 s]
# # Iteration 9 fit: [11.4 s]: Recall = 0.1951, Jaccard score = 0.1708, loss = 0.3432, eval: [6.6 s]
# # Iteration 10 fit: [11.7 s]: Recall = 0.1955, Jaccard score = 0.1713, loss = 0.3371, eval: [6.7 s]
# # Iteration 11 fit: [11.4 s]: Recall = 0.1936, Jaccard score = 0.1693, loss = 0.3315, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564057782.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564057782.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <keras.engine.training.Model object at 0x7f0f6a95d2b0>
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0249, Jaccard score = 0.0190


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564057804.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564057804.h5
# # Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 10)        200000      user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 10)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1010)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1074)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          137600      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # dropout_1 (Dropout)             (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           dropout_1[0][0]                  
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 465,729
# # Trainable params: 465,729
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0263, Jaccard score = 0.0201
# # Iteration 0 fit: [11.5 s]: Recall = 0.1578, Jaccard score = 0.1338, loss = 0.4435, eval: [6.6 s]
# # Iteration 1 fit: [10.7 s]: Recall = 0.1750, Jaccard score = 0.1506, loss = 0.4133, eval: [6.6 s]
# # Iteration 2 fit: [10.8 s]: Recall = 0.1813, Jaccard score = 0.1569, loss = 0.3990, eval: [6.7 s]
# # Iteration 3 fit: [10.7 s]: Recall = 0.1864, Jaccard score = 0.1620, loss = 0.3892, eval: [6.6 s]
# # Iteration 4 fit: [10.7 s]: Recall = 0.1912, Jaccard score = 0.1668, loss = 0.3802, eval: [6.7 s]
# # Iteration 5 fit: [10.8 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3725, eval: [6.6 s]
# # Iteration 6 fit: [10.7 s]: Recall = 0.1971, Jaccard score = 0.1729, loss = 0.3651, eval: [6.6 s]
# # Iteration 7 fit: [10.7 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3591, eval: [6.7 s]
# # Iteration 8 fit: [10.7 s]: Recall = 0.1978, Jaccard score = 0.1736, loss = 0.3536, eval: [6.8 s]
# # Iteration 9 fit: [10.7 s]: Recall = 0.1977, Jaccard score = 0.1735, loss = 0.3477, eval: [6.8 s]
# # Iteration 10 fit: [10.7 s]: Recall = 0.1967, Jaccard score = 0.1725, loss = 0.3429, eval: [6.6 s]
# # Iteration 11 fit: [10.8 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.3380, eval: [6.6 s]
# # Iteration 12 fit: [10.7 s]: Recall = 0.1940, Jaccard score = 0.1697, loss = 0.3331, eval: [6.9 s]
# # Iteration 13 fit: [10.8 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3291, eval: [6.6 s]
# # Iteration 14 fit: [10.7 s]: Recall = 0.1966, Jaccard score = 0.1724, loss = 0.3253, eval: [6.7 s]
# # Iteration 15 fit: [10.7 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3207, eval: [6.8 s]
# # Iteration 16 fit: [10.8 s]: Recall = 0.1971, Jaccard score = 0.1729, loss = 0.3177, eval: [6.6 s]
# # Iteration 17 fit: [10.7 s]: Recall = 0.1948, Jaccard score = 0.1705, loss = 0.3142, eval: [6.6 s]
# # Iteration 18 fit: [10.7 s]: Recall = 0.1922, Jaccard score = 0.1679, loss = 0.3112, eval: [6.6 s]
# # Iteration 19 fit: [10.8 s]: Recall = 0.1918, Jaccard score = 0.1675, loss = 0.3081, eval: [6.6 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058172.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058172.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 10)        200000      user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 10)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1010)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1074)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          137600      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # dropout_1 (Dropout)             (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           dropout_1[0][0]                  
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # dropout_2 (Dropout)             (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           dropout_2[0][0]                  
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 482,241
# # Trainable params: 482,241
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0271, Jaccard score = 0.0207
# # Iteration 0 fit: [12.0 s]: Recall = 0.1711, Jaccard score = 0.1467, loss = 0.4493, eval: [6.7 s]
# # Iteration 1 fit: [11.5 s]: Recall = 0.1861, Jaccard score = 0.1617, loss = 0.4120, eval: [6.9 s]
# # Iteration 2 fit: [11.5 s]: Recall = 0.1933, Jaccard score = 0.1690, loss = 0.4011, eval: [6.9 s]
# # Iteration 3 fit: [11.9 s]: Recall = 0.1952, Jaccard score = 0.1710, loss = 0.3915, eval: [6.9 s]
# # Iteration 4 fit: [11.6 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3841, eval: [6.9 s]
# # Iteration 5 fit: [11.9 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3775, eval: [6.9 s]
# # Iteration 6 fit: [11.5 s]: Recall = 0.1992, Jaccard score = 0.1751, loss = 0.3721, eval: [6.9 s]
# # Iteration 7 fit: [11.5 s]: Recall = 0.1983, Jaccard score = 0.1741, loss = 0.3662, eval: [6.9 s]
# # Iteration 8 fit: [12.0 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3614, eval: [6.9 s]
# # Iteration 9 fit: [11.5 s]: Recall = 0.2000, Jaccard score = 0.1758, loss = 0.3564, eval: [6.8 s]
# # Iteration 10 fit: [11.5 s]: Recall = 0.1991, Jaccard score = 0.1749, loss = 0.3521, eval: [6.8 s]
# # Iteration 11 fit: [11.6 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3470, eval: [6.9 s]
# # Iteration 12 fit: [11.5 s]: Recall = 0.1968, Jaccard score = 0.1726, loss = 0.3427, eval: [6.8 s]
# # Iteration 13 fit: [11.5 s]: Recall = 0.1937, Jaccard score = 0.1694, loss = 0.3383, eval: [6.9 s]
# # Iteration 14 fit: [11.5 s]: Recall = 0.1944, Jaccard score = 0.1701, loss = 0.3345, eval: [6.7 s]
# # Iteration 15 fit: [11.5 s]: Recall = 0.1975, Jaccard score = 0.1733, loss = 0.3310, eval: [6.9 s]
# # Iteration 16 fit: [11.5 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3274, eval: [6.7 s]
# # Iteration 17 fit: [11.5 s]: Recall = 0.1959, Jaccard score = 0.1717, loss = 0.3239, eval: [6.9 s]
# # Iteration 18 fit: [11.9 s]: Recall = 0.1951, Jaccard score = 0.1709, loss = 0.3206, eval: [6.9 s]
# # Iteration 19 fit: [11.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3178, eval: [8.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058569.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058569.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1064)         0           flatten_1[0][0]                  
# #                                                                  user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1128)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          144512      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 1,569,153
# # Trainable params: 1,569,153
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0296, Jaccard score = 0.0226
# # Iteration 0 fit: [13.5 s]: Recall = 0.1769, Jaccard score = 0.1525, loss = 0.4295, eval: [6.8 s]
# # Iteration 1 fit: [13.0 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.3854, eval: [6.8 s]
# # Iteration 2 fit: [13.0 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3648, eval: [6.9 s]
# # Iteration 3 fit: [13.1 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3482, eval: [6.8 s]
# # Iteration 4 fit: [13.1 s]: Recall = 0.1941, Jaccard score = 0.1698, loss = 0.3322, eval: [6.9 s]
# # Iteration 5 fit: [13.1 s]: Recall = 0.1920, Jaccard score = 0.1677, loss = 0.3167, eval: [6.7 s]
# # Iteration 6 fit: [13.1 s]: Recall = 0.1877, Jaccard score = 0.1633, loss = 0.3011, eval: [6.8 s]
# # Iteration 7 fit: [13.1 s]: Recall = 0.1853, Jaccard score = 0.1609, loss = 0.2862, eval: [6.7 s]
# # Iteration 8 fit: [15.0 s]: Recall = 0.1803, Jaccard score = 0.1559, loss = 0.2713, eval: [7.6 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058767.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058767.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'ValueError'>: Graph disconnected: cannot obtain value for tensor Tensor("user_features:0", shape=(?, 1000), dtype=float32) at layer "user_features". The following previous layers were accessed without issue: ['user_input', 'item_input']


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564058944.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564058944.h5
# # Load data done [1.8 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'TypeError'>: Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059632.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059632.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # <class 'TypeError'>: Input 'b' of 'MatMul' Op has type float32 that does not match type int32 of argument 'a'.


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059642.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059642.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059662.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059662.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059710.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059710.h5
# # Load data done [4.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564059729.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564059729.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060094.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060094.h5
# # Load data done [3.9 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060232.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060232.h5
# # Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 256)          0           dense_feature_layer[0][0]        
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 320)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          41088       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 313,857
# # Trainable params: 313,857
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0273, Jaccard score = 0.0208
# # Iteration 0 fit: [11.1 s]: Recall = 0.1861, Jaccard score = 0.1617, loss = 0.4188, eval: [6.8 s]
# # Iteration 1 fit: [11.2 s]: Recall = 0.1961, Jaccard score = 0.1718, loss = 0.3824, eval: [6.7 s]
# # Iteration 2 fit: [11.1 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3670, eval: [6.8 s]
# # Iteration 3 fit: [11.1 s]: Recall = 0.1989, Jaccard score = 0.1747, loss = 0.3558, eval: [6.7 s]
# # Iteration 4 fit: [11.2 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3474, eval: [6.8 s]
# # Iteration 5 fit: [11.2 s]: Recall = 0.2022, Jaccard score = 0.1782, loss = 0.3401, eval: [6.6 s]
# # Iteration 6 fit: [11.0 s]: Recall = 0.2020, Jaccard score = 0.1780, loss = 0.3328, eval: [6.8 s]
# # Iteration 7 fit: [11.2 s]: Recall = 0.1972, Jaccard score = 0.1730, loss = 0.3273, eval: [6.8 s]
# # Iteration 8 fit: [11.2 s]: Recall = 0.1997, Jaccard score = 0.1756, loss = 0.3217, eval: [6.7 s]
# # Iteration 9 fit: [14.1 s]: Recall = 0.1980, Jaccard score = 0.1738, loss = 0.3161, eval: [6.7 s]
# # Iteration 10 fit: [10.7 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3111, eval: [6.8 s]
# # Iteration 11 fit: [11.1 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3056, eval: [6.6 s]
# # Iteration 12 fit: [11.1 s]: Recall = 0.1967, Jaccard score = 0.1725, loss = 0.3012, eval: [6.8 s]
# # Iteration 13 fit: [11.6 s]: Recall = 0.1953, Jaccard score = 0.1710, loss = 0.2971, eval: [6.8 s]
# # Iteration 14 fit: [11.2 s]: Recall = 0.1955, Jaccard score = 0.1712, loss = 0.2932, eval: [6.8 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060531.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060531.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 256)          0           dense_feature_layer[0][0]        
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 320)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          41088       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 313,857
# # Trainable params: 313,857
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0225, Jaccard score = 0.0171
# # Iteration 0 fit: [11.6 s]: Recall = 0.1847, Jaccard score = 0.1602, loss = 0.4185, eval: [8.4 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060587.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060587.h5
# # Load data done [4.0 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 256)          0           dense_feature_layer[0][0]        
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 320)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          41088       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 313,857
# # Trainable params: 313,857
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060656.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060656.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer (Dense)     (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 192)          0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer[0][0]        
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 256)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          32896       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 1,585,665
# # Trainable params: 1,585,665
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0303, Jaccard score = 0.0232
# # Iteration 0 fit: [13.9 s]: Recall = 0.1758, Jaccard score = 0.1514, loss = 0.4315, eval: [6.8 s]
# # Iteration 1 fit: [13.5 s]: Recall = 0.1879, Jaccard score = 0.1635, loss = 0.3885, eval: [6.8 s]
# # Iteration 2 fit: [13.4 s]: Recall = 0.1960, Jaccard score = 0.1717, loss = 0.3683, eval: [6.8 s]
# # Iteration 3 fit: [13.4 s]: Recall = 0.1961, Jaccard score = 0.1718, loss = 0.3525, eval: [6.9 s]
# # Iteration 4 fit: [13.8 s]: Recall = 0.1962, Jaccard score = 0.1720, loss = 0.3388, eval: [8.7 s]
# # Iteration 5 fit: [14.5 s]: Recall = 0.1917, Jaccard score = 0.1674, loss = 0.3255, eval: [6.7 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128,128]_1564060810.h5
# --weights_path: Pretrain/_MLP_8_[128,128,128]_1564060810.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer2 (Dense)    (None, 128)          16512       dense_feature_layer1[0][0]       
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 192)          0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer2[0][0]       
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 256)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          32896       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # layer2 (Dense)                  (None, 128)          16512       activation_1[0][0]               
# # __________________________________________________________________________________________________
# # activation_2 (Activation)       (None, 128)          0           layer2[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_2[0][0]               
# # ==================================================================================================
# # Total params: 1,602,177
# # Trainable params: 1,602,177
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0313, Jaccard score = 0.0240
# # Iteration 0 fit: [14.8 s]: Recall = 0.1758, Jaccard score = 0.1514, loss = 0.4315, eval: [6.9 s]
# # Iteration 1 fit: [14.3 s]: Recall = 0.1893, Jaccard score = 0.1650, loss = 0.3903, eval: [7.0 s]
# # Iteration 2 fit: [14.2 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3724, eval: [7.0 s]
# # Iteration 3 fit: [14.3 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.3572, eval: [6.9 s]
# # Iteration 4 fit: [14.6 s]: Recall = 0.1916, Jaccard score = 0.1673, loss = 0.3446, eval: [6.9 s]
# # Iteration 5 fit: [14.2 s]: Recall = 0.1893, Jaccard score = 0.1650, loss = 0.3315, eval: [7.0 s]
# # Iteration 6 fit: [14.2 s]: Recall = 0.1874, Jaccard score = 0.1630, loss = 0.3185, eval: [6.9 s]
# # Iteration 7 fit: [14.4 s]: Recall = 0.1837, Jaccard score = 0.1592, loss = 0.3057, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564061014.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564061014.h5
# # Load data done [1.6 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 128)          128128      user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 192)          0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer1[0][0]       
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 256)          0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          32896       concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 1,569,153
# # Trainable params: 1,569,153
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0243, Jaccard score = 0.0185
# # Iteration 0 fit: [13.4 s]: Recall = 0.1684, Jaccard score = 0.1441, loss = 0.4355, eval: [6.7 s]
# # Iteration 1 fit: [13.0 s]: Recall = 0.1821, Jaccard score = 0.1577, loss = 0.3938, eval: [6.7 s]
# # Iteration 2 fit: [13.0 s]: Recall = 0.1915, Jaccard score = 0.1671, loss = 0.3728, eval: [6.7 s]
# # Iteration 3 fit: [13.0 s]: Recall = 0.1942, Jaccard score = 0.1699, loss = 0.3571, eval: [6.7 s]
# # Iteration 4 fit: [13.0 s]: Recall = 0.1928, Jaccard score = 0.1685, loss = 0.3420, eval: [6.7 s]
# # Iteration 5 fit: [13.0 s]: Recall = 0.1925, Jaccard score = 0.1682, loss = 0.3280, eval: [6.8 s]
# # Iteration 6 fit: [13.0 s]: Recall = 0.1878, Jaccard score = 0.1634, loss = 0.3134, eval: [6.7 s]
# # Iteration 7 fit: [13.0 s]: Recall = 0.1818, Jaccard score = 0.1573, loss = 0.2987, eval: [6.8 s]
# # Iteration 8 fit: [13.0 s]: Recall = 0.1776, Jaccard score = 0.1532, loss = 0.2838, eval: [6.6 s]
# # Iteration 9 fit: [13.0 s]: Recall = 0.1751, Jaccard score = 0.1507, loss = 0.2716, eval: [6.8 s]
# # Iteration 10 fit: [13.0 s]: Recall = 0.1747, Jaccard score = 0.1503, loss = 0.2583, eval: [6.6 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564061555.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564061555.h5
# # Load data done [1.7 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # user_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_embedding (Embedding)      (None, 1, 64)        1280000     user_input[0][0]                 
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # flatten_1 (Flatten)             (None, 64)           0           user_embedding[0][0]             
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # concatenate_1 (Concatenate)     (None, 1088)         0           flatten_1[0][0]                  
# #                                                                  dense_feature_layer1[0][0]       
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_2 (Concatenate)     (None, 1152)         0           concatenate_1[0][0]              
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          147584      concatenate_2[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 2,580,737
# # Trainable params: 2,580,737
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0334, Jaccard score = 0.0256
# # Iteration 0 fit: [16.4 s]: Recall = 0.1649, Jaccard score = 0.1407, loss = 0.4361, eval: [6.8 s]
# # Iteration 1 fit: [16.1 s]: Recall = 0.1835, Jaccard score = 0.1591, loss = 0.3981, eval: [6.7 s]
# # Iteration 2 fit: [16.2 s]: Recall = 0.1915, Jaccard score = 0.1671, loss = 0.3786, eval: [6.8 s]
# # Iteration 3 fit: [16.2 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3626, eval: [6.9 s]
# # Iteration 4 fit: [16.2 s]: Recall = 0.1949, Jaccard score = 0.1706, loss = 0.3482, eval: [7.0 s]
# # Iteration 5 fit: [16.1 s]: Recall = 0.1940, Jaccard score = 0.1697, loss = 0.3344, eval: [8.6 s]
# # Iteration 6 fit: [17.0 s]: Recall = 0.1906, Jaccard score = 0.1662, loss = 0.3209, eval: [7.0 s]
# # Iteration 7 fit: [16.0 s]: Recall = 0.1867, Jaccard score = 0.1623, loss = 0.3080, eval: [6.8 s]
# # Iteration 8 fit: [15.8 s]: Recall = 0.1836, Jaccard score = 0.1592, loss = 0.2955, eval: [7.0 s]
# # Iteration 9 fit: [16.1 s]: Recall = 0.1806, Jaccard score = 0.1561, loss = 0.2838, eval: [6.8 s]
# # Iteration 10 fit: [16.1 s]: Recall = 0.1765, Jaccard score = 0.1520, loss = 0.2729, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[128,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[128,128]_1564061882.h5
# --weights_path: Pretrain/_MLP_8_[128,128]_1564061882.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 64)        128000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 64)           0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_3 (Concatenate)     (None, 1088)         0           dense_feature_layer1[0][0]       
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          139392      concatenate_3[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 1,292,545
# # Trainable params: 1,292,545
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0338, Jaccard score = 0.0260
# # Iteration 0 fit: [13.1 s]: Recall = 0.1759, Jaccard score = 0.1514, loss = 0.4314, eval: [6.8 s]
# # Iteration 1 fit: [12.7 s]: Recall = 0.1865, Jaccard score = 0.1621, loss = 0.3941, eval: [6.9 s]
# # Iteration 2 fit: [12.8 s]: Recall = 0.1930, Jaccard score = 0.1687, loss = 0.3777, eval: [6.9 s]
# # Iteration 3 fit: [13.0 s]: Recall = 0.1938, Jaccard score = 0.1695, loss = 0.3645, eval: [6.8 s]
# # Iteration 4 fit: [12.7 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3554, eval: [6.8 s]
# # Iteration 5 fit: [13.0 s]: Recall = 0.1993, Jaccard score = 0.1751, loss = 0.3477, eval: [7.0 s]
# # Iteration 6 fit: [12.8 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3408, eval: [6.9 s]
# # Iteration 7 fit: [12.8 s]: Recall = 0.1999, Jaccard score = 0.1758, loss = 0.3355, eval: [6.9 s]
# # Iteration 8 fit: [12.9 s]: Recall = 0.2019, Jaccard score = 0.1779, loss = 0.3303, eval: [6.9 s]
# # Iteration 9 fit: [12.7 s]: Recall = 0.2019, Jaccard score = 0.1779, loss = 0.3259, eval: [7.0 s]
# # Iteration 10 fit: [12.7 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3209, eval: [6.8 s]
# # Iteration 11 fit: [13.0 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3164, eval: [7.0 s]
# # Iteration 12 fit: [12.7 s]: Recall = 0.2000, Jaccard score = 0.1759, loss = 0.3122, eval: [6.9 s]
# # Iteration 13 fit: [12.7 s]: Recall = 0.2027, Jaccard score = 0.1786, loss = 0.3087, eval: [6.8 s]
# # Iteration 14 fit: [12.7 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3045, eval: [6.9 s]
# # Iteration 15 fit: [12.7 s]: Recall = 0.1986, Jaccard score = 0.1744, loss = 0.3014, eval: [6.9 s]
# # Iteration 16 fit: [12.7 s]: Recall = 0.1996, Jaccard score = 0.1754, loss = 0.2978, eval: [6.8 s]
# # Iteration 17 fit: [12.8 s]: Recall = 0.1992, Jaccard score = 0.1750, loss = 0.2942, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[512,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[512,128]_1564062257.h5
# --weights_path: Pretrain/_MLP_8_[512,128]_1564062257.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 256)       512000      item_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 256)          0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_3 (Concatenate)     (None, 1280)         0           dense_feature_layer1[0][0]       
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          163968      concatenate_3[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 1,701,121
# # Trainable params: 1,701,121
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0286, Jaccard score = 0.0219
# # Iteration 0 fit: [14.6 s]: Recall = 0.1896, Jaccard score = 0.1652, loss = 0.4109, eval: [6.9 s]
# # Iteration 1 fit: [14.2 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3717, eval: [6.9 s]
# # Iteration 2 fit: [14.2 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3541, eval: [7.0 s]
# # Iteration 3 fit: [14.1 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3431, eval: [6.8 s]
# # Iteration 4 fit: [14.1 s]: Recall = 0.2019, Jaccard score = 0.1779, loss = 0.3337, eval: [7.0 s]
# # Iteration 5 fit: [14.1 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3258, eval: [7.0 s]
# # Iteration 6 fit: [14.2 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3193, eval: [6.9 s]
# # Iteration 7 fit: [14.1 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.3117, eval: [6.9 s]
# # Iteration 8 fit: [14.1 s]: Recall = 0.2034, Jaccard score = 0.1795, loss = 0.3056, eval: [7.0 s]
# # Iteration 9 fit: [14.1 s]: Recall = 0.2046, Jaccard score = 0.1807, loss = 0.2996, eval: [6.8 s]
# # Iteration 10 fit: [14.0 s]: Recall = 0.2069, Jaccard score = 0.1831, loss = 0.2942, eval: [7.0 s]
# # Iteration 11 fit: [14.3 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.2882, eval: [7.0 s]
# # Iteration 12 fit: [14.0 s]: Recall = 0.2005, Jaccard score = 0.1764, loss = 0.2833, eval: [7.0 s]
# # Iteration 13 fit: [14.1 s]: Recall = 0.2001, Jaccard score = 0.1760, loss = 0.2786, eval: [6.8 s]
# # Iteration 14 fit: [14.1 s]: Recall = 0.1999, Jaccard score = 0.1758, loss = 0.2735, eval: [7.0 s]
# # Iteration 15 fit: [14.1 s]: Recall = 0.2015, Jaccard score = 0.1774, loss = 0.2692, eval: [6.8 s]
# # Iteration 16 fit: [14.1 s]: Recall = 0.1991, Jaccard score = 0.1750, loss = 0.2655, eval: [7.0 s]
# # Iteration 17 fit: [14.3 s]: Recall = 0.1971, Jaccard score = 0.1729, loss = 0.2614, eval: [6.9 s]
# # Iteration 18 fit: [14.1 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.2570, eval: [7.0 s]
# # Iteration 19 fit: [14.1 s]: Recall = 0.1975, Jaccard score = 0.1733, loss = 0.2528, eval: [6.9 s]
# # Iteration 20 fit: [14.1 s]: Recall = 0.1981, Jaccard score = 0.1739, loss = 0.2494, eval: [7.0 s]
# # Iteration 21 fit: [14.1 s]: Recall = 0.1972, Jaccard score = 0.1730, loss = 0.2468, eval: [6.8 s]
# # Iteration 22 fit: [14.1 s]: Recall = 0.1944, Jaccard score = 0.1702, loss = 0.2432, eval: [7.0 s]


# # Launched by terminal.
# # MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# # The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1564062791.h5
# --weights_path: Pretrain/_MLP_8_[1024,128]_1564062791.h5
# # Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# # __________________________________________________________________________________________________
# # Layer (type)                    Output Shape         Param #     Connected to                     
# # ==================================================================================================
# # item_input (InputLayer)         (None, 1)            0                                            
# # __________________________________________________________________________________________________
# # user_features (InputLayer)      (None, 1000)         0                                            
# # __________________________________________________________________________________________________
# # item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# # __________________________________________________________________________________________________
# # dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# # __________________________________________________________________________________________________
# # flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# # __________________________________________________________________________________________________
# # concatenate_3 (Concatenate)     (None, 1536)         0           dense_feature_layer1[0][0]       
# #                                                                  flatten_2[0][0]                  
# # __________________________________________________________________________________________________
# # layer1 (Dense)                  (None, 128)          196736      concatenate_3[0][0]              
# # __________________________________________________________________________________________________
# # activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# # __________________________________________________________________________________________________
# # prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# # ==================================================================================================
# # Total params: 2,245,889
# # Trainable params: 2,245,889
# # Non-trainable params: 0
# # __________________________________________________________________________________________________
# # None
# # 
# # Performing k-fold 1
# # Init: Recall = 0.0289, Jaccard score = 0.0221
# # Iteration 0 fit: [15.9 s]: Recall = 0.1920, Jaccard score = 0.1676, loss = 0.4040, eval: [7.0 s]
# # Iteration 1 fit: [15.3 s]: Recall = 0.2020, Jaccard score = 0.1779, loss = 0.3644, eval: [7.0 s]
# # Iteration 2 fit: [15.3 s]: Recall = 0.2078, Jaccard score = 0.1840, loss = 0.3477, eval: [7.0 s]
# # Iteration 3 fit: [15.2 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.3368, eval: [7.0 s]
# # Iteration 4 fit: [15.6 s]: Recall = 0.2066, Jaccard score = 0.1827, loss = 0.3274, eval: [6.9 s]
# # Iteration 5 fit: [15.4 s]: Recall = 0.2057, Jaccard score = 0.1818, loss = 0.3193, eval: [7.0 s]
# # Iteration 6 fit: [15.4 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.3123, eval: [6.8 s]
# # Iteration 7 fit: [15.3 s]: Recall = 0.2055, Jaccard score = 0.1816, loss = 0.3053, eval: [7.0 s]
# # Iteration 8 fit: [15.5 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.2978, eval: [6.9 s]
# # Iteration 9 fit: [15.3 s]: Recall = 0.2057, Jaccard score = 0.1818, loss = 0.2923, eval: [7.0 s]
# # Iteration 10 fit: [15.3 s]: Recall = 0.2031, Jaccard score = 0.1791, loss = 0.2860, eval: [7.0 s]
# # Iteration 11 fit: [15.3 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.2807, eval: [6.9 s]
# # Iteration 12 fit: [15.3 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.2745, eval: [7.0 s]
# # Iteration 13 fit: [15.6 s]: Recall = 0.2000, Jaccard score = 0.1758, loss = 0.2688, eval: [7.0 s]
# # Iteration 14 fit: [15.2 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.2637, eval: [7.0 s]
# # Iteration 15 fit: [15.4 s]: Recall = 0.1967, Jaccard score = 0.1725, loss = 0.2588, eval: [6.9 s]
# # Iteration 16 fit: [15.3 s]: Recall = 0.1992, Jaccard score = 0.1750, loss = 0.2544, eval: [7.0 s]
# # Iteration 17 fit: [15.6 s]: Recall = 0.1980, Jaccard score = 0.1738, loss = 0.2496, eval: [7.0 s]
# # Iteration 18 fit: [15.3 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.2456, eval: [7.1 s]


# Launched by terminal.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='cold_0.0_', early_stopping=35, epochs=300, eval_recall=1, is_tag=1, layers='[1024,128]', learner='adagrad', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.0, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_MLP_8_[1024,128]_1564063268.h5
--weights_path: Pretrain/_MLP_8_[1024,128]_1564063268.h5
# Load data done [1.5 s]. #user=20000, #item=2000, #train=143502, #test=eval_recall
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_features (InputLayer)      (None, 1000)         0                                            
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 512)       1024000     item_input[0][0]                 
# __________________________________________________________________________________________________
# dense_feature_layer1 (Dense)    (None, 1024)         1025024     user_features[0][0]              
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 512)          0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_3 (Concatenate)     (None, 1536)         0           dense_feature_layer1[0][0]       
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 128)          196736      concatenate_3[0][0]              
# __________________________________________________________________________________________________
# activation_1 (Activation)       (None, 128)          0           layer1[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            129         activation_1[0][0]               
# ==================================================================================================
# Total params: 2,245,889
# Trainable params: 2,245,889
# Non-trainable params: 0
# __________________________________________________________________________________________________
# None
# 
# Performing k-fold 1
# Init: Recall = 0.0292, Jaccard score = 0.0223
# Iteration 0 fit: [13.8 s]: Recall = 0.1492, Jaccard score = 0.1256, loss = 0.4409, eval: [7.4 s]
# Iteration 1 fit: [15.6 s]: Recall = 0.1542, Jaccard score = 0.1304, loss = 0.4199, eval: [7.0 s]
# Iteration 2 fit: [13.8 s]: Recall = 0.1593, Jaccard score = 0.1352, loss = 0.4134, eval: [6.8 s]
# Iteration 3 fit: [13.6 s]: Recall = 0.1627, Jaccard score = 0.1385, loss = 0.4097, eval: [7.1 s]
# Iteration 4 fit: [15.8 s]: Recall = 0.1692, Jaccard score = 0.1449, loss = 0.4064, eval: [6.9 s]
# Iteration 5 fit: [13.9 s]: Recall = 0.1696, Jaccard score = 0.1452, loss = 0.4036, eval: [6.9 s]
# Iteration 6 fit: [13.8 s]: Recall = 0.1721, Jaccard score = 0.1478, loss = 0.4018, eval: [7.0 s]
# Iteration 7 fit: [13.8 s]: Recall = 0.1714, Jaccard score = 0.1470, loss = 0.3996, eval: [6.9 s]
# Iteration 8 fit: [13.8 s]: Recall = 0.1734, Jaccard score = 0.1490, loss = 0.3979, eval: [6.8 s]
# Iteration 9 fit: [13.8 s]: Recall = 0.1781, Jaccard score = 0.1537, loss = 0.3962, eval: [7.0 s]
# Iteration 10 fit: [13.7 s]: Recall = 0.1772, Jaccard score = 0.1528, loss = 0.3947, eval: [7.0 s]
# Iteration 11 fit: [13.8 s]: Recall = 0.1784, Jaccard score = 0.1539, loss = 0.3932, eval: [7.1 s]
# Iteration 12 fit: [13.7 s]: Recall = 0.1791, Jaccard score = 0.1546, loss = 0.3920, eval: [6.8 s]
# Iteration 13 fit: [13.8 s]: Recall = 0.1796, Jaccard score = 0.1552, loss = 0.3909, eval: [6.8 s]
# Iteration 14 fit: [14.1 s]: Recall = 0.1819, Jaccard score = 0.1575, loss = 0.3897, eval: [8.2 s]
# Iteration 15 fit: [14.7 s]: Recall = 0.1828, Jaccard score = 0.1583, loss = 0.3888, eval: [6.8 s]
# Iteration 16 fit: [15.1 s]: Recall = 0.1819, Jaccard score = 0.1575, loss = 0.3880, eval: [8.6 s]
# Iteration 17 fit: [15.8 s]: Recall = 0.1850, Jaccard score = 0.1606, loss = 0.3868, eval: [7.0 s]
# Iteration 18 fit: [14.1 s]: Recall = 0.1838, Jaccard score = 0.1594, loss = 0.3855, eval: [6.9 s]
# Iteration 19 fit: [13.6 s]: Recall = 0.1855, Jaccard score = 0.1611, loss = 0.3846, eval: [6.9 s]
# Iteration 20 fit: [13.8 s]: Recall = 0.1866, Jaccard score = 0.1622, loss = 0.3840, eval: [6.8 s]
# Iteration 21 fit: [13.8 s]: Recall = 0.1847, Jaccard score = 0.1603, loss = 0.3830, eval: [7.0 s]
# Iteration 22 fit: [13.9 s]: Recall = 0.1842, Jaccard score = 0.1598, loss = 0.3822, eval: [6.9 s]
# Iteration 23 fit: [13.8 s]: Recall = 0.1873, Jaccard score = 0.1629, loss = 0.3815, eval: [6.8 s]
# Iteration 24 fit: [13.8 s]: Recall = 0.1884, Jaccard score = 0.1640, loss = 0.3803, eval: [7.0 s]
# Iteration 25 fit: [13.7 s]: Recall = 0.1875, Jaccard score = 0.1631, loss = 0.3797, eval: [6.9 s]
# Iteration 26 fit: [13.8 s]: Recall = 0.1900, Jaccard score = 0.1656, loss = 0.3794, eval: [6.8 s]
# Iteration 27 fit: [14.0 s]: Recall = 0.1886, Jaccard score = 0.1642, loss = 0.3788, eval: [7.0 s]
# Iteration 28 fit: [13.8 s]: Recall = 0.1897, Jaccard score = 0.1654, loss = 0.3782, eval: [6.8 s]
# Iteration 29 fit: [13.8 s]: Recall = 0.1897, Jaccard score = 0.1653, loss = 0.3772, eval: [7.0 s]
# Iteration 30 fit: [13.8 s]: Recall = 0.1906, Jaccard score = 0.1663, loss = 0.3765, eval: [6.9 s]
# Iteration 31 fit: [14.2 s]: Recall = 0.1910, Jaccard score = 0.1667, loss = 0.3757, eval: [6.9 s]
# Iteration 32 fit: [13.8 s]: Recall = 0.1917, Jaccard score = 0.1674, loss = 0.3760, eval: [6.9 s]
# Iteration 33 fit: [13.8 s]: Recall = 0.1895, Jaccard score = 0.1651, loss = 0.3746, eval: [6.9 s]
# Iteration 34 fit: [13.8 s]: Recall = 0.1919, Jaccard score = 0.1675, loss = 0.3743, eval: [6.8 s]
# Iteration 35 fit: [13.8 s]: Recall = 0.1927, Jaccard score = 0.1683, loss = 0.3735, eval: [6.8 s]
# Iteration 36 fit: [13.8 s]: Recall = 0.1916, Jaccard score = 0.1673, loss = 0.3728, eval: [6.8 s]
# Iteration 37 fit: [13.8 s]: Recall = 0.1890, Jaccard score = 0.1646, loss = 0.3725, eval: [6.9 s]
# Iteration 38 fit: [13.8 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3720, eval: [6.8 s]
# Iteration 39 fit: [13.8 s]: Recall = 0.1947, Jaccard score = 0.1704, loss = 0.3715, eval: [7.0 s]
# Iteration 40 fit: [14.1 s]: Recall = 0.1948, Jaccard score = 0.1705, loss = 0.3712, eval: [6.9 s]
# Iteration 41 fit: [13.8 s]: Recall = 0.1945, Jaccard score = 0.1702, loss = 0.3705, eval: [6.9 s]
# Iteration 42 fit: [13.7 s]: Recall = 0.1970, Jaccard score = 0.1728, loss = 0.3702, eval: [6.8 s]
# Iteration 43 fit: [14.1 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3697, eval: [7.0 s]
# Iteration 44 fit: [13.7 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3693, eval: [6.8 s]
# Iteration 45 fit: [13.8 s]: Recall = 0.1931, Jaccard score = 0.1688, loss = 0.3686, eval: [6.9 s]
# Iteration 46 fit: [13.8 s]: Recall = 0.1943, Jaccard score = 0.1701, loss = 0.3682, eval: [6.8 s]
# Iteration 47 fit: [13.8 s]: Recall = 0.1957, Jaccard score = 0.1714, loss = 0.3681, eval: [7.0 s]
# Iteration 48 fit: [14.0 s]: Recall = 0.1944, Jaccard score = 0.1701, loss = 0.3670, eval: [6.9 s]
# Iteration 49 fit: [13.7 s]: Recall = 0.1969, Jaccard score = 0.1727, loss = 0.3671, eval: [6.9 s]
# Iteration 50 fit: [13.6 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3664, eval: [7.0 s]
# Iteration 51 fit: [13.8 s]: Recall = 0.1953, Jaccard score = 0.1711, loss = 0.3662, eval: [6.9 s]
# Iteration 52 fit: [13.9 s]: Recall = 0.1964, Jaccard score = 0.1721, loss = 0.3657, eval: [6.9 s]
# Iteration 53 fit: [13.6 s]: Recall = 0.1948, Jaccard score = 0.1706, loss = 0.3650, eval: [7.0 s]
# Iteration 54 fit: [13.9 s]: Recall = 0.1983, Jaccard score = 0.1742, loss = 0.3650, eval: [7.0 s]
# Iteration 55 fit: [13.8 s]: Recall = 0.1953, Jaccard score = 0.1710, loss = 0.3646, eval: [6.9 s]
# Iteration 56 fit: [13.8 s]: Recall = 0.1966, Jaccard score = 0.1724, loss = 0.3643, eval: [7.0 s]
# Iteration 57 fit: [13.8 s]: Recall = 0.1991, Jaccard score = 0.1750, loss = 0.3635, eval: [7.0 s]
# Iteration 58 fit: [13.8 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3636, eval: [7.0 s]
# Iteration 59 fit: [14.2 s]: Recall = 0.1978, Jaccard score = 0.1736, loss = 0.3630, eval: [7.0 s]
# Iteration 60 fit: [13.8 s]: Recall = 0.1973, Jaccard score = 0.1731, loss = 0.3625, eval: [6.8 s]
# Iteration 61 fit: [14.0 s]: Recall = 0.1956, Jaccard score = 0.1713, loss = 0.3625, eval: [7.0 s]
# Iteration 62 fit: [13.7 s]: Recall = 0.1989, Jaccard score = 0.1748, loss = 0.3617, eval: [6.8 s]
# Iteration 63 fit: [13.5 s]: Recall = 0.1983, Jaccard score = 0.1741, loss = 0.3616, eval: [6.8 s]
# Iteration 64 fit: [13.6 s]: Recall = 0.1984, Jaccard score = 0.1743, loss = 0.3612, eval: [6.8 s]
# Iteration 65 fit: [14.1 s]: Recall = 0.1974, Jaccard score = 0.1732, loss = 0.3611, eval: [6.8 s]
# Iteration 66 fit: [13.8 s]: Recall = 0.1989, Jaccard score = 0.1747, loss = 0.3609, eval: [6.9 s]
# Iteration 67 fit: [13.8 s]: Recall = 0.1958, Jaccard score = 0.1716, loss = 0.3599, eval: [6.9 s]
# Iteration 68 fit: [13.9 s]: Recall = 0.1999, Jaccard score = 0.1758, loss = 0.3600, eval: [6.8 s]
# Iteration 69 fit: [13.6 s]: Recall = 0.2000, Jaccard score = 0.1758, loss = 0.3599, eval: [6.9 s]
# Iteration 70 fit: [13.8 s]: Recall = 0.1991, Jaccard score = 0.1749, loss = 0.3594, eval: [7.0 s]
# Iteration 71 fit: [13.6 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.3590, eval: [6.8 s]
# Iteration 72 fit: [13.9 s]: Recall = 0.1991, Jaccard score = 0.1749, loss = 0.3586, eval: [6.9 s]
# Iteration 73 fit: [13.8 s]: Recall = 0.2023, Jaccard score = 0.1782, loss = 0.3584, eval: [6.8 s]
# Iteration 74 fit: [13.8 s]: Recall = 0.2007, Jaccard score = 0.1767, loss = 0.3580, eval: [6.9 s]
# Iteration 75 fit: [13.8 s]: Recall = 0.2001, Jaccard score = 0.1760, loss = 0.3576, eval: [6.9 s]
# Iteration 76 fit: [14.1 s]: Recall = 0.2024, Jaccard score = 0.1784, loss = 0.3578, eval: [7.0 s]
# Iteration 77 fit: [13.6 s]: Recall = 0.2000, Jaccard score = 0.1759, loss = 0.3572, eval: [6.8 s]
# Iteration 78 fit: [13.8 s]: Recall = 0.1983, Jaccard score = 0.1741, loss = 0.3570, eval: [6.9 s]
# Iteration 79 fit: [13.8 s]: Recall = 0.2017, Jaccard score = 0.1776, loss = 0.3568, eval: [6.8 s]
# Iteration 80 fit: [13.8 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.3570, eval: [6.9 s]
# Iteration 81 fit: [13.8 s]: Recall = 0.2016, Jaccard score = 0.1775, loss = 0.3560, eval: [6.8 s]
# Iteration 82 fit: [13.9 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3557, eval: [7.0 s]
# Iteration 83 fit: [13.8 s]: Recall = 0.2025, Jaccard score = 0.1785, loss = 0.3552, eval: [6.8 s]
# Iteration 84 fit: [13.8 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3552, eval: [6.8 s]
# Iteration 85 fit: [13.7 s]: Recall = 0.2015, Jaccard score = 0.1774, loss = 0.3551, eval: [6.8 s]
# Iteration 86 fit: [13.6 s]: Recall = 0.2009, Jaccard score = 0.1768, loss = 0.3552, eval: [7.0 s]
# Iteration 87 fit: [13.8 s]: Recall = 0.2012, Jaccard score = 0.1771, loss = 0.3545, eval: [6.8 s]
# Iteration 88 fit: [13.5 s]: Recall = 0.1994, Jaccard score = 0.1753, loss = 0.3540, eval: [6.8 s]
# Iteration 89 fit: [13.6 s]: Recall = 0.2000, Jaccard score = 0.1759, loss = 0.3544, eval: [7.0 s]
# Iteration 90 fit: [13.7 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3540, eval: [7.0 s]
# Iteration 91 fit: [13.9 s]: Recall = 0.2014, Jaccard score = 0.1774, loss = 0.3535, eval: [6.8 s]
# Iteration 92 fit: [13.7 s]: Recall = 0.2020, Jaccard score = 0.1779, loss = 0.3529, eval: [7.0 s]
# Iteration 93 fit: [13.8 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3533, eval: [6.8 s]
# Iteration 94 fit: [13.8 s]: Recall = 0.2050, Jaccard score = 0.1811, loss = 0.3526, eval: [7.0 s]
# Iteration 95 fit: [13.8 s]: Recall = 0.2010, Jaccard score = 0.1769, loss = 0.3526, eval: [6.8 s]
# Iteration 96 fit: [13.8 s]: Recall = 0.2026, Jaccard score = 0.1786, loss = 0.3522, eval: [7.0 s]
# Iteration 97 fit: [14.0 s]: Recall = 0.2023, Jaccard score = 0.1783, loss = 0.3517, eval: [6.9 s]
# Iteration 98 fit: [13.8 s]: Recall = 0.2005, Jaccard score = 0.1764, loss = 0.3518, eval: [6.8 s]
# Iteration 99 fit: [13.6 s]: Recall = 0.1993, Jaccard score = 0.1752, loss = 0.3515, eval: [7.0 s]
# Iteration 100 fit: [13.9 s]: Recall = 0.2030, Jaccard score = 0.1790, loss = 0.3510, eval: [6.9 s]
# Iteration 101 fit: [13.9 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3509, eval: [6.8 s]
# Iteration 102 fit: [13.9 s]: Recall = 0.2033, Jaccard score = 0.1793, loss = 0.3509, eval: [7.0 s]
# Iteration 103 fit: [13.8 s]: Recall = 0.2019, Jaccard score = 0.1778, loss = 0.3513, eval: [6.8 s]
# Iteration 104 fit: [14.2 s]: Recall = 0.2044, Jaccard score = 0.1805, loss = 0.3508, eval: [7.0 s]
# Iteration 105 fit: [13.5 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3501, eval: [7.0 s]
# Iteration 106 fit: [14.0 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3499, eval: [6.9 s]
# Iteration 107 fit: [13.8 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3494, eval: [6.8 s]
# Iteration 108 fit: [13.5 s]: Recall = 0.2018, Jaccard score = 0.1777, loss = 0.3497, eval: [6.8 s]
# Iteration 109 fit: [13.7 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3495, eval: [6.9 s]
# Iteration 110 fit: [13.8 s]: Recall = 0.2021, Jaccard score = 0.1781, loss = 0.3491, eval: [6.8 s]
# Iteration 111 fit: [13.8 s]: Recall = 0.2044, Jaccard score = 0.1804, loss = 0.3488, eval: [6.9 s]
# Iteration 112 fit: [13.6 s]: Recall = 0.2039, Jaccard score = 0.1800, loss = 0.3486, eval: [7.0 s]
# Iteration 113 fit: [14.1 s]: Recall = 0.2039, Jaccard score = 0.1799, loss = 0.3488, eval: [6.9 s]
# Iteration 114 fit: [13.5 s]: Recall = 0.2026, Jaccard score = 0.1786, loss = 0.3484, eval: [7.0 s]
# Iteration 115 fit: [13.9 s]: Recall = 0.2031, Jaccard score = 0.1791, loss = 0.3479, eval: [7.0 s]
# Iteration 116 fit: [13.9 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3477, eval: [6.9 s]
# Iteration 117 fit: [13.8 s]: Recall = 0.2047, Jaccard score = 0.1808, loss = 0.3478, eval: [6.8 s]
# Iteration 118 fit: [13.8 s]: Recall = 0.2053, Jaccard score = 0.1814, loss = 0.3474, eval: [6.9 s]
# Iteration 119 fit: [13.8 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3469, eval: [6.9 s]
# Iteration 120 fit: [13.8 s]: Recall = 0.2032, Jaccard score = 0.1792, loss = 0.3467, eval: [7.0 s]
# Iteration 121 fit: [14.0 s]: Recall = 0.2037, Jaccard score = 0.1797, loss = 0.3467, eval: [7.0 s]
# Iteration 122 fit: [13.8 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3467, eval: [6.9 s]
# Iteration 123 fit: [13.9 s]: Recall = 0.2031, Jaccard score = 0.1791, loss = 0.3459, eval: [6.9 s]
# Iteration 124 fit: [13.6 s]: Recall = 0.2047, Jaccard score = 0.1807, loss = 0.3463, eval: [6.9 s]
# Iteration 125 fit: [13.8 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3457, eval: [7.0 s]
# Iteration 126 fit: [13.9 s]: Recall = 0.2045, Jaccard score = 0.1806, loss = 0.3456, eval: [6.9 s]
# Iteration 127 fit: [14.0 s]: Recall = 0.2034, Jaccard score = 0.1794, loss = 0.3458, eval: [6.8 s]
# Iteration 128 fit: [13.9 s]: Recall = 0.2040, Jaccard score = 0.1800, loss = 0.3453, eval: [7.0 s]
# Iteration 129 fit: [13.8 s]: Recall = 0.2015, Jaccard score = 0.1775, loss = 0.3453, eval: [6.9 s]
# Iteration 130 fit: [13.8 s]: Recall = 0.2038, Jaccard score = 0.1799, loss = 0.3454, eval: [6.9 s]
# Iteration 131 fit: [13.5 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3445, eval: [6.9 s]
# Iteration 132 fit: [13.8 s]: Recall = 0.2035, Jaccard score = 0.1795, loss = 0.3445, eval: [6.8 s]
# Iteration 133 fit: [13.8 s]: Recall = 0.2056, Jaccard score = 0.1817, loss = 0.3449, eval: [7.0 s]
# Iteration 134 fit: [13.5 s]: Recall = 0.2038, Jaccard score = 0.1798, loss = 0.3447, eval: [6.9 s]
# Iteration 135 fit: [13.7 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3441, eval: [7.0 s]
# Iteration 136 fit: [13.8 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3439, eval: [6.9 s]
# Iteration 137 fit: [13.5 s]: Recall = 0.2068, Jaccard score = 0.1829, loss = 0.3441, eval: [6.9 s]
# Iteration 138 fit: [13.8 s]: Recall = 0.2054, Jaccard score = 0.1815, loss = 0.3438, eval: [6.9 s]
# Iteration 139 fit: [13.7 s]: Recall = 0.2050, Jaccard score = 0.1810, loss = 0.3431, eval: [6.9 s]
# Iteration 140 fit: [14.0 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.3434, eval: [6.9 s]
# Iteration 141 fit: [13.9 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3429, eval: [6.8 s]
# Iteration 142 fit: [13.6 s]: Recall = 0.2038, Jaccard score = 0.1798, loss = 0.3429, eval: [6.9 s]
# Iteration 143 fit: [13.9 s]: Recall = 0.2046, Jaccard score = 0.1806, loss = 0.3427, eval: [7.0 s]
# Iteration 144 fit: [13.8 s]: Recall = 0.2044, Jaccard score = 0.1804, loss = 0.3423, eval: [7.0 s]
# Iteration 145 fit: [13.8 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3425, eval: [6.9 s]
# Iteration 146 fit: [13.8 s]: Recall = 0.2050, Jaccard score = 0.1811, loss = 0.3420, eval: [6.9 s]
# Iteration 147 fit: [13.7 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3423, eval: [6.8 s]
# Iteration 148 fit: [13.7 s]: Recall = 0.2068, Jaccard score = 0.1829, loss = 0.3417, eval: [6.9 s]
# Iteration 149 fit: [13.5 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3417, eval: [7.0 s]
# Iteration 150 fit: [13.3 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3414, eval: [6.9 s]
# Iteration 151 fit: [13.9 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.3415, eval: [7.0 s]
# Iteration 152 fit: [13.5 s]: Recall = 0.2088, Jaccard score = 0.1851, loss = 0.3413, eval: [6.8 s]
# Iteration 153 fit: [13.9 s]: Recall = 0.2047, Jaccard score = 0.1807, loss = 0.3411, eval: [6.9 s]
# Iteration 154 fit: [13.8 s]: Recall = 0.2042, Jaccard score = 0.1803, loss = 0.3410, eval: [6.8 s]
# Iteration 155 fit: [13.5 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.3411, eval: [6.9 s]
# Iteration 156 fit: [13.8 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.3410, eval: [6.9 s]
# Iteration 157 fit: [13.8 s]: Recall = 0.2043, Jaccard score = 0.1803, loss = 0.3403, eval: [6.9 s]
# Iteration 158 fit: [13.9 s]: Recall = 0.2037, Jaccard score = 0.1797, loss = 0.3398, eval: [7.0 s]
# Iteration 159 fit: [13.9 s]: Recall = 0.2058, Jaccard score = 0.1819, loss = 0.3402, eval: [6.9 s]
# Iteration 160 fit: [13.8 s]: Recall = 0.2036, Jaccard score = 0.1796, loss = 0.3400, eval: [7.0 s]
# Iteration 161 fit: [13.9 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3395, eval: [7.0 s]
# Iteration 162 fit: [13.7 s]: Recall = 0.2060, Jaccard score = 0.1821, loss = 0.3397, eval: [7.0 s]
# Iteration 163 fit: [13.9 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3398, eval: [7.0 s]
# Iteration 164 fit: [13.5 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3391, eval: [6.9 s]
# Iteration 165 fit: [13.9 s]: Recall = 0.2047, Jaccard score = 0.1808, loss = 0.3391, eval: [7.0 s]
# Iteration 166 fit: [13.8 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3392, eval: [6.9 s]
# Iteration 167 fit: [13.9 s]: Recall = 0.2059, Jaccard score = 0.1820, loss = 0.3389, eval: [7.0 s]
# Iteration 168 fit: [13.7 s]: Recall = 0.2066, Jaccard score = 0.1828, loss = 0.3391, eval: [6.9 s]
# Iteration 169 fit: [13.8 s]: Recall = 0.2057, Jaccard score = 0.1819, loss = 0.3386, eval: [6.9 s]
# Iteration 170 fit: [13.8 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3385, eval: [6.9 s]
# Iteration 171 fit: [13.7 s]: Recall = 0.2057, Jaccard score = 0.1818, loss = 0.3384, eval: [7.0 s]
# Iteration 172 fit: [13.8 s]: Recall = 0.2073, Jaccard score = 0.1835, loss = 0.3386, eval: [6.8 s]
# Iteration 173 fit: [13.8 s]: Recall = 0.2083, Jaccard score = 0.1846, loss = 0.3380, eval: [7.0 s]
# Iteration 174 fit: [13.8 s]: Recall = 0.2066, Jaccard score = 0.1828, loss = 0.3380, eval: [6.8 s]
# Iteration 175 fit: [13.8 s]: Recall = 0.2050, Jaccard score = 0.1810, loss = 0.3381, eval: [6.9 s]
# Iteration 176 fit: [13.7 s]: Recall = 0.2048, Jaccard score = 0.1809, loss = 0.3373, eval: [6.8 s]
# Iteration 177 fit: [13.8 s]: Recall = 0.2061, Jaccard score = 0.1822, loss = 0.3376, eval: [6.9 s]
# Iteration 178 fit: [13.8 s]: Recall = 0.2043, Jaccard score = 0.1804, loss = 0.3374, eval: [6.8 s]
# Iteration 179 fit: [13.6 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3371, eval: [6.8 s]
# Iteration 180 fit: [13.6 s]: Recall = 0.2051, Jaccard score = 0.1812, loss = 0.3373, eval: [6.9 s]
# Iteration 181 fit: [13.8 s]: Recall = 0.2077, Jaccard score = 0.1839, loss = 0.3369, eval: [6.9 s]
# Iteration 182 fit: [14.1 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3369, eval: [6.9 s]
# Iteration 183 fit: [13.7 s]: Recall = 0.2070, Jaccard score = 0.1832, loss = 0.3365, eval: [6.9 s]
# Iteration 184 fit: [13.7 s]: Recall = 0.2081, Jaccard score = 0.1843, loss = 0.3365, eval: [6.9 s]
# Iteration 185 fit: [13.8 s]: Recall = 0.2082, Jaccard score = 0.1844, loss = 0.3360, eval: [6.9 s]
# Iteration 186 fit: [13.7 s]: Recall = 0.2071, Jaccard score = 0.1833, loss = 0.3361, eval: [6.9 s]
# Iteration 187 fit: [13.8 s]: Recall = 0.2075, Jaccard score = 0.1837, loss = 0.3361, eval: [6.9 s]
# End. Best Iteration 152:  Recall = 0.2088, Jaccard score = 0.1851. 
# The best NeuMF model has been saved to Pretrain/_MLP_8_[1024,128]_1564063268.h5
# Model test performed 
# Recall score: 0.06872795414462081     Jaccard score: 0.05446128313752893