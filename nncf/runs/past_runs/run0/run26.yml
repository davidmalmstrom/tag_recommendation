--nn_model: MLP
--is_tag: '1'
--eval_recall: '1'
--topk: '3'
--big_tag: '0'
--epochs: '200'


# Launched by VS Code.
# MLP arguments: Namespace(batch_size=256, big_tag=0, dataset='', epochs=200, eval_recall=1, is_tag=1, layers='[64,32,16,8]', learner='adam', lr=0.001, mf_pretrain='', mlp_pretrain='', nn_model='MLP', num_factors=8, num_neg=4, out=1, path='Data/', reg_layers='[0,0,0,0]', reg_mf=0, topk=3, verbose=1) 
# Load data done [6.0 s]. #user=17431, #item=986, #train=133143, #test=17431
# __________________________________________________________________________________________________
# Layer (type)                    Output Shape         Param #     Connected to                     
# ==================================================================================================
# user_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# item_input (InputLayer)         (None, 1)            0                                            
# __________________________________________________________________________________________________
# user_embedding (Embedding)      (None, 1, 32)        557792      user_input[0][0]                 
# __________________________________________________________________________________________________
# item_embedding (Embedding)      (None, 1, 32)        31552       item_input[0][0]                 
# __________________________________________________________________________________________________
# flatten_1 (Flatten)             (None, 32)           0           user_embedding[0][0]             
# __________________________________________________________________________________________________
# flatten_2 (Flatten)             (None, 32)           0           item_embedding[0][0]             
# __________________________________________________________________________________________________
# concatenate_1 (Concatenate)     (None, 64)           0           flatten_1[0][0]                  
#                                                                  flatten_2[0][0]                  
# __________________________________________________________________________________________________
# layer1 (Dense)                  (None, 32)           2080        concatenate_1[0][0]              
# __________________________________________________________________________________________________
# layer2 (Dense)                  (None, 16)           528         layer1[0][0]                     
# __________________________________________________________________________________________________
# layer3 (Dense)                  (None, 8)            136         layer2[0][0]                     
# __________________________________________________________________________________________________
# prediction (Dense)              (None, 1)            9           layer3[0][0]                     
# ==================================================================================================
# Total params: 592,097
# Trainable params: 592,097
# Non-trainable params: 0
# __________________________________________________________________________________________________
