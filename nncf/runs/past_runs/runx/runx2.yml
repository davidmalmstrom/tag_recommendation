--nn_model: NeuMF
--is_tag: "1"
--eval_recall: "1"
--topk: "3"
--big_tag: "0"
--epochs: "300"
--num_factors: "94"
--layers: "[512,96]"
--reg_layers: "[0,0]"
--early_stopping: "45"
--test_dataset: "1"
--mf_pretrain: "Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5"
--mlp_pretrain: "Pretrain/_MLP_8_[512,96]_1566587297.h5"

# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=45, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5', mlp_pretrain='Pretrain/_MLP_8_[512,96]_1565793831.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,96]_1568018575.h5
--weights_path: Pretrain/_NeuMF_94_[512,96]_1568018575.h5
# Load data done [4.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=45, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5', mlp_pretrain='Pretrain/_MLP_8_[512,96]_1566587297.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,96]_1568019162.h5
--weights_path: Pretrain/_NeuMF_94_[512,96]_1568019162.h5
# Load data done [4.4 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5) and MLP (Pretrain/_MLP_8_[512,96]_1566587297.h5) models done. 
# 
# Performing k-fold 1
# Init: Recall = 0.1488, Jaccard score = 0.0969
# Iteration 0 fit: [40.7 s]: Recall = 0.3675, Jaccard score = 0.2788, loss = 0.0047, gradient norm = 1.0360, eval: [12.6 s]
# Iteration 1 fit: [39.0 s]: Recall = 0.3617, Jaccard score = 0.2732, loss = 0.0044, gradient norm = 0.9826, eval: [12.6 s]
# Iteration 2 fit: [39.2 s]: Recall = 0.3528, Jaccard score = 0.2647, loss = 0.0044, gradient norm = 0.9769, eval: [12.6 s]


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=45, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5', mlp_pretrain='Pretrain/_MLP_8_[512,96]_1566587297.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,96]_1568019605.h5
--weights_path: Pretrain/_NeuMF_94_[512,96]_1568019605.h5
# Load data done [5.0 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5) and MLP (Pretrain/_MLP_8_[512,96]_1566587297.h5) models done. 
# 
# Performing k-fold 1
# Init: Recall = 0.1496, Jaccard score = 0.0974
# Iteration 0 fit: [40.9 s]: Recall = 0.3630, Jaccard score = 0.2745, loss = 0.0045, gradient norm = 0.9932, eval: [12.9 s]


# Launched by terminal.
# NeuMF arguments: Namespace(batch_size=256, big_tag=0, dataset='', dataset_name_prepend='', early_stopping=45, epochs=300, eval_recall=1, is_tag=1, layers='[512,96]', learner='adam', lr=0.001, mf_pretrain='Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5', mlp_pretrain='Pretrain/_MLP_8_[512,96]_1566587297.h5', nn_model='NeuMF', num_factors=94, num_k_folds=1, num_neg=4, out=1, path='../data/', percentage=0.5, reg_layers='[0,0]', reg_mf=0, test_dataset=1, topk=3, verbose=1) 
# The best NeuMF model will be saved to Pretrain/_NeuMF_94_[512,96]_1568021176.h5
--weights_path: Pretrain/_NeuMF_94_[512,96]_1568021176.h5
# Load data done [4.7 s]. #user=20000, #item=2000, #train=161729, #test=eval_recall
# Load pretrained GMF (Pretrain/_GMF_94_[64,32,16,8]_1565810780.h5) and MLP (Pretrain/_MLP_8_[512,96]_1566587297.h5) models done. 
# 
# Performing k-fold 1
# Init: Recall = 0.3940, Jaccard score = 0.3051
# Model test performed 
# Recall score: 0.18377594286989513     Jaccard score: 0.12369508073601201# Model test performed 
# Recall score: 0.18377594286989513     Jaccard score: 0.12369508073601201